---
phase: 54-feature-gap-closure
plan: 10
type: execute
wave: 3
depends_on: [54-07]
files_modified:
  - Plugins/DataWarehouse.Plugins.UltimateFilesystem/Strategies/**
  - Plugins/DataWarehouse.Plugins.UltimateCompute/Strategies/**
  - Plugins/DataWarehouse.Plugins.Compute.Wasm/**
  - Plugins/DataWarehouse.Plugins.UltimateIntelligence/Strategies/**
autonomous: true

must_haves:
  truths:
    - "Top 10 filesystem implementations (ext4, NTFS, APFS, XFS, Btrfs) have core operations"
    - "WASM compute runtime executes bytecode"
    - "AI provider SDK integrations (OpenAI, embeddings) operational via UltimateIntelligence"
    - "Compute runtime strategies have working execution paths"
  artifacts:
    - path: "Plugins/DataWarehouse.Plugins.UltimateFilesystem/Strategies/"
      provides: "Top 10 filesystem strategy implementations"
    - path: "Plugins/DataWarehouse.Plugins.UltimateCompute/Strategies/"
      provides: "Compute runtime strategies"
    - path: "Plugins/DataWarehouse.Plugins.UltimateIntelligence/Strategies/"
      provides: "AI provider integrations"
  key_links:
    - from: "UltimateFilesystem"
      to: "VDE (Phase 33)"
      via: "block device abstraction"
      pattern: "IBlockDevice|FileBlockDevice"
    - from: "UltimateIntelligence"
      to: "intelligence.* bus topics"
      via: "AI inference delegation"
      pattern: "intelligence\\.infer"
---

<objective>
Major Gaps: Filesystem, Compute, Intelligence — Core implementations for metadata-only features.

Purpose: Domains 10 (Filesystem), 11 (Compute), and 13 (Intelligence) have 93%+ features as metadata-only. This plan implements the most critical subset: top 10 filesystem types, WASM runtime, and AI provider integrations.

SCOPE LIMITATION: Implement the top 10-15 most critical features per domain rather than all metadata-only features. Full coverage would require 50+ additional plans.

Output: ~50 critical features moved from <20% to functional (60%+) implementations.
</objective>

<execution_context>
@C:/Users/ddamien/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/ddamien/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/PLUGIN-CATALOG.md
@.planning/phases/42-feature-verification-matrix/domains-9-13-summary.md
@.planning/phases/54-feature-gap-closure/54-07-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Filesystem — Top 10 Implementations + I/O Drivers (25 features)</name>
  <files>
    Plugins/DataWarehouse.Plugins.UltimateFilesystem/Strategies/**
  </files>
  <action>
Implement core filesystem strategy logic for the top 10 filesystem types. These are currently at 5% (strategy ID registered, zero implementation).

NOTE: All filesystem strategies should work through the VDE (Virtual Disk Engine) block device abstraction from Phase 33. Use IBlockDevice for all block-level operations.

**Core Filesystem Operations (each strategy must implement)**:
1. Format — create filesystem structures (superblock, allocation bitmap, inode table)
2. Mount — read superblock, verify integrity, load metadata
3. Create file/directory — allocate inode, update directory entry, set permissions
4. Read file — resolve path to inode, read data blocks, return content
5. Write file — allocate blocks, write data, update inode metadata
6. Delete — unlink inode, update free space, handle directory entries
7. List directory — read directory entries, resolve inodes, return metadata
8. Get/Set attributes — permissions, timestamps, extended attributes

**Top 10 Filesystem Implementations**:
1. ext4 (5%->80%): Extent-based allocation, journaling (journal/ordered/writeback), delayed allocation, inline data for small files, htree directories, 64-bit block addressing
2. NTFS (5%->80%): MFT (Master File Table), resident/non-resident attributes, B+ tree indexes, USN journal, ACL security descriptors, compression (LZ77 variant)
3. XFS (5%->80%): Allocation groups, B+ tree extent mapping, delayed allocation, online defragmentation, real-time subvolume
4. Btrfs (5%->80%): Copy-on-write B-trees, subvolumes, snapshots (via VDE COW), checksumming (delegate to UltimateDataIntegrity), inline compression, RAID support (delegate to UltimateRAID)
5. ZFS (5%->80%): Storage pool (vdev hierarchy), copy-on-write, data integrity (checksums via bus), deduplication (via bus), compression (via bus), snapshots, clones
6. APFS (5%->70%): Copy-on-write, space sharing across volumes, encryption (delegate to UltimateEncryption via bus), snapshot-based, case-sensitivity options
7. FAT32 (5%->90%): Simple implementation — FAT table, 8.3 filenames + VFAT long names, cluster chains, 4GB file size limit, no permissions
8. exFAT (5%->90%): Extended FAT — no file size limit, allocation bitmap, up-case table, extended directory entries
9. F2FS (5%->70%): Flash-friendly — multi-head logging, node/sit/nat areas, cold/warm/hot data separation, inline inode data
10. tmpfs (5%->90%): RAM-based — simple in-memory inode/dentry structures, configurable size limit, no persistence

**I/O Drivers (5 strategies)**:
- Direct I/O (10%): Bypass page cache, aligned buffer management, O_DIRECT flag handling
- io_uring (10%): Submission/completion queue pair, batched I/O, zero-copy where supported (Linux only — platform check with NotSupportedOnPlatformException on Windows/macOS)
- Memory-mapped I/O (10%): mmap/munmap abstraction, page fault handling, msync for durability
- Buffered I/O (10%): Read-ahead, write-behind, configurable buffer sizes, flush policies
- SPDK integration (10%): NVMe user-space driver abstraction, polled I/O completions (Linux only)

CRITICAL: All hashing delegates to UltimateDataIntegrity via bus. All encryption delegates to UltimateEncryption via bus. All RAID delegates to UltimateRAID via bus. Filesystem strategies MUST NOT contain inline crypto.
  </action>
  <verify>
dotnet build DataWarehouse.slnx — zero errors
ext4 strategy: format/mount/create/read/write/delete/list operations compile
FAT32 strategy: simple but complete implementation
No inline crypto (AD-11)
  </verify>
  <done>Top 10 filesystem implementations with core CRUD operations functional via VDE block device</done>
</task>

<task type="auto">
  <name>Task 2: Compute Runtime + Intelligence AI Providers (25 features)</name>
  <files>
    Plugins/DataWarehouse.Plugins.UltimateCompute/Strategies/**
    Plugins/DataWarehouse.Plugins.Compute.Wasm/**
    Plugins/DataWarehouse.Plugins.UltimateIntelligence/Strategies/**
    Plugins/DataWarehouse.Plugins.UltimateIntelligence/Providers/**
  </files>
  <action>
Implement the most critical compute runtimes and AI provider integrations.

**Compute Runtimes (10 strategies)**:
- WASM execution (15%->80%): Use Wasmtime NuGet (or similar). Module compilation, instance creation, linear memory management, imported/exported functions, WASI (file I/O, clock, random, env vars). Sandbox with memory ceiling and execution timeout.
- Container execution (5%->60%): Docker Engine API via HTTP (Unix socket /var/run/docker.sock or TCP). Container lifecycle: create, start, stop, remove. Image pull, volume mount, network configuration. Use SharedHttpClient.
- Serverless execution (5%->60%): Function invocation abstraction. Support AWS Lambda (InvokeAsync via AWSSDK.Lambda), Azure Functions (HTTP trigger), local execution (in-process). Cold start measurement, resource limits.
- Process execution (5%->80%): System.Diagnostics.Process wrapper. stdin/stdout/stderr capture, exit code handling, timeout enforcement, resource limits (memory/CPU via Job Objects on Windows, cgroups on Linux).
- Script execution (5%->70%): Embedded scripting via Roslyn (C# scripting), or Jint (JavaScript). Script compilation caching, sandboxed execution with restricted APIs, variable injection.
- GPU compute (5%->40%): CUDA/ROCm abstraction layer. Kernel launch, memory allocation (device/host/managed), stream management. Platform detection with CPU fallback. NOTE: Actual GPU execution requires CUDA toolkit — implement abstraction with fallback.
- Batch execution (5%->70%): Job queue, worker pool with configurable concurrency, job state tracking (pending/running/completed/failed), retry policies, dependency ordering.
- Parallel execution (5%->70%): Fork/join pattern, data partitioning, result aggregation, cancellation propagation, progress tracking.
- Pipeline execution (5%->70%): Multi-stage pipeline with data flowing between stages, stage-level error handling, backpressure, metrics per stage.
- Hybrid compute (already hardened in v4.4): Verify still at 100%, no regression.

**AI Provider Integrations (15 strategies)**:
NOTE: If Plan 54-09 already wired these in UltimateConnector, this task wires them into UltimateIntelligence's intelligence bus topics.

- OpenAI integration (15%->90%): Wire OpenAI NuGet into UltimateIntelligence. Expose via bus topics: intelligence.chat.complete, intelligence.embeddings.generate, intelligence.image.generate. Model selection (GPT-4, GPT-3.5-turbo), temperature/top-p configuration, token counting, rate limiting.
- Azure OpenAI (15%->90%): Same as OpenAI but with Azure endpoint configuration. Deployment name mapping.
- Anthropic (15%->80%): Wire Anthropic API. intelligence.chat.complete topic, streaming support, tool/function calling.
- Embedding providers (5%->80%): Normalize embedding generation across providers — OpenAI text-embedding-3, Cohere embed, HuggingFace sentence-transformers. Common interface: GenerateEmbedding(text) -> float[].
- Vector search (5%->70%): Wire vector DB clients (ChromaDB/Pinecone/Qdrant from Plan 09) into intelligence.vector.search topic. Similarity search, hybrid search (vector + keyword), metadata filtering.
- Model management (5%->60%): Model registry (name, version, provider, capabilities), model health monitoring, automatic fallback (if primary model unavailable, use secondary), cost tracking per model.
- Inference optimization (5%->50%): Request batching (group small requests), caching (cache identical prompts with configurable TTL), token budget tracking, prompt compression.
- Metadata harvesting (5%->60%): Auto-extract metadata from stored objects using AI — file type detection, content summarization, entity extraction, language detection. Run as background job via compute pipeline.
- Remaining 7: Sentiment analysis, classification, NER, summarization, translation, Q&A, image analysis — implement as thin wrappers around provider APIs exposed via bus topics.

Pattern: All AI operations exposed via intelligence.* bus topics. Other plugins consume AI via bus, never direct SDK calls. Compute runtimes need sandbox isolation, resource limits, and timeout enforcement.
  </action>
  <verify>
dotnet build DataWarehouse.slnx — zero errors
WASM: module compilation and execution functional
OpenAI: chat completion via intelligence bus topic
Container: Docker API lifecycle operations compile
  </verify>
  <done>Top 25 compute and intelligence features implemented with real SDK integrations</done>
</task>

</tasks>

<verification>
- dotnet build DataWarehouse.slnx succeeds with 0 errors, 0 warnings
- dotnet test passes all existing tests
- All AI operations available via intelligence.* bus topics
- All crypto/hashing delegated (AD-11)
</verification>

<success_criteria>
- ~50 critical features moved from <20% to 60%+ functional implementations
- Zero build errors or warnings
</success_criteria>

<output>
After completion, create `.planning/phases/54-feature-gap-closure/54-10-SUMMARY.md`
</output>
