---
phase: 86-adaptive-index-engine
plan: 14
type: execute
wave: 4
depends_on: ["86-01"]
files_modified:
  - DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/HilbertCurveEngine.cs
  - DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/TrainedZstdDictionary.cs
autonomous: true
must_haves:
  truths:
    - "Hilbert curve maps multi-dimensional keys to 1D with better locality than Z-order"
    - "Trained Zstd dictionaries compress small blocks more effectively than generic compression"
    - "Dictionary auto-retrains when compression ratio degrades"
    - "Compression Dictionary Region stores trained dictionaries in VDE"
  artifacts:
    - path: "DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/HilbertCurveEngine.cs"
      provides: "Full Hilbert SFC implementation"
      exports: ["HilbertCurveEngine"]
    - path: "DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/TrainedZstdDictionary.cs"
      provides: "Zstd dictionary trainer and compressor"
      exports: ["TrainedZstdDictionary"]
  key_links:
    - from: "HilbertCurveEngine"
      to: "HilbertPartitioner"
      via: "provides core SFC math used by partitioner"
      pattern: "HilbertCurveEngine\\.PointToIndex"
---

<objective>
Implement Hilbert curve engine (full SFC with 3-11x locality improvement over Z-order) and trained Zstd dictionaries (dictionary trainer, Compression Dictionary Region storage, auto-retrain).

Purpose: Hilbert curves provide optimal locality preservation for multi-dimensional data, critical for spatial indexes and shard partitioning. Trained Zstd dictionaries dramatically improve compression of small blocks (like index nodes) by learning the data's statistical patterns.
Output: 2 files implementing the Hilbert engine and Zstd dictionary system.
</objective>

<execution_context>
@C:/Users/ddamien/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/ddamien/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Hilbert curve engine with multi-dimensional support</name>
  <files>
    DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/HilbertCurveEngine.cs
  </files>
  <action>
    **HilbertCurveEngine.cs**: Complete Hilbert space-filling curve implementation.

    1. **Core 2D Hilbert curve** (Butz algorithm):
       - `static long PointToIndex2D(int x, int y, int order)`: Convert (x,y) to Hilbert index. Order determines resolution (2^order cells per dimension).
       - `static (int X, int Y) IndexToPoint2D(long index, int order)`: Inverse mapping.
       - Algorithm: iterative, processing one bit at a time from MSB. Track rotation state via (rx, ry) quadrant. Apply transformations (flip/rotate) per level.
       - `[MethodImpl(MethodImplOptions.AggressiveInlining)]` for hot-path methods.

    2. **Generalized N-dimensional Hilbert curve** (Skilling algorithm):
       - `static long PointToIndex(int[] coordinates, int dimensions, int bitsPerDimension)`: N-dim to 1D.
       - `static int[] IndexToPoint(long index, int dimensions, int bitsPerDimension)`: 1D to N-dim.
       - Skilling's compact algorithm: transpose bits, Gray code, untranspose. Handles arbitrary dimensions.
       - Max: 8 dimensions at 16 bits each = 128-bit index (use `UInt128` for wide indexes).

    3. **Byte array key integration**:
       - `static long KeyToHilbertIndex(byte[] key, int dimensions, int bitsPerDimension)`: Interprets key bytes as coordinate values. First `dimensions * ceil(bitsPerDimension/8)` bytes used.
       - `static byte[] HilbertIndexToKey(long index, int dimensions, int bitsPerDimension)`: Reverse.

    4. **Range query support**:
       - `static IEnumerable<(long Start, long End)> HilbertRanges(int[] minCoords, int[] maxCoords, int dimensions, int bitsPerDimension)`: Given a multi-dimensional bounding box, returns the set of 1D Hilbert ranges that cover it. This is the key to efficient spatial queries.
       - Implementation: recursive subdivision of the Hilbert curve. At each level, determine which quadrants/octants intersect the bounding box. Merge adjacent ranges.

    5. **Locality metrics**:
       - `static double LocalityRatio(IReadOnlyList<int[]> points, int dimensions, int bitsPerDimension)`: Measures how well the 1D ordering preserves spatial proximity. Compare sum of 1D distances vs sum of N-dim distances. Hilbert should be 3-11x better than Z-order.
       - `static double CompareWithZOrder(IReadOnlyList<int[]> points, int dimensions, int bitsPerDimension)`: Returns Hilbert locality / Z-order locality ratio.

    All methods are static and pure (no state). Thread-safe by design.
    Add `[SdkCompatibility("6.0.0", Notes = "Phase 86: AIE-14 Hilbert curve")]`.
  </action>
  <verify>Build: `dotnet build DataWarehouse.SDK/DataWarehouse.SDK.csproj --no-restore` compiles with zero errors.</verify>
  <done>HilbertCurveEngine provides 2D and N-dimensional Hilbert SFC with point-to-index, index-to-point, range queries, and locality metrics. Static pure methods, zero allocation.</done>
</task>

<task type="auto">
  <name>Task 2: Trained Zstd dictionaries with auto-retrain</name>
  <files>
    DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/TrainedZstdDictionary.cs
  </files>
  <action>
    **TrainedZstdDictionary.cs**: Dictionary-based Zstd compression for index blocks.

    Note: Uses System.IO.Compression or ZstdNet if available. Since ZstdNet may not be a dependency, implement as optional with fallback.

    1. **IIndexBlockCompressor** interface:
       - `byte[] Compress(byte[] data)`
       - `byte[] Decompress(byte[] compressedData, int originalSize)`
       - `double CompressionRatio { get; }` â€” average ratio across recent operations
       - `bool HasTrainedDictionary { get; }`

    2. **ZstdDictionaryTrainer**: Trains compression dictionaries from sample data.
       - `byte[] TrainDictionary(IReadOnlyList<byte[]> samples, int dictSize = 65536)`: Collects statistics from sample blocks and builds dictionary. If ZstdNet not available, uses a simplified approach: frequency analysis of common byte sequences (top-N n-grams stored as dictionary prefix).
       - `bool ShouldRetrain(double currentRatio, double baselineRatio, double threshold = 0.8)`: Returns true when current compression ratio has degraded to 80% of baseline (data patterns have changed).

    3. **TrainedZstdCompressor**: Implements `IIndexBlockCompressor`.
       - Constructor: `byte[]? dictionary = null`, `int compressionLevel = 3`
       - Uses trained dictionary for compression/decompression if provided
       - Without dictionary: falls back to standard Zstd (or DeflateStream if Zstd unavailable)
       - Tracks rolling average compression ratio via circular buffer of last 100 ratios
       - Thread-safe: compressor instances are per-thread (ThreadLocal) or pooled

    4. **CompressionDictionaryRegion**: VDE region storage for trained dictionaries.
       - `StoreAsync(byte[] dictionary, string name, IBlockDevice device, long regionStart)`: Serialize dictionary with header [MagicCDCT:4][Version:2][NameLen:2][Name:NameLen][DictSize:4][Dict:DictSize][XxHash64:8]
       - `LoadAsync(IBlockDevice device, long regionStart)`: Deserialize and return dictionary bytes
       - `IsValid(byte[] data)`: Check magic + hash integrity

    5. **Auto-retrain coordinator**:
       - `AutoRetrainPolicy`: `TimeSpan CheckInterval` (default 1 hour), `double DegradationThreshold` (default 0.8), `int MinSamplesForRetrain` (default 1000)
       - `DictionaryRetrainer`: Background timer checks compression ratio. If degraded, collects new samples from recent blocks, retrains, hot-swaps dictionary (volatile reference swap).

    Add `[SdkCompatibility("6.0.0", Notes = "Phase 86: AIE-14 Trained Zstd")]`.
  </action>
  <verify>Build: `dotnet build DataWarehouse.SDK/DataWarehouse.SDK.csproj --no-restore` compiles with zero errors.</verify>
  <done>TrainedZstdDictionary provides dictionary-based compression for index blocks with auto-retrain when compression ratio degrades. VDE region storage for dictionary persistence.</done>
</task>

</tasks>

<verification>
- Both files exist under `DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/`
- `dotnet build DataWarehouse.SDK/DataWarehouse.SDK.csproj` succeeds with zero errors
- Hilbert curve static methods are pure and thread-safe
- Compression dictionary persists in VDE region with integrity check
</verification>

<success_criteria>
- Hilbert curve provides N-dimensional SFC with range query support
- Trained Zstd dictionaries improve small-block compression
- Auto-retrain detects degradation and hot-swaps dictionaries
- VDE Compression Dictionary Region stores dictionaries persistently
- Build passes with zero errors
</success_criteria>

<output>
After completion, create `.planning/phases/86-adaptive-index-engine/86-14-SUMMARY.md`
</output>
