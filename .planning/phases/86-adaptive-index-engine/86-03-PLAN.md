---
phase: 86-adaptive-index-engine
plan: 03
type: execute
wave: 2
depends_on: ["86-01", "86-02"]
files_modified:
  - DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/AlexLearnedIndex.cs
  - DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/AlexModel.cs
autonomous: true
must_haves:
  truths:
    - "ALEX learned overlay achieves O(1) point lookups for skewed access patterns"
    - "CDF model auto-trains on key distribution and retrains when hit rate drops"
    - "Gapped array leaves handle insertions without immediate restructuring"
    - "ALEX auto-activates when hit-rate benefit detected, deactivates when not beneficial"
  artifacts:
    - path: "DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/AlexLearnedIndex.cs"
      provides: "Level 4 ALEX learned index overlay"
      exports: ["AlexLearnedIndex"]
    - path: "DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/AlexModel.cs"
      provides: "CDF model for learned position prediction"
      exports: ["AlexModel", "AlexGappedArray"]
  key_links:
    - from: "AlexLearnedIndex"
      to: "BeTree"
      via: "uses Be-tree as backing store, overlays learned predictions"
      pattern: "_backingTree"
---

<objective>
Implement Level 4: ALEX learned overlay on Be-tree with gapped array leaves, CDF model training, incremental retrain, hit-rate monitoring, and automatic activation/deactivation.

Purpose: ALEX (Adaptive Learned Index Structure) uses machine-learned CDF models to predict key positions, achieving O(1) lookups on skewed distributions. It overlays the Be-tree, accelerating reads while the Be-tree handles writes.
Output: 2 files implementing the ALEX learned index as Level 4.
</objective>

<execution_context>
@C:/Users/ddamien/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/ddamien/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/phases/86-adaptive-index-engine/86-01-SUMMARY.md
@.planning/phases/86-adaptive-index-engine/86-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: ALEX CDF model and gapped array leaf structure</name>
  <files>
    DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/AlexModel.cs
  </files>
  <action>
    **AlexModel.cs**: Contains the learned CDF model and gapped array leaf.

    1. **AlexCdfModel**: Linear regression model mapping keys to positions.
       - `double Slope`, `double Intercept` — learned parameters
       - `int PredictPosition(byte[] key, int arraySize)` — converts key to double (first 8 bytes as big-endian ulong, normalized to [0,1]), applies y = slope*x + intercept, clamps to [0, arraySize-1]
       - `Train(IReadOnlyList<byte[]> sortedKeys)` — fits linear regression on key positions. Uses least-squares: slope = n*sum(xi*yi) - sum(xi)*sum(yi) / (n*sum(xi^2) - (sum(xi))^2). Handles edge cases (n<=1, all same keys).
       - `double MeanAbsoluteError` — computed during training, used to size error bounds
       - `int ErrorBound` — ceil(MAE * 1.5), defines search window around prediction

    2. **AlexGappedArray**: Fixed-size array with gaps for future insertions.
       - `(byte[]? Key, long Value)[]` backing array, `double GapRatio` (default 0.3 = 30% gaps)
       - `int Count` — number of non-null entries
       - `int Capacity` — total array size including gaps
       - **Lookup(byte[] key, int predictedPos, int errorBound)**: Exponential search from predictedPos within errorBound, then linear scan. Returns value or null.
       - **Insert(byte[] key, long value, int predictedPos)**: Place at predicted position. If occupied, shift entries to nearest gap. If no gap within threshold, trigger array expansion (double size, redistribute with gaps).
       - **Delete(byte[] key, int predictedPos, int errorBound)**: Find and null out entry (creates gap naturally).
       - **GetSortedEntries()**: Returns all non-null entries in sorted order (for retraining).
       - `double DensityRatio => Count / (double)Capacity` — triggers restructure if too high (>0.8) or too low (<0.2)

    3. **AlexInternalNode**: RMI (Recursive Model Index) node for multi-level model.
       - `AlexCdfModel Model` — predicts which child to descend to
       - `AlexNode[] Children` — either more AlexInternalNode or AlexLeafNode
       - `int NumChildren` — fan-out

    4. **AlexLeafNode**: Leaf containing gapped array + local CDF model.
       - `AlexCdfModel Model`
       - `AlexGappedArray Data`
       - `bool NeedsRetrain` flag set when error rate exceeds threshold
  </action>
  <verify>Build: `dotnet build DataWarehouse.SDK/DataWarehouse.SDK.csproj --no-restore` compiles with zero errors.</verify>
  <done>AlexCdfModel provides linear CDF prediction with training. AlexGappedArray handles gapped insertion/deletion. RMI structure supports multi-level learned routing.</done>
</task>

<task type="auto">
  <name>Task 2: ALEX learned index overlay (Level 4) with auto-activation</name>
  <files>
    DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/AlexLearnedIndex.cs
  </files>
  <action>
    **AlexLearnedIndex.cs**: Implements `IAdaptiveIndex` as Level 4. Overlays learned predictions on a Be-tree backing store.

    Constructor: Takes a `BeTree backingTree` (the Level 3 store) plus configuration.

    Architecture:
    - Maintains an RMI (2-level: one root AlexInternalNode → N AlexLeafNode leaves)
    - On construction/morph-in, bulk-loads all entries from backing tree, trains RMI
    - `CurrentLevel = MorphLevel.LearnedIndex`

    Operations:
    - **LookupAsync**: Use RMI to predict leaf, then gapped array lookup with error bounds. If found, return. If miss, fall back to backing tree lookup (and increment miss counter).
    - **InsertAsync**: Insert into backing tree first (source of truth). Then insert into ALEX gapped array at predicted position. If gapped array needs expansion or retrain, schedule async.
    - **DeleteAsync**: Delete from backing tree. Remove from gapped array.
    - **RangeQueryAsync**: Delegate to backing tree (ALEX optimizes point queries, not ranges).
    - **CountAsync**: Delegate to backing tree.

    Hit-rate monitoring:
    - Track `_hitCount` and `_missCount` with `Interlocked.Increment`
    - `HitRate => _hitCount / (double)(_hitCount + _missCount)`
    - Every 10,000 operations, check hit rate:
      - If hit rate < 0.7 and model age > 1 minute: trigger incremental retrain
      - If hit rate < 0.3 after retrain: ALEX is not beneficial, recommend demotion to Level 3

    Incremental retrain:
    - `RetrainAsync()`: Re-read entries from backing tree, retrain affected leaf models
    - Only retrain leaves whose local error has drifted (not entire RMI)
    - `_retrainLock` (SemaphoreSlim) prevents concurrent retrains

    Auto-activation/deactivation:
    - `bool IsActive` — when false, all operations delegate directly to backing tree (zero overhead)
    - Activation: when AdaptiveIndexEngine morphs to Level 4, sets IsActive = true and triggers initial training
    - Deactivation: when hit rate stays below threshold for 3 consecutive evaluation windows, sets IsActive = false and recommends Level 3

    Add `[SdkCompatibility("6.0.0", Notes = "Phase 86: AIE-03 ALEX learned index")]`.
  </action>
  <verify>Build: `dotnet build DataWarehouse.SDK/DataWarehouse.SDK.csproj --no-restore` compiles with zero errors.</verify>
  <done>ALEX learned index overlays Be-tree with CDF model predictions. Auto-trains on key distribution. Hit-rate monitoring triggers retrain or deactivation. O(1) point lookups for skewed patterns.</done>
</task>

</tasks>

<verification>
- Both files exist under `DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/`
- `dotnet build DataWarehouse.SDK/DataWarehouse.SDK.csproj` succeeds with zero errors
- AlexLearnedIndex.CurrentLevel == MorphLevel.LearnedIndex
- CDF model trains from sorted key distribution
- Hit-rate monitoring triggers retrain at configurable thresholds
</verification>

<success_criteria>
- ALEX CDF model predicts positions with bounded error on trained distributions
- Gapped arrays handle insertions without immediate restructuring
- Hit-rate monitoring auto-retrains when accuracy degrades
- ALEX auto-deactivates when not beneficial (falls back to Be-tree)
- Build passes with zero errors
</success_criteria>

<output>
After completion, create `.planning/phases/86-adaptive-index-engine/86-03-SUMMARY.md`
</output>
