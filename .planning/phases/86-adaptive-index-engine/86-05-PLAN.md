---
phase: 86-adaptive-index-engine
plan: 05
type: execute
wave: 3
depends_on: ["86-03", "86-04"]
files_modified:
  - DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/BloofiFilter.cs
  - DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/CrushPlacement.cs
  - DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/ClockSiTransaction.cs
  - DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/DistributedRoutingIndex.cs
autonomous: true
must_haves:
  truths:
    - "Bloofi hierarchical bloom reduces cross-node queries by aggregating per-shard filters"
    - "CRUSH provides deterministic shard placement without centralized lookup table"
    - "Clock-SI enables snapshot isolation across distributed shards"
    - "Distributed routing scales to 10T+ objects across cluster"
  artifacts:
    - path: "DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/DistributedRoutingIndex.cs"
      provides: "Level 6 distributed probabilistic routing"
      exports: ["DistributedRoutingIndex"]
    - path: "DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/BloofiFilter.cs"
      provides: "Hierarchical bloom filter tree"
      exports: ["BloofiFilter"]
  key_links:
    - from: "DistributedRoutingIndex"
      to: "BloofiFilter"
      via: "bloom filter check before cross-node query"
      pattern: "_bloofi\\.MayContain"
    - from: "DistributedRoutingIndex"
      to: "ClockSiTransaction"
      via: "snapshot isolation for cross-shard reads"
      pattern: "_transaction\\.BeginSnapshot"
---

<objective>
Implement Level 6: Distributed Probabilistic Routing with Bloofi hierarchical bloom filters, CRUSH shard placement, Clock-SI snapshot isolation, and cross-node AIE coordination.

Purpose: At planetary scale (10T+ objects), the index spans multiple nodes. Bloofi reduces cross-node queries by 80%+ via hierarchical bloom filter aggregation. CRUSH provides deterministic placement without a centralized table. Clock-SI enables consistent reads across shards.
Output: 4 files implementing Level 6 distributed routing.
</objective>

<execution_context>
@C:/Users/ddamien/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/ddamien/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/phases/86-adaptive-index-engine/86-04-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Bloofi hierarchical bloom filter and CRUSH shard placement</name>
  <files>
    DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/BloofiFilter.cs
    DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/CrushPlacement.cs
  </files>
  <action>
    1. **BloofiFilter.cs**: Bloom Filter Index (Bloofi) — a tree of bloom filters where each internal node's filter is the OR of its children.
       - `BloofiNode`: `byte[] Filter` (bit array), `int FilterBitCount`, `int HashCount`, `List<BloofiNode> Children`, `int NodeId` (maps to shard/node)
       - Leaf node: bloom filter for a single shard's key set
       - Internal node: OR of all descendant filters (any bit set in any child is set in parent)
       - `Add(byte[] key, int shardId)`: Set bits in leaf for shardId, propagate OR up to root
       - `IReadOnlyList<int> Query(byte[] key)`: Check root filter first (fast reject if no bits set). If root may-contain, recursively check children. Returns list of shard IDs that may contain the key. Reduces cross-node queries by only querying shards whose bloom filter indicates possible match.
       - `Remove(int shardId)`: Clear leaf, rebuild parent ORs (requires re-OR from sibling leaves)
       - `RebuildNode(BloofiNode node)`: Recompute filter as OR of children
       - Hash functions: XxHash64 with K different seeds (default K=7)
       - `double FalsePositiveRate(int itemCount)`: Theoretical FPR for given load
       - Tree structure: balanced binary tree of bloom filters. Depth = ceil(log2(shardCount)).
       - `Serialize() / Deserialize()`: For persistence in VDE region

    2. **CrushPlacement.cs**: Controlled Replication Under Scalable Hashing.
       - `CrushMap`: Hierarchical cluster topology. `CrushBucket` (root/datacenter/rack/host) with `BucketType` enum and `float Weight`.
       - `Select(byte[] key, int numReplicas, CrushMap map)`: Deterministic pseudorandom placement. For each replica, walk the hierarchy: at each level, hash(key + replica_index + bucket_id) to select weighted child. Straw2 algorithm: for each child, compute `draw = hash(key, child.id) * child.weight`, select max draw.
       - `int[] GetTargetNodes(byte[] key, int replicas = 1)`: Returns node IDs for key placement.
       - Handles node failures: if selected node is marked down, re-select from remaining (using r' = r + numReplicas as tiebreaker).
       - `AddNode(int nodeId, float weight, int parentBucketId)`: Add node to map.
       - `RemoveNode(int nodeId)`: Mark as down (minimal data movement).
       - Deterministic: same key + same map = same placement (no coordinator needed).
  </action>
  <verify>Build: `dotnet build DataWarehouse.SDK/DataWarehouse.SDK.csproj --no-restore` compiles with zero errors.</verify>
  <done>BloofiFilter provides hierarchical bloom filter tree with OR-propagation. CrushPlacement provides deterministic shard placement via weighted hash selection.</done>
</task>

<task type="auto">
  <name>Task 2: Clock-SI transactions and distributed routing index (Level 6)</name>
  <files>
    DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/ClockSiTransaction.cs
    DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/DistributedRoutingIndex.cs
  </files>
  <action>
    1. **ClockSiTransaction.cs**: Clock-based Snapshot Isolation for distributed index operations.
       - `ClockSiTimestamp`: `long PhysicalTime` (DateTimeOffset.UtcNow.Ticks), `int LogicalCounter` (Lamport-like for same-physical-time ordering)
       - `ClockSiTransaction`: `ClockSiTimestamp SnapshotTime`, `TransactionState State` (Active/Committed/Aborted), `List<WriteRecord> WriteSet`, `Guid TransactionId`
       - `BeginSnapshot()`: Captures current time as snapshot timestamp. All reads see data committed before this timestamp.
       - `Read(byte[] key, IAdaptiveIndex shard)`: Check if shard has pending writes from other transactions with commit time > snapshot. If so, wait or use snapshot version. For simplicity: read from shard, which returns latest committed version <= snapshot time.
       - `Write(byte[] key, long value)`: Buffer in write set (not applied until commit).
       - `CommitAsync()`: Assign commit timestamp (current time). Write all buffered writes to respective shards. If any shard detects write-write conflict (same key written by concurrent committed transaction with higher timestamp), abort.
       - `Abort()`: Discard write set.
       - `PrepareAsync(int shardId)`: Two-phase: prepare on each shard (check conflicts), then commit.
       - Thread-safe: `_lock` for write set mutations.

    2. **DistributedRoutingIndex.cs**: Implements `IAdaptiveIndex` as Level 6.
       - Constructor: `IReadOnlyList<IAdaptiveIndex> remoteShards`, `CrushMap crushMap`, `BloofiFilter bloofi`.
       - `CurrentLevel = MorphLevel.DistributedRouting`
       - **LookupAsync**: Check Bloofi for candidate shards. If single candidate, query directly. If multiple, query all candidates in parallel (Task.WhenAll), return first hit. If Bloofi says none, return null.
       - **InsertAsync**: Use CRUSH to determine target shard. Insert into shard. Update Bloofi leaf for that shard. If cross-shard transaction, use Clock-SI.
       - **DeleteAsync**: Bloofi query to find shard, delete. Note: bloom filter does not support removal of individual keys, so Bloofi leaf must be periodically rebuilt.
       - **RangeQueryAsync**: Fan out to all shards (no bloom filter for ranges), merge-sort results.
       - **CountAsync**: Sum across all shards.
       - **Cross-node coordination**: `DistributedMorphCoordinator` — when a remote shard needs to morph, it notifies coordinator. Coordinator ensures Bloofi is updated after morph (filter may change).

       Thread safety: Operations are inherently parallel across shards. Local state (Bloofi, CRUSH map) protected by `ReaderWriterLockSlim`.

       Add `[SdkCompatibility("6.0.0", Notes = "Phase 86: AIE-05 Distributed routing")]`.
  </action>
  <verify>Build: `dotnet build DataWarehouse.SDK/DataWarehouse.SDK.csproj --no-restore` compiles with zero errors.</verify>
  <done>DistributedRoutingIndex (Level 6) uses Bloofi for cross-node query reduction, CRUSH for deterministic placement, and Clock-SI for distributed snapshot isolation.</done>
</task>

</tasks>

<verification>
- All 4 files exist under `DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/`
- `dotnet build DataWarehouse.SDK/DataWarehouse.SDK.csproj` succeeds with zero errors
- DistributedRoutingIndex.CurrentLevel == MorphLevel.DistributedRouting
- Bloofi Query returns subset of shards (not all) for point queries
</verification>

<success_criteria>
- Bloofi hierarchical bloom filter reduces cross-node queries via OR-propagation
- CRUSH provides deterministic placement without centralized table
- Clock-SI enables snapshot isolation across distributed shards
- Level 6 handles 10T+ objects conceptually via shard routing
- Build passes with zero errors
</success_criteria>

<output>
After completion, create `.planning/phases/86-adaptive-index-engine/86-05-SUMMARY.md`
</output>
