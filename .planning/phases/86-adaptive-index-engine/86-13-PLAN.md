---
phase: 86-adaptive-index-engine
plan: 13
type: execute
wave: 4
depends_on: ["86-01"]
files_modified:
  - DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/HnswIndex.cs
  - DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/ProductQuantizer.cs
  - DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/GpuVectorKernels.cs
autonomous: true
must_haves:
  truths:
    - "CPU HNSW achieves approximate nearest neighbor with logarithmic query time"
    - "SIMD distance functions (cosine, dot-product, euclidean) via Vector256/Avx2"
    - "Product Quantization compresses vectors with ADC lookup tables"
    - "GPU path via ILGPU achieves 5x+ speedup over CPU SIMD"
    - "Transparent fallback chain: GPU -> SIMD -> scalar"
  artifacts:
    - path: "DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/HnswIndex.cs"
      provides: "HNSW graph for vector nearest-neighbor search"
      exports: ["HnswIndex"]
    - path: "DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/ProductQuantizer.cs"
      provides: "PQ compression with ADC tables"
      exports: ["ProductQuantizer"]
    - path: "DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/GpuVectorKernels.cs"
      provides: "ILGPU batch distance computation"
      exports: ["GpuVectorKernels"]
  key_links:
    - from: "HnswIndex"
      to: "GpuVectorKernels"
      via: "GPU-accelerated batch distance computation"
      pattern: "_gpuKernels\\.BatchDistance|_distanceFunc"
---

<objective>
Implement HNSW + Product Quantization with GPU acceleration: CPU path (HNSW + Vector256/Avx2 SIMD distance + PQ ADC tables), GPU path (ILGPU C# to PTX batch distance + parallel traversal), cuVS optional path, VDE Intelligence Cache storage, and transparent fallback chain.

Purpose: Vector search is essential for AI/ML workloads (embeddings, similarity search). HNSW provides state-of-the-art approximate nearest neighbor search. PQ compresses high-dimensional vectors. GPU acceleration enables massive parallelism for distance computation.
Output: 3 files implementing the vector search subsystem.
</objective>

<execution_context>
@C:/Users/ddamien/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/ddamien/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: HNSW index with SIMD distance functions and PQ compression</name>
  <files>
    DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/HnswIndex.cs
    DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/ProductQuantizer.cs
  </files>
  <action>
    1. **HnswIndex.cs**: Hierarchical Navigable Small World graph for approximate nearest neighbor search.

       Core structure:
       - `HnswNode`: `int Id`, `float[] Vector`, `List<int>[] Neighbors` (per-layer neighbor lists)
       - `int MaxLayers` (default 6), `int M` (max connections per layer, default 16), `int EfConstruction` (search width during build, default 200), `int EfSearch` (search width during query, default 50)
       - `HnswNode _entryPoint` — top-layer entry node
       - `Dictionary<int, HnswNode> _nodes`

       Build:
       - `InsertAsync(int id, float[] vector)`: Assign random level L = floor(-ln(random) * mL) where mL = 1/ln(M). Connect to M closest neighbors at each layer 0..L. Use greedy search to find candidates at each layer.
       - Layer 0: connect to M*2 neighbors (denser for better recall)

       Query:
       - `SearchAsync(float[] query, int k, int efSearch)`: Start at entry point, greedily descend layers. At layer 0, expand search to efSearch candidates via priority queue. Return k closest.
       - Returns `IReadOnlyList<(int Id, float Distance)>` sorted by distance ascending.

       Distance functions (selected via `DistanceMetric` enum: Cosine, DotProduct, Euclidean):
       - `CosineDistance(float[] a, float[] b)`: Use `Vector256<float>` with Avx2/Fma if `Avx2.IsSupported`. Compute dot product, magnitudes, 1 - dot/(magA*magB). Process 8 floats per SIMD iteration. Scalar fallback.
       - `DotProductDistance(float[] a, float[] b)`: Negative dot product (for max-inner-product search). SIMD.
       - `EuclideanDistance(float[] a, float[] b)`: Sum of squared differences, sqrt. SIMD.
       - All distance functions: `[MethodImpl(MethodImplOptions.AggressiveInlining)]`

       Persistence: `Serialize(Stream)` / `Deserialize(Stream)` — writes node count, vectors, neighbor lists. For VDE storage: serialize to VDE Intelligence Cache region blocks.

    2. **ProductQuantizer.cs**: Vector compression via Product Quantization.
       - Splits D-dimensional vector into M sub-vectors of D/M dimensions (default M=8, D=128 -> 16 dims per sub-vector)
       - Each sub-vector quantized to nearest of K centroids (default K=256, 1 byte per sub-vector)
       - **Train(float[][] vectors)**: k-means clustering on each sub-vector partition. Produces `float[M][K][D/M]` codebook.
       - **Encode(float[] vector)**: Returns `byte[M]` — centroid indices for each sub-vector.
       - **ADC (Asymmetric Distance Computation)**: Pre-compute distance from query sub-vectors to all centroids -> `float[M][K]` lookup table. Compressed distance = sum of table lookups. O(M) per candidate vs O(D) for exact.
       - `ComputeAdcTable(float[] query)`: Returns distance lookup table.
       - `float AdcDistance(byte[] code, float[,] adcTable)`: Sum table[m][code[m]] for each sub-vector.
       - Compression ratio: D*4 bytes -> M bytes (e.g., 512 bytes -> 8 bytes = 64x)
       - `Serialize/Deserialize` for codebook persistence.

    Add `[SdkCompatibility("6.0.0", Notes = "Phase 86: AIE-13 HNSW+PQ")]`.
  </action>
  <verify>Build: `dotnet build DataWarehouse.SDK/DataWarehouse.SDK.csproj --no-restore` compiles with zero errors.</verify>
  <done>HNSW graph provides approximate nearest neighbor search with SIMD-accelerated distance functions. ProductQuantizer compresses vectors 64x with ADC lookup tables.</done>
</task>

<task type="auto">
  <name>Task 2: GPU vector kernels via ILGPU with transparent fallback</name>
  <files>
    DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/GpuVectorKernels.cs
  </files>
  <action>
    **GpuVectorKernels.cs**: GPU-accelerated batch distance computation using ILGPU (C# to PTX compiler).

    Note: ILGPU is a C# GPU computing library that compiles C# to CUDA PTX. Since it may not be a project dependency, implement as optional with graceful degradation.

    1. **IGpuVectorAccelerator** interface:
       - `float[] BatchCosineDistance(float[] query, float[][] candidates)` — compute distances to all candidates in parallel
       - `float[] BatchEuclideanDistance(float[] query, float[][] candidates)`
       - `(int[] Indices, float[] Distances) TopK(float[] query, float[][] candidates, int k)` — find k nearest
       - `bool IsAvailable { get; }`
       - `void Dispose()`

    2. **IlgpuVectorAccelerator**: ILGPU implementation of `IGpuVectorAccelerator`.
       - Static `IsAvailable`: Try to create ILGPU context and detect CUDA device. Catches exceptions gracefully.
       - If available: create `Context`, `Accelerator` (CudaAccelerator preferred, falls back to CPU accelerator for testing)
       - **BatchCosineDistance kernel**: Each GPU thread computes distance for one candidate vector. Shared memory for query vector. Reduction for dot product within warp.
       - Memory management: pre-allocate device buffers for max batch size. Reuse across calls.
       - **TopK**: Compute all distances on GPU, then partial sort on CPU (GPU sort complex for small K).

    3. **CuvsVectorAccelerator**: Optional cuVS (NVIDIA) path.
       - `[LibraryImport("libcuvs")]` bindings for cuvs_search, cuvs_build
       - Static `IsAvailable`: `NativeLibrary.TryLoad("libcuvs", out _)`
       - Wraps cuVS HNSW build and search (offloads entire HNSW to GPU)
       - Fallback: if not available, use IlgpuVectorAccelerator

    4. **VectorAcceleratorFactory**: Transparent fallback chain.
       - `static IGpuVectorAccelerator Create()`:
         1. Try CuvsVectorAccelerator (highest performance, full GPU HNSW)
         2. Try IlgpuVectorAccelerator (GPU batch distance)
         3. Return `SimdVectorAccelerator` (CPU SIMD — always available)
       - `SimdVectorAccelerator`: Uses the SIMD distance functions from HnswIndex as `IGpuVectorAccelerator` adapter (no GPU, just parallel CPU).

    Thread safety: GPU accelerators are typically single-threaded (one CUDA stream). Wrap with SemaphoreSlim(1,1) for thread-safe access. Batch submissions amortize the serialization cost.

    Add `[SdkCompatibility("6.0.0", Notes = "Phase 86: AIE-13 GPU vector kernels")]`.
  </action>
  <verify>Build: `dotnet build DataWarehouse.SDK/DataWarehouse.SDK.csproj --no-restore` compiles with zero errors.</verify>
  <done>GPU vector kernels provide batch distance computation via ILGPU/cuVS with transparent fallback to CPU SIMD. Factory method selects best available accelerator.</done>
</task>

</tasks>

<verification>
- All 3 files exist under `DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/`
- `dotnet build DataWarehouse.SDK/DataWarehouse.SDK.csproj` succeeds with zero errors
- HNSW distance functions use Vector256 when Avx2.IsSupported
- ProductQuantizer ADC table enables O(M) distance instead of O(D)
- VectorAcceleratorFactory.Create() returns SimdVectorAccelerator on machines without GPU
</verification>

<success_criteria>
- HNSW provides ANN search with logarithmic query time
- SIMD distance functions (cosine/dot/euclidean) via Vector256/Avx2
- PQ compresses vectors 64x with ADC lookup tables
- Transparent fallback: cuVS -> ILGPU -> SIMD -> scalar
- Build passes with zero errors
</success_criteria>

<output>
After completion, create `.planning/phases/86-adaptive-index-engine/86-13-SUMMARY.md`
</output>
