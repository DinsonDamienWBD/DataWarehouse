---
phase: 86-adaptive-index-engine
plan: 11
type: execute
wave: 2
depends_on: ["86-01"]
files_modified:
  - DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/ExtendibleHashTable.cs
  - DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/ExtendibleHashBucket.cs
autonomous: true
must_haves:
  truths:
    - "Extendible hash table grows from 1K to 1B+ inodes without rebuild"
    - "O(1) amortized lookup via directory + bucket structure"
    - "Dynamic growth doubles directory only when bucket splits require new bit"
    - "On-disk persistence in VDE region supports crash recovery"
  artifacts:
    - path: "DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/ExtendibleHashTable.cs"
      provides: "Extendible hashing inode table"
      exports: ["ExtendibleHashTable"]
    - path: "DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/ExtendibleHashBucket.cs"
      provides: "Hash bucket with local depth tracking"
      exports: ["ExtendibleHashBucket"]
  key_links:
    - from: "ExtendibleHashTable"
      to: "IBlockDevice"
      via: "persists directory and buckets to VDE blocks"
      pattern: "_device\\.(Read|Write)BlockAsync"
---

<objective>
Implement extendible hashing inode table: directory/bucket structure, dynamic growth, on-disk persistence in VDE region, migration from fixed linear array, and trillion-object support.

Purpose: The current fixed-size inode table limits VDE scalability. Extendible hashing provides O(1) amortized lookup that scales from 1K to 1B+ inodes by dynamically growing the directory (doubling) only when needed, never requiring a full table rebuild.
Output: 2 files implementing the extendible hash table.
</objective>

<execution_context>
@C:/Users/ddamien/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/ddamien/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@DataWarehouse.SDK/VirtualDiskEngine/BlockAllocation/IBlockAllocator.cs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extendible hash bucket and directory structure</name>
  <files>
    DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/ExtendibleHashBucket.cs
    DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/ExtendibleHashTable.cs
  </files>
  <action>
    1. **ExtendibleHashBucket.cs**: Fixed-size bucket holding inode entries.
       - `int LocalDepth` — number of hash bits this bucket uses (starts at 0, grows on split)
       - `int Capacity` — max entries per bucket (derived from block size: `(blockSize - HeaderSize) / EntrySize`)
       - `List<(ulong InodeId, long BlockNumber)> Entries` — stored entries
       - `long BlockNumber` — the VDE block storing this bucket
       - `bool IsFull => Entries.Count >= Capacity`
       - **Split()**: Returns two new buckets. Entries redistributed based on the (LocalDepth+1)th bit of hash. New buckets have LocalDepth = old + 1.
       - **Serialize(int blockSize)**: Header [LocalDepth:4][Count:4], then entries [InodeId:8][BlockNumber:8] each. Zero-pad remainder.
       - **Deserialize(byte[] data)**: Inverse of Serialize.

    2. **ExtendibleHashTable.cs**: The directory + bucket extendible hash table.
       - `int GlobalDepth` — number of hash bits used for directory indexing (starts at 1, meaning 2 directory slots)
       - `long[] _directory` — array of 2^GlobalDepth entries, each pointing to a bucket block number. Multiple directory entries can point to same bucket (when LocalDepth < GlobalDepth).
       - Hash function: `XxHash64(inodeId bytes)` for uniform distribution.

       **Lookup(ulong inodeId)**:
       - Hash inodeId, take top GlobalDepth bits as directory index
       - Read bucket at _directory[index]
       - Linear scan bucket entries for match
       - O(1) amortized (single block read)

       **Insert(ulong inodeId, long blockNumber)**:
       - Hash, find bucket, check if exists (update if so)
       - If bucket not full, append entry, write bucket block
       - If bucket full, split:
         a. Create two new buckets via bucket.Split()
         b. If bucket.LocalDepth == GlobalDepth, double directory (GlobalDepth++)
         c. Update directory entries: entries that pointed to old bucket now point to appropriate new bucket based on the new bit
         d. Write new buckets and directory to disk
         e. WAL-protect: write WAL entry before modifying directory

       **Delete(ulong inodeId)**:
       - Find bucket, remove entry, write bucket
       - Optionally merge with sibling bucket if both below threshold (deferred)

       **Persistence**:
       - Directory stored in dedicated VDE region blocks. Block 0 of region: [GlobalDepth:4][BucketCount:8][DirectoryEntries:8*2^GlobalDepth]
       - If directory exceeds one block, spans multiple consecutive blocks
       - `SaveAsync(IBlockDevice device, long regionStartBlock)`: Serialize and write
       - `LoadAsync(IBlockDevice device, long regionStartBlock)`: Read and deserialize

       **Migration from linear array**:
       - `static ExtendibleHashTable MigrateFromLinearArray(IReadOnlyList<(ulong InodeId, long BlockNumber)> entries, IBlockDevice device, IBlockAllocator allocator, int blockSize)`: Bulk-load existing inodes into extendible hash table. Start with GlobalDepth = ceil(log2(entries.Count / bucketCapacity)), insert all entries.

       **Statistics**: `long EntryCount`, `int BucketCount`, `double LoadFactor => EntryCount / (double)(BucketCount * BucketCapacity)`, `double DirectorySizeBytes => 8 * (1L << GlobalDepth)`

       Thread safety: `ReaderWriterLockSlim` — concurrent reads, single writer (directory doubling is exclusive).

       Add `[SdkCompatibility("6.0.0", Notes = "Phase 86: AIE-11 Extendible hashing")]`.
  </action>
  <verify>Build: `dotnet build DataWarehouse.SDK/DataWarehouse.SDK.csproj --no-restore` compiles with zero errors.</verify>
  <done>ExtendibleHashTable provides O(1) amortized inode lookup with dynamic growth via directory doubling. Buckets split independently. On-disk persistence in VDE region blocks. Migration from linear array supported.</done>
</task>

</tasks>

<verification>
- Both files exist under `DataWarehouse.SDK/VirtualDiskEngine/AdaptiveIndex/`
- `dotnet build DataWarehouse.SDK/DataWarehouse.SDK.csproj` succeeds with zero errors
- Directory doubles only when bucket split requires new bit (LocalDepth == GlobalDepth)
- Hash function uses XxHash64 for uniform distribution
</verification>

<success_criteria>
- Extendible hash table supports O(1) amortized lookup
- Dynamic growth from 1K to 1B+ inodes without rebuild
- On-disk format persists directory and buckets in VDE region
- Migration path from existing linear inode array
- Build passes with zero errors
</success_criteria>

<output>
After completion, create `.planning/phases/86-adaptive-index-engine/86-11-SUMMARY.md`
</output>
