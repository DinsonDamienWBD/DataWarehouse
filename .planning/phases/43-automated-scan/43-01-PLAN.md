---
phase: 43
plan: 43-01
title: "Automated Pattern Scan: Code Quality"
depends_on: []
---

# Plan 43-01: Automated Pattern Scan: Code Quality

## Goal
Scan ALL 71 projects in the DataWarehouse solution for common code quality anti-patterns that indicate technical debt, incomplete implementations, or maintainability risks. Generate a comprehensive audit report with prioritized findings.

## Approach

### 1. Define Anti-Pattern Search Signatures

**Sync-over-Async Blocking**
- `.Result` on Task/ValueTask
- `.Wait()` on Task/ValueTask
- `.GetAwaiter().GetResult()` on Task/ValueTask
- Context: Identify file, line, method signature, calling context

**NotImplementedException**
- `throw new NotImplementedException`
- `NotImplementedException(` with any message
- Context: Method signature, class name, plugin name

**TODO/HACK/FIXME Comments**
- `// TODO:`, `// HACK:`, `// FIXME:`
- `/* TODO */`, `/* HACK */`, `/* FIXME */`
- Context: Full comment text, surrounding code

**Placeholder Exceptions**
- `throw new Exception("` (generic exception with string)
- `throw new InvalidOperationException("Not implemented`
- `throw new NotSupportedException("` as placeholder
- Context: Method signature, exception message

**Unbounded Collections**
- `new List<>()` without capacity hint in hot paths
- `new Dictionary<,>()` without capacity in constructors/loops
- `new HashSet<>()` without capacity
- Context: Scope (constructor/loop/hot path), estimated usage

**Missing Cancellation Support**
- `async` methods without `CancellationToken` parameter
- Async methods that don't pass token to child calls
- Context: Method signature, call depth, public/internal visibility

**Missing Dispose Patterns**
- Types implementing `IDisposable` used without `using` statement
- `IDisposable` fields without disposal in containing type
- Manual stream/reader/writer allocation without using
- Context: Variable scope, type name, containing class

### 2. Scan Execution Strategy

**Phase 1: Grep-based Pattern Matching**
- Use `Grep` tool with regex patterns for each anti-pattern
- Scan all `.cs` files across all 71 projects
- Collect line numbers, file paths, code context (-B 2 -A 2)

**Phase 2: LSP-based Semantic Analysis**
- Use `lsp_workspace_symbols` to find all async methods
- Use `lsp_diagnostics` on each project for compiler warnings
- Cross-reference with pattern matches for false positive elimination

**Phase 3: Call Graph Analysis**
- For sync-over-async: trace back to identify blocking call chains
- For missing cancellation: identify public API surface vs internal usage
- For unbounded collections: estimate collection growth based on usage

### 3. Severity Classification

**P0 (Critical)** - Blocks production readiness:
- Sync-over-async in public API methods
- NotImplementedException in production code paths
- Placeholder exceptions in core domain logic
- Missing cancellation in long-running operations

**P1 (High)** - Technical debt requiring fix before v4.0:
- TODO/HACK comments without tracking issue reference
- Unbounded collections in high-frequency paths
- Missing dispose in resource-intensive code

**P2 (Medium)** - Quality improvement, fix in maintenance:
- Async methods without cancellation in internal helpers
- Unbounded collections in low-frequency paths
- Generic exceptions in edge case handling

### 4. Output Format

Generate `AUDIT-FINDINGS-01-quality.md` with structure:
```
# Code Quality Audit Findings - Phase 43-01
Generated: [timestamp]
Scan Coverage: 71 projects, [N] .cs files

## Executive Summary
- Total Findings: [N]
- P0 Critical: [N]
- P1 High: [N]
- P2 Medium: [N]

## P0 Critical Findings

### P0-001: Sync-over-Async in [PluginName].[MethodName]
**Location**: `Path/To/File.cs:123`
**Pattern**: `.Result` on async operation
**Impact**: Thread pool starvation, potential deadlock
**Code**:
```csharp
[3 lines of context]
```
**Recommendation**: Convert to async/await or use ConfigureAwait(false)

[... repeat for each P0 finding ...]

## P1 High Findings
[... same format ...]

## P2 Medium Findings
[... same format ...]

## Appendix: Statistics by Category
- Sync-over-Async: [N] findings ([P0/P1/P2] breakdown)
- NotImplementedException: [N] findings
- TODO/HACK/FIXME: [N] findings
- Placeholder Exceptions: [N] findings
- Unbounded Collections: [N] findings
- Missing Cancellation: [N] findings
- Missing Dispose: [N] findings

## Appendix: Findings by Project
[Table: Project | P0 | P1 | P2 | Total]
```

## Scope

**In Scope**:
- All 71 projects under `DataWarehouse.sln`
- All `.cs` source files (exclude obj/, bin/, generated/)
- All production code and test code (separate stats)
- Pattern matching + semantic analysis

**Out of Scope**:
- Performance profiling (covered in Phase 42)
- Security patterns (covered in Plan 43-02)
- Build/test execution (covered in Plan 43-03)
- Fixing findings (covered in Plan 43-04)

**Project List** (verify against solution):
- DataWarehouse.Kernel
- DataWarehouse.SDK + all base classes
- 60+ plugins in `Plugins/DataWarehouse.Plugins.*`
- All test projects

## Success Criteria

1. **Complete Coverage**: Every .cs file in all 71 projects scanned
2. **Zero False Negatives**: All anti-patterns detected (validate with manual spot-check on 5 known issues)
3. **Accurate Severity**: P0/P1/P2 assignment matches production impact
4. **Actionable Output**: Each finding has file, line, context, recommendation
5. **Prioritized Remediation**: P0 findings listed first, grouped by plugin
6. **Statistics**: Aggregate counts by category, project, severity
7. **Verification**: Cross-check with known Phase 31.1/41.1 cleanup work

## Output

**Primary Artifact**:
- `.planning/phases/43-automated-scan/AUDIT-FINDINGS-01-quality.md`

**Supporting Data**:
- `.planning/phases/43-automated-scan/scan-results-quality.json` (raw structured data)
- `.planning/phases/43-automated-scan/scan-stats-quality.csv` (pivot table for analysis)

**Validation**:
- Minimum 50 findings expected (based on known TODO/HACK comments)
- If findings < 10, re-validate scan completeness
- Spot-check 10 random findings for accuracy

**Handoff to 43-04**:
- AUDIT-FINDINGS-01-quality.md becomes input to Plan 43-04 (Fix Wave)
- P0 findings MUST be resolved before v4.0 certification
- P1 findings SHOULD be resolved, defer to v4.1 only if low risk
- P2 findings tracked in backlog for v4.x maintenance
