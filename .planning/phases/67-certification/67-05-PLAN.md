---
phase: 67-certification
plan: 05
type: execute
wave: 2
depends_on: ["67-01"]
files_modified:
  - .planning/phases/67-certification/67-05-BENCHMARKS.md
autonomous: true

must_haves:
  truths:
    - "Performance benchmarks are published for core hot paths"
    - "VDE write/read throughput is measured"
    - "Compression algorithm performance is measured across all algorithms"
    - "Encryption performance is measured for key algorithms"
    - "Message bus throughput is measured"
    - "All benchmarks are reproducible (methodology documented)"
    - "Performance bottlenecks are identified with root causes"
  artifacts:
    - path: ".planning/phases/67-certification/67-05-BENCHMARKS.md"
      provides: "Performance benchmark suite results"
      contains: "Benchmark"
  key_links:
    - from: "VDE write path"
      to: "SemaphoreSlim concurrency"
      via: "Write lock analysis"
      pattern: "SemaphoreSlim|_writeLock"
    - from: "Compression strategies"
      to: "Quality/speed tradeoffs"
      via: "Configuration parameters"
      pattern: "CompressionLevel|Quality"
---

<objective>
Create and run a reproducible performance benchmark suite measuring core hot paths: VDE I/O, compression, encryption, message bus, and strategy dispatch.

Purpose: Produce published, reproducible performance numbers that can be compared to industry competitors. Identify bottlenecks with root causes.
Output: `.planning/phases/67-certification/67-05-BENCHMARKS.md`
</objective>

<execution_context>
@C:/Users/ddamien/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/ddamien/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/51-certification-authority/v4.5-CERTIFICATION.md
@.planning/phases/67-certification/67-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Static Performance Analysis and Bottleneck Identification</name>
  <files>.planning/phases/67-certification/67-05-BENCHMARKS.md</files>
  <action>
    Since this is a read-only audit phase, perform STATIC performance analysis rather than runtime benchmarks. Analyze the code for performance characteristics:

    **A. VDE (Virtual Disk Engine) Performance Analysis:**

    1. Find VDE write path -- locate SemaphoreSlim, lock patterns, serialization points
    2. Analyze block allocation: BitmapAllocator, ExtentTree -- are they O(1), O(log n), O(n)?
    3. Analyze WAL (WriteAheadLog) -- sequential write? fsync frequency?
    4. Check CowBlockManager for copy overhead
    5. Identify: Is the single-writer lock still present? (v4.5 flagged this as P0)
    6. Analyze read path parallelism -- can reads proceed during writes?

    **B. Compression Performance Profile:**

    1. For each compression algorithm (Brotli, Zstd, LZ4, Snappy, Deflate, etc.):
       - Is quality/level configurable? (v4.5 flagged Brotli Q11 hardcoded)
       - What is the default level?
       - Are there async streaming overloads?
    2. Identify any algorithms with hardcoded expensive settings
    3. Check for buffer pooling (ArrayPool usage in compression paths)

    **C. Encryption Performance Profile:**

    1. For key algorithms (AES-GCM, ChaCha20-Poly1305, CRYSTALS-Kyber/Dilithium):
       - Hardware acceleration detection (AES-NI, AVX)
       - Key caching / session key reuse
       - Buffer management (SecureMemory, pooling)
    2. Check PQC implementations for known performance pitfalls

    **D. Message Bus Throughput Analysis:**

    1. Find message bus implementation (in-process vs distributed)
    2. Analyze dispatch pattern: synchronous? async? batched?
    3. Count average subscriber count per topic
    4. Check for backpressure mechanisms
    5. Identify serialization overhead (JSON? binary? zero-copy?)

    **E. Strategy Dispatch Overhead:**

    1. How are strategies resolved? (DI? dictionary lookup? reflection?)
    2. Is there caching of strategy instances?
    3. What is the overhead per dispatch (estimated from code patterns)?

    **F. Memory Analysis:**

    1. Search for large allocation patterns (new byte[], new List<> without capacity)
    2. ArrayPool adoption rate
    3. Span<T> / Memory<T> usage in hot paths
    4. IDisposable compliance in resource-heavy paths

    **G. Concurrency Analysis:**

    1. Lock contention points (SemaphoreSlim, lock, Monitor, ReaderWriterLockSlim)
    2. Async patterns -- any sync-over-async remaining?
    3. Thread pool starvation risks (blocking calls in async context)
    4. CancellationToken propagation in long-running operations

    Write `.planning/phases/67-certification/67-05-BENCHMARKS.md` with:
    - Executive summary with overall performance grade
    - VDE analysis: write throughput estimate, read throughput estimate, bottleneck identification
    - Compression profile table: Algorithm | Default Level | Configurable | Async | Buffer Pooled | Estimate
    - Encryption profile table: Algorithm | HW Accel | Key Cache | Secure Mem | Estimate
    - Message bus analysis: dispatch pattern, throughput estimate, bottlenecks
    - Memory efficiency grade
    - Concurrency grade
    - Top 10 performance bottlenecks ranked by impact
    - Comparison to v4.5 (were P0-11, P0-12 fixed?)
    - Recommendations for competitive parity (what would be needed to match MinIO/Ceph throughput)
    - PASS/FAIL verdict
  </action>
  <verify>
    Analysis covers all 7 areas (VDE, compression, encryption, bus, dispatch, memory, concurrency). Top 10 bottlenecks are identified with specific file:line references. Audit document exists with verdicts.
  </verify>
  <done>
    67-05-BENCHMARKS.md exists with static performance analysis, bottleneck ranking, and comparison to v4.5 baseline. All claims backed by code references.
  </done>
</task>

</tasks>

<verification>
- VDE write path analyzed for serialization points
- Compression algorithms checked for configurable levels
- Bus throughput characteristics documented
- Memory/concurrency patterns analyzed
- Top 10 bottlenecks identified
</verification>

<success_criteria>
Static performance analysis produces evidence-based performance profile. Bottlenecks identified with specific code references. Comparison to v4.5 shows whether P0-11 (Brotli) and P0-12 (ORSet) are resolved. Honest assessment of competitive position on performance.
</success_criteria>

<output>
After completion, create `.planning/phases/67-certification/67-05-SUMMARY.md`
</output>
