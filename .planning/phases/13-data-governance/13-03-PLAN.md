---
phase: 13-data-governance
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - Plugins/DataWarehouse.Plugins.UltimateDataQuality/Strategies/PredictiveQuality/PredictiveQualityStrategies.cs
  - Metadata/TODO.md
autonomous: true
must_haves:
  truths:
    - "5 predictive quality strategies (B3.1-B3.5) compile and are discoverable by DataQualityStrategyRegistry"
    - "Each strategy extends DataQualityStrategyBase with unique StrategyId and production-ready implementations"
    - "QualityAnticipatorStrategy predicts quality issues using moving average and standard deviation thresholds"
    - "DataDriftDetectorStrategy detects distribution drift using Population Stability Index (PSI) calculation"
    - "AnomalousDataFlagStrategy flags anomalies using Z-score and IQR-based outlier detection"
    - "QualityTrendAnalyzerStrategy analyzes quality trends using linear regression over time-series data"
    - "RootCauseAnalyzerStrategy traces quality issues to root causes using correlation analysis across data dimensions"
    - "TODO.md sub-tasks 146.B3.1-146.B3.5 are marked [x]"
  artifacts:
    - path: "Plugins/DataWarehouse.Plugins.UltimateDataQuality/Strategies/PredictiveQuality/PredictiveQualityStrategies.cs"
      provides: "5 sealed strategy classes extending DataQualityStrategyBase"
      contains: "QualityAnticipatorStrategy"
  key_links:
    - from: "PredictiveQualityStrategies.cs"
      to: "DataQualityStrategyBase"
      via: "class inheritance"
      pattern: "DataQualityStrategyBase"
    - from: "PredictiveQualityStrategies.cs"
      to: "DataQualityStrategyRegistry"
      via: "auto-discovery from assembly"
      pattern: "sealed class.*: DataQualityStrategyBase"
---

<objective>
Implement 5 Predictive Quality strategies (T146.B3.1-B3.5) in UltimateDataQuality plugin.

Purpose: These AI-native quality strategies provide industry-first capabilities for predicting quality issues before they occur, detecting data drift, flagging anomalies, analyzing quality trends, and identifying root causes -- all using statistical and heuristic methods with no external AI dependency.

Output: PredictiveQualityStrategies.cs with 5 production-ready sealed strategy classes in a new PredictiveQuality subfolder.
</objective>

<execution_context>
@C:/Users/ddamien/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/ddamien/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/13-data-governance/13-RESEARCH.md
@Plugins/DataWarehouse.Plugins.UltimateDataQuality/DataQualityStrategyBase.cs
@Plugins/DataWarehouse.Plugins.UltimateDataQuality/Strategies/Monitoring/MonitoringStrategies.cs
@Metadata/CLAUDE.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement 5 Predictive Quality strategies in PredictiveQualityStrategies.cs</name>
  <files>Plugins/DataWarehouse.Plugins.UltimateDataQuality/Strategies/PredictiveQuality/PredictiveQualityStrategies.cs</files>
  <action>
Create directory `Plugins/DataWarehouse.Plugins.UltimateDataQuality/Strategies/PredictiveQuality/` and file `PredictiveQualityStrategies.cs` with namespace `DataWarehouse.Plugins.UltimateDataQuality.Strategies.PredictiveQuality`.

Use `using System.Collections.Concurrent;` and `using System.Text.Json;`. Each strategy extends `DataQualityStrategyBase` which provides metadata properties (StrategyId, DisplayName, Category, Capabilities, SemanticDescription, Tags). These strategies also include public methods for their predictive operations.

**Strategy 1: QualityAnticipatorStrategy**
- StrategyId: `"predictive-anticipator"`
- DisplayName: `"Quality Anticipator"`
- Category: `DataQualityCategory.Monitoring`
- Capabilities: SupportsAsync=true, SupportsBatch=true, SupportsStreaming=true, SupportsDistributed=false, SupportsIncremental=true
- SemanticDescription: "Predicts quality issues before they occur by analyzing metric trends using exponential moving averages and standard deviation breach detection."
- Tags: `["predictive", "anticipation", "early-warning", "trend-detection", "industry-first"]`
- Private fields: `ConcurrentDictionary<string, List<QualityMeasurement>> _metricHistory` (stores time-series of quality measurements), `ConcurrentDictionary<string, QualityThresholdConfig> _thresholds`
- Define internal records: `QualityMeasurement(string MetricName, double Value, DateTimeOffset Timestamp)`, `QualityThresholdConfig(double WarningStdDevs, double CriticalStdDevs)`, `QualityPrediction(string MetricName, double PredictedValue, double Confidence, string Severity, string Reason, DateTimeOffset PredictionTime)`
- Public methods:
  - `RecordMetric(string metricName, double value)` -> append to history with current timestamp
  - `SetThreshold(string metricName, double warningStdDevs = 2.0, double criticalStdDevs = 3.0)` -> configure thresholds
  - `PredictIssues(string metricName)` -> if fewer than 5 data points, return empty. Calculate mean and stdDev of last 20 measurements. Compute exponential moving average (EMA with alpha=0.3) of last 10 points. If EMA deviates from mean by more than warningStdDevs * stdDev, predict "Warning". If by criticalStdDevs, predict "Critical". Compute confidence = 1.0 - (1.0 / Math.Sqrt(dataPointCount)). Return QualityPrediction.
  - `GetTrend(string metricName, int windowSize = 10)` -> return "improving" if last windowSize mean > previous windowSize mean, "degrading" if less, "stable" otherwise (use 5% tolerance)

**Strategy 2: DataDriftDetectorStrategy**
- StrategyId: `"predictive-drift-detector"`
- DisplayName: `"Data Drift Detector"`
- Category: `DataQualityCategory.Monitoring`
- Capabilities: SupportsAsync=true, SupportsBatch=true, SupportsStreaming=true, SupportsDistributed=true, SupportsIncremental=true
- SemanticDescription: "Detects when data characteristics change significantly from baseline using Population Stability Index (PSI) and Kolmogorov-Smirnov-inspired distribution comparison."
- Tags: `["drift-detection", "distribution-shift", "psi", "baseline-comparison", "industry-first"]`
- Private fields: `ConcurrentDictionary<string, double[]> _baselines` (reference distribution histograms), `ConcurrentDictionary<string, double[]> _currentDistributions`
- Define internal records: `DriftReport(string ColumnName, double PsiScore, string DriftLevel, double[] BaselineDistribution, double[] CurrentDistribution, DateTimeOffset DetectedAt)`, `DriftLevel` constants: "none" (PSI < 0.1), "minor" (0.1-0.25), "significant" (> 0.25)
- Public methods:
  - `SetBaseline(string columnName, double[] values)` -> compute histogram (10 bins) from values, store as baseline distribution
  - `UpdateCurrent(string columnName, double[] values)` -> compute histogram from current values, store as current
  - `DetectDrift(string columnName)` -> if no baseline or no current, return null. Compute PSI = sum over bins of (current_i - baseline_i) * ln(current_i / baseline_i), where each bin proportion is max(0.0001, proportion) to avoid log(0). Classify drift level. Return DriftReport.
  - Private helper `ComputeHistogram(double[] values, int bins = 10)` -> returns double[] of bin proportions. Find min/max, divide into equal bins, count values per bin, normalize to proportions.

**Strategy 3: AnomalousDataFlagStrategy**
- StrategyId: `"predictive-anomaly-flag"`
- DisplayName: `"Anomalous Data Flagger"`
- Category: `DataQualityCategory.Scoring`
- Capabilities: SupportsAsync=true, SupportsBatch=true, SupportsStreaming=true, SupportsDistributed=false, SupportsIncremental=true
- SemanticDescription: "Automatically flags unusual data using Z-score analysis and IQR-based outlier detection. Supports both univariate and multivariate anomaly detection."
- Tags: `["anomaly-detection", "outlier-flagging", "z-score", "iqr", "industry-first"]`
- Private fields: `ConcurrentDictionary<string, List<double>> _columnValues`
- Define internal records: `AnomalyReport(string ColumnName, IReadOnlyList<AnomalyFlag> Flags, int TotalValues, int AnomalyCount, double AnomalyRate)`, `AnomalyFlag(int Index, double Value, double ZScore, string Method, string Severity)`
- Public methods:
  - `AddValues(string columnName, double[] values)` -> append to _columnValues
  - `DetectAnomalies(string columnName, double zScoreThreshold = 3.0)` -> retrieve all values. Compute mean and stdDev. For each value, compute zScore = |value - mean| / stdDev. If zScore > threshold -> flag as anomaly. Also compute IQR method: sort values, Q1 = 25th percentile, Q3 = 75th percentile, IQR = Q3-Q1, lower = Q1 - 1.5*IQR, upper = Q3 + 1.5*IQR. Values outside -> flag. Combine both methods: flagged by both = "Critical", flagged by one = "Warning". Return AnomalyReport.
  - Private helper `Percentile(List<double> sorted, double percentile)` -> linear interpolation at the given percentile

**Strategy 4: QualityTrendAnalyzerStrategy**
- StrategyId: `"predictive-trend-analyzer"`
- DisplayName: `"Quality Trend Analyzer"`
- Category: `DataQualityCategory.Reporting`
- Capabilities: SupportsAsync=true, SupportsBatch=true, SupportsStreaming=false, SupportsDistributed=false, SupportsIncremental=true
- SemanticDescription: "Analyzes quality trends over time using linear regression to detect improving, degrading, or cyclic quality patterns and forecast future quality scores."
- Tags: `["trend-analysis", "regression", "forecasting", "time-series", "industry-first"]`
- Private fields: `ConcurrentDictionary<string, List<TrendDataPoint>> _trendData`
- Define internal records: `TrendDataPoint(double Value, DateTimeOffset Timestamp)`, `TrendAnalysis(string MetricName, double Slope, double Intercept, double RSquared, string Direction, double ForecastNext, IReadOnlyList<TrendDataPoint> DataPoints)`
- Public methods:
  - `RecordDataPoint(string metricName, double value)` -> add to _trendData with current timestamp
  - `AnalyzeTrend(string metricName)` -> if fewer than 3 data points, return null. Perform simple linear regression: convert timestamps to sequential indices (0, 1, 2, ...). Compute slope and intercept using least squares (sum of x*y, sum of x, sum of y, sum of x^2). Compute R-squared. Direction: slope > 0.01 -> "improving", slope < -0.01 -> "degrading", else "stable". Forecast next value = slope * (n) + intercept. Return TrendAnalysis.
  - `GetSeasonality(string metricName, int period)` -> compute autocorrelation at the given lag period. If autocorrelation > 0.5, return true (cyclic pattern detected).

**Strategy 5: RootCauseAnalyzerStrategy**
- StrategyId: `"predictive-root-cause"`
- DisplayName: `"Root Cause Analyzer"`
- Category: `DataQualityCategory.Reporting`
- Capabilities: SupportsAsync=true, SupportsBatch=true, SupportsStreaming=false, SupportsDistributed=true, SupportsIncremental=false
- SemanticDescription: "Traces quality issues to their root causes by analyzing correlations between quality dimensions, identifying temporal patterns, and ranking contributing factors."
- Tags: `["root-cause", "correlation", "contributing-factors", "causal-analysis", "industry-first"]`
- Private fields: `ConcurrentDictionary<string, List<QualityEvent>> _events`
- Define internal records: `QualityEvent(string EventId, string Dimension, string Description, double Severity, DateTimeOffset Timestamp, Dictionary<string, string>? Attributes)`, `RootCauseReport(string IssueDescription, IReadOnlyList<CauseCandidate> Candidates)`, `CauseCandidate(string Dimension, double CorrelationScore, int OccurrenceCount, string Evidence)`
- Public methods:
  - `RecordEvent(string dimension, string description, double severity, Dictionary<string, string>? attributes = null)` -> add to _events with generated EventId (Guid.NewGuid())
  - `AnalyzeRootCause(string targetDimension, TimeSpan lookbackWindow)` -> find all events in targetDimension within lookbackWindow. For each OTHER dimension, count events that occurred within +/- 5 minutes of target events. Compute correlation score = coOccurrenceCount / targetEventCount. Rank by correlation score descending. Return RootCauseReport with top candidates (correlation > 0.3).
  - `GetCorrelationMatrix(IReadOnlyList<string> dimensions)` -> for each pair of dimensions, compute temporal correlation (co-occurrence within 5-minute windows) and return as Dictionary<(string, string), double>

All classes MUST be `sealed`. All must have XML `<summary>` and `<remarks>` docs referencing T146.B3.N. No TODO comments, no stubs, no placeholder logic. All statistical methods must use real formulas.
  </action>
  <verify>Run `dotnet build Plugins/DataWarehouse.Plugins.UltimateDataQuality/DataWarehouse.Plugins.UltimateDataQuality.csproj` -- must compile with zero errors.</verify>
  <done>5 sealed strategy classes exist in PredictiveQualityStrategies.cs, all extending DataQualityStrategyBase with real EMA prediction, PSI drift detection, Z-score/IQR anomaly detection, linear regression trend analysis, and temporal correlation root cause analysis. Build passes.</done>
</task>

<task type="auto">
  <name>Task 2: Mark T146.B3 sub-tasks complete in TODO.md</name>
  <files>Metadata/TODO.md</files>
  <action>
In Metadata/TODO.md, find the T146 Phase B table (around line 15954-15958) and change the status of B3.1 through B3.5 from `[ ]` to `[x]`:

- Line with `146.B3.1` QualityAnticipatorStrategy -> `[x]`
- Line with `146.B3.2` DataDriftDetectorStrategy -> `[x]`
- Line with `146.B3.3` AnomalousDataFlagStrategy -> `[x]`
- Line with `146.B3.4` QualityTrendAnalyzerStrategy -> `[x]`
- Line with `146.B3.5` RootCauseAnalyzerStrategy -> `[x]`

Do NOT modify any other lines.
  </action>
  <verify>Grep for `146.B3` in TODO.md and confirm all 5 lines show `[x]`.</verify>
  <done>All 5 T146.B3 sub-tasks marked [x] in TODO.md.</done>
</task>

</tasks>

<verification>
- `dotnet build Plugins/DataWarehouse.Plugins.UltimateDataQuality/DataWarehouse.Plugins.UltimateDataQuality.csproj` passes with zero errors
- PredictiveQualityStrategies.cs contains exactly 5 sealed classes extending DataQualityStrategyBase
- Each class has unique StrategyId starting with "predictive-"
- Statistical formulas are correct: EMA (alpha=0.3), PSI (sum of (p-q)*ln(p/q)), Z-score, IQR, linear regression (least squares), Pearson-style temporal correlation
- No forbidden patterns: no TODO comments, no "simulation", no "mock", no "stub"
- All 5 T146.B3 sub-tasks marked [x] in TODO.md
</verification>

<success_criteria>
5 predictive quality strategies compile, use real statistical methods (EMA, PSI, Z-score, IQR, linear regression, temporal correlation), and produce actionable predictions, drift reports, anomaly flags, trend analyses, and root cause reports. All sub-tasks marked complete.
</success_criteria>

<output>
After completion, create `.planning/phases/13-data-governance/13-03-SUMMARY.md`
</output>
