---
phase: 13-data-governance
plan: 04
type: execute
wave: 1
depends_on: []
files_modified:
  - Plugins/DataWarehouse.Plugins.UltimateIntelligence/Strategies/DataSemantic/SemanticIntelligenceStrategies.cs
  - Metadata/TODO.md
autonomous: true
must_haves:
  truths:
    - "4 semantic intelligence strategies (B4.1-B4.4) compile and are discoverable by IntelligenceStrategyRegistry"
    - "Each strategy extends IntelligenceStrategyBase with unique StrategyId and production-ready implementations"
    - "SemanticMeaningExtractorStrategy extracts semantic meaning using regex-based entity extraction and keyword frequency analysis"
    - "ContextualRelevanceStrategy scores contextual relevance using TF-IDF-inspired term weighting"
    - "DomainKnowledgeIntegratorStrategy integrates domain glossaries and business rules for enriched understanding"
    - "CrossSystemSemanticMatchStrategy matches semantics across systems using Jaccard similarity and column-name normalization"
    - "TODO.md sub-tasks 146.B4.1-146.B4.4 are marked [x]"
  artifacts:
    - path: "Plugins/DataWarehouse.Plugins.UltimateIntelligence/Strategies/DataSemantic/SemanticIntelligenceStrategies.cs"
      provides: "4 sealed strategy classes extending IntelligenceStrategyBase"
      contains: "SemanticMeaningExtractorStrategy"
  key_links:
    - from: "SemanticIntelligenceStrategies.cs"
      to: "IntelligenceStrategyBase"
      via: "class inheritance"
      pattern: "IntelligenceStrategyBase"
    - from: "SemanticIntelligenceStrategies.cs"
      to: "IntelligenceStrategyRegistry"
      via: "auto-discovery from assembly"
      pattern: "sealed class.*: IntelligenceStrategyBase"
    - from: "SemanticIntelligenceStrategies.cs"
      to: "DataSemanticStrategies.cs"
      via: "same namespace, no type conflicts"
      pattern: "DataWarehouse.Plugins.UltimateIntelligence.Strategies.DataSemantic"
---

<objective>
Implement 4 Semantic Understanding strategies (T146.B4.1-B4.4) in UltimateIntelligence plugin's DataSemantic folder.

Purpose: These AI-native semantic strategies provide industry-first capabilities for extracting meaning from data (not just structure), scoring contextual relevance, integrating domain knowledge, and matching semantics across disparate systems.

Output: SemanticIntelligenceStrategies.cs with 4 production-ready sealed strategy classes alongside existing DataSemanticStrategies.cs.
</objective>

<execution_context>
@C:/Users/ddamien/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/ddamien/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/13-data-governance/13-RESEARCH.md
@Plugins/DataWarehouse.Plugins.UltimateIntelligence/IIntelligenceStrategy.cs
@Plugins/DataWarehouse.Plugins.UltimateIntelligence/IntelligenceStrategyBase.cs
@Plugins/DataWarehouse.Plugins.UltimateIntelligence/Strategies/DataSemantic/DataSemanticStrategies.cs
@Metadata/CLAUDE.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement 4 Semantic Intelligence strategies in SemanticIntelligenceStrategies.cs</name>
  <files>Plugins/DataWarehouse.Plugins.UltimateIntelligence/Strategies/DataSemantic/SemanticIntelligenceStrategies.cs</files>
  <action>
Create `Plugins/DataWarehouse.Plugins.UltimateIntelligence/Strategies/DataSemantic/SemanticIntelligenceStrategies.cs` with namespace `DataWarehouse.Plugins.UltimateIntelligence.Strategies.DataSemantic`.

IMPORTANT: The existing DataSemanticStrategies.cs in the same namespace defines types like `LineageNode`, `LineageEdge`, `SemanticProfile`, `CatalogEntry`, etc. Do NOT redefine these types. The new B4 strategies define their OWN internal types for semantic operations. Use `using DataWarehouse.SDK.AI;` for `IntelligenceCapabilities`, `ConfigurationRequirement`.

Each strategy extends `IntelligenceStrategyBase` which requires: `StrategyId` (string), `StrategyName` (string), `Category` (IntelligenceStrategyCategory), `Info` (IntelligenceStrategyInfo). Use `IntelligenceStrategyCategory.Feature` for all B4 strategies.

**Strategy 1: SemanticMeaningExtractorStrategy**
- StrategyId: `"data-semantic-meaning-extractor"`
- StrategyName: `"Semantic Meaning Extractor"`
- Category: `IntelligenceStrategyCategory.Feature`
- Info: ProviderName="Semantic Meaning Extractor", Description="Extracts semantic meaning from data including entities, concepts, relationships, and domain context", Capabilities=IntelligenceCapabilities.Classification | IntelligenceCapabilities.SemanticSearch, CostTier=3, LatencyTier=3, RequiresNetworkAccess=false, SupportsOfflineMode=true, Tags=["semantic", "meaning", "extraction", "nlp", "industry-first"], ConfigurationRequirements=Array.Empty<ConfigurationRequirement>()
- Private fields: `ConcurrentDictionary<string, SemanticMeaning> _meanings`
- Define internal records: `SemanticMeaning(string DataId, IReadOnlyList<string> Entities, IReadOnlyList<string> Concepts, IReadOnlyList<string> Keywords, string DominantDomain, double SemanticRichness)`, `ExtractionResult(SemanticMeaning Meaning, Dictionary<string, double> DomainScores)`
- Public methods:
  - `ExtractMeaning(string dataId, string content)` -> extracts:
    - Entities: find capitalized words/phrases using regex `\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b`, deduplicate
    - Concepts: extract noun-like phrases (2-3 word sequences that appear more than once)
    - Keywords: split on whitespace, lowercase, remove stopwords (common English: "the","a","an","is","are","was","were","in","on","at","to","for","of","and","or","but","not","with","this","that"), take top 10 by frequency
    - DominantDomain: score against domain dictionaries -- financial ("revenue","profit","margin","equity","asset","liability"), healthcare ("patient","diagnosis","treatment","clinical","medical"), technology ("server","database","api","deploy","cloud","container"), legal ("contract","clause","regulation","compliance","statute"). Highest scoring domain wins.
    - SemanticRichness: (uniqueWordCount / totalWordCount) * (entityCount + conceptCount) / max(1, totalWordCount / 100.0), clamped 0-1
  - `CompareMeanings(string dataId1, string dataId2)` -> compute Jaccard similarity of keyword sets + entity sets. Return average.
  - `GetMeaning(string dataId)` -> retrieve cached meaning

**Strategy 2: ContextualRelevanceStrategy**
- StrategyId: `"data-semantic-contextual-relevance"`
- StrategyName: `"Contextual Relevance Scorer"`
- Category: `IntelligenceStrategyCategory.Feature`
- Info: ProviderName="Contextual Relevance Scorer", Description="Scores contextual relevance of data using TF-IDF-inspired term weighting and query-document matching", Capabilities=IntelligenceCapabilities.SemanticSearch, CostTier=2, LatencyTier=2, RequiresNetworkAccess=false, SupportsOfflineMode=true, Tags=["relevance", "context", "scoring", "tf-idf", "industry-first"], ConfigurationRequirements=Array.Empty<ConfigurationRequirement>()
- Private fields: `ConcurrentDictionary<string, Dictionary<string, int>> _documentTermFreqs` (document -> term -> count), `ConcurrentDictionary<string, int> _documentFreqs` (term -> how many documents contain it), `int _totalDocuments`
- Public methods:
  - `IndexDocument(string docId, string content)` -> tokenize (split on non-alphanumeric, lowercase), count term frequencies, update document frequency counts, increment _totalDocuments (use Interlocked.Increment)
  - `ScoreRelevance(string query, int topK = 10)` -> tokenize query. For each indexed document, compute TF-IDF score: for each query term, tf = termFreq / totalTermsInDoc, idf = log(totalDocuments / (1 + docFreq)), score += tf * idf. Return top K documents sorted by score descending as list of `RelevanceResult(string DocId, double Score, Dictionary<string, double> TermScores)`.
  - `GetContextualScore(string docId1, string docId2)` -> compute cosine similarity of their TF-IDF vectors. Build term vector for each doc, compute dot product / (mag1 * mag2).
- Define internal record: `RelevanceResult(string DocId, double Score, Dictionary<string, double> TermScores)`

**Strategy 3: DomainKnowledgeIntegratorStrategy**
- StrategyId: `"data-semantic-domain-integrator"`
- StrategyName: `"Domain Knowledge Integrator"`
- Category: `IntelligenceStrategyCategory.Feature`
- Info: ProviderName="Domain Knowledge Integrator", Description="Integrates domain-specific glossaries, business rules, and ontologies to enrich data understanding", Capabilities=IntelligenceCapabilities.Classification | IntelligenceCapabilities.SemanticSearch, CostTier=2, LatencyTier=2, RequiresNetworkAccess=false, SupportsOfflineMode=true, Tags=["domain-knowledge", "glossary", "ontology", "enrichment", "industry-first"], ConfigurationRequirements=Array.Empty<ConfigurationRequirement>()
- Private fields: `ConcurrentDictionary<string, DomainGlossary> _glossaries`, `ConcurrentDictionary<string, List<BusinessRule>> _rules`
- Define internal records: `DomainGlossary(string DomainName, ConcurrentDictionary<string, string> Terms)` (term -> definition), `BusinessRule(string RuleId, string DomainName, string Condition, string Action, int Priority)`, `EnrichmentResult(string DataId, IReadOnlyList<GlossaryMatch> Matches, IReadOnlyList<BusinessRule> ApplicableRules, string InferredDomain)`
- Define internal record: `GlossaryMatch(string Term, string Definition, string Domain, double Confidence)`
- Public methods:
  - `RegisterGlossary(string domain, Dictionary<string, string> terms)` -> create DomainGlossary
  - `RegisterRule(string domain, string ruleId, string condition, string action, int priority = 0)` -> add to _rules
  - `EnrichData(string dataId, string content)` -> for each glossary, scan content for glossary terms (case-insensitive substring match). Collect all matches with confidence = 1.0 for exact word boundary match, 0.7 for substring match. Find applicable rules where condition keywords appear in content. Inferred domain = domain with most glossary matches. Return EnrichmentResult.
  - `GetDomainTerms(string domain)` -> return glossary terms for the domain

**Strategy 4: CrossSystemSemanticMatchStrategy**
- StrategyId: `"data-semantic-cross-system-match"`
- StrategyName: `"Cross-System Semantic Matcher"`
- Category: `IntelligenceStrategyCategory.Feature`
- Info: ProviderName="Cross-System Semantic Matcher", Description="Matches semantically equivalent fields across different systems using name normalization, type compatibility, and sample value analysis", Capabilities=IntelligenceCapabilities.SemanticSearch | IntelligenceCapabilities.Classification, CostTier=3, LatencyTier=3, RequiresNetworkAccess=false, SupportsOfflineMode=true, Tags=["cross-system", "semantic-matching", "field-mapping", "integration", "industry-first"], ConfigurationRequirements=Array.Empty<ConfigurationRequirement>()
- Private fields: `ConcurrentDictionary<string, SystemSchema> _systems`
- Define internal records: `SystemSchema(string SystemId, ConcurrentDictionary<string, FieldInfo> Fields)`, `FieldInfo(string FieldName, string DataType, string? Description, string[]? SampleValues)`, `SemanticMatch(string System1Id, string Field1Name, string System2Id, string Field2Name, double Confidence, string MatchReason)`, `MatchReport(IReadOnlyList<SemanticMatch> Matches, int TotalFieldsCompared, int MatchesFound)`
- Public methods:
  - `RegisterSystem(string systemId, Dictionary<string, FieldInfo> fields)` -> store in _systems
  - `FindMatches(string system1Id, string system2Id, double minConfidence = 0.5)` -> for each field in system1, compare against each field in system2:
    1. Normalize names: lowercase, replace underscores/hyphens with empty, strip common prefixes ("fk_", "pk_", "col_", "fld_")
    2. Exact normalized match = 1.0 confidence, reason "exact_name_match"
    3. One name contains the other = 0.8 confidence, reason "partial_name_match"
    4. Same data type + similar name (Levenshtein-inspired: shared character ratio > 0.6) = 0.6, reason "type_and_name_similarity"
    5. If SampleValues available: overlap ratio of sample values > 0.3 = bonus 0.2 confidence, reason appends "+value_overlap"
    Filter by minConfidence. Return MatchReport.
  - Private helper `NormalizeName(string name)` -> lowercase, strip prefixes, remove underscores/hyphens
  - Private helper `SharedCharRatio(string a, string b)` -> count shared characters / max(a.Length, b.Length) using character frequency comparison

All classes MUST be `sealed`. All must have XML `<summary>` and `<remarks>` docs referencing T146.B4.N. No TODO comments, no stubs. Do NOT redefine types already in DataSemanticStrategies.cs (LineageNode, SemanticProfile, etc.).
  </action>
  <verify>Run `dotnet build Plugins/DataWarehouse.Plugins.UltimateIntelligence/DataWarehouse.Plugins.UltimateIntelligence.csproj` -- must compile with zero errors. Specifically watch for type name collisions with existing DataSemanticStrategies.cs types.</verify>
  <done>4 sealed strategy classes exist in SemanticIntelligenceStrategies.cs, all extending IntelligenceStrategyBase with real entity extraction, TF-IDF scoring, domain glossary matching, and cross-system field mapping. Build passes with no type collisions.</done>
</task>

<task type="auto">
  <name>Task 2: Mark T146.B4 sub-tasks complete in TODO.md</name>
  <files>Metadata/TODO.md</files>
  <action>
In Metadata/TODO.md, find the T146 Phase B table (around line 15960-15963) and change the status of B4.1 through B4.4 from `[ ]` to `[x]`:

- Line with `146.B4.1` SemanticMeaningExtractorStrategy -> `[x]`
- Line with `146.B4.2` ContextualRelevanceStrategy -> `[x]`
- Line with `146.B4.3` DomainKnowledgeIntegratorStrategy -> `[x]`
- Line with `146.B4.4` CrossSystemSemanticMatchStrategy -> `[x]`

Do NOT modify any other lines.
  </action>
  <verify>Grep for `146.B4` in TODO.md and confirm all 4 lines show `[x]`.</verify>
  <done>All 4 T146.B4 sub-tasks marked [x] in TODO.md.</done>
</task>

</tasks>

<verification>
- `dotnet build Plugins/DataWarehouse.Plugins.UltimateIntelligence/DataWarehouse.Plugins.UltimateIntelligence.csproj` passes with zero errors
- SemanticIntelligenceStrategies.cs contains exactly 4 sealed classes extending IntelligenceStrategyBase
- Each class has unique StrategyId starting with "data-semantic-"
- No type name collisions with existing DataSemanticStrategies.cs
- No forbidden patterns: no TODO comments, no "simulation", no "mock", no "stub"
- All 4 T146.B4 sub-tasks marked [x] in TODO.md
</verification>

<success_criteria>
4 semantic intelligence strategies compile, implement real entity/keyword extraction (regex), TF-IDF relevance scoring (term frequency * inverse document frequency), domain glossary matching (substring + word boundary), and cross-system field mapping (name normalization + sample value overlap). All sub-tasks marked complete.
</success_criteria>

<output>
After completion, create `.planning/phases/13-data-governance/13-04-SUMMARY.md`
</output>
