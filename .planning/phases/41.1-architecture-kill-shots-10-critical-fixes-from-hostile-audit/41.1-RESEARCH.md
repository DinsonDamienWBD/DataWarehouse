# Phase 41.1: Architecture Kill Shots (10 Critical Fixes from Hostile Audit) - Research

**Researched:** 2026-02-17
**Domain:** Distributed systems architecture, async/await patterns, cryptographic memory safety, CRDT scalability
**Confidence:** HIGH

## Summary

This phase fixes 10 critical architecture issues ("kill shots") identified by a hostile 6-persona audit that would cause production failures at scale. The fixes span async pipeline correctness (KS1), kernel DI wiring (KS2), type-safe message handlers (KS3+4), native key memory (KS5), tenant-scoped storage (KS6+10), scalable vector clocks (KS7), Multi-Raft consensus consolidation (KS8), and lineage default implementations (KS9).

The research reveals that several killshots are 1-line fixes (KS2), others require API additions without breaking changes (KS1, KS3, KS6), and the most complex involve algorithmic replacements (KS7, KS8) to support 10M+ node scale. All fixes target the v3.0 hierarchy; the old hierarchy in PluginBase.cs is deleted.

**Primary recommendation:** Execute killshots in dependency order: KS2 first (enables plugin testing), then KS1/KS5 (foundational safety), then KS3/KS6/KS9 (base class improvements), finally KS7/KS8 (scalability infrastructure).

## Standard Stack

### Core
| Library | Version | Purpose | Why Standard |
|---------|---------|---------|--------------|
| .NET 10 | 10.0 | Runtime, async/await, NativeMemory | Latest LTS with native memory APIs |
| System.Runtime.InteropServices | Built-in | NativeMemory.AllocZeroed | Secure key allocation off managed heap |
| System.Security.Cryptography | Built-in | CryptographicOperations.ZeroMemory | Secure key wiping |
| System.Collections.Concurrent | Built-in | Thread-safe storage | Base class persistence layer |

### Supporting
| Library | Version | Purpose | When to Use |
|---------|---------|---------|-------------|
| System.Reflection | Built-in | Generic handler registration | Type-safe message handler discovery |
| MediatR patterns | Reference | Typed request/response handlers | Message bus type-safety model |

### Alternatives Considered
| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| NativeMemory | ProtectedMemory (DPAPI) | ProtectedMemory is Windows-only, NativeMemory is cross-platform |
| DVV/ITC | Classic VectorClock | Classic unbounded, DVV/ITC prune automatically with membership |
| Multi-Raft | Single Raft group | Single-group O(N) heartbeats impossible at 10K+ nodes |

**Installation:**
Already in .NET 10 BCL — no NuGet packages required.

## Architecture Patterns

### Recommended Project Structure
```
DataWarehouse.SDK/
├── Contracts/
│   ├── Hierarchy/                      # v3.0 hierarchy (keep)
│   │   ├── IntelligenceAwarePluginBase
│   │   ├── FeaturePluginBase
│   │   │   ├── SecurityPluginBase
│   │   │   ├── InfrastructurePluginBase
│   │   │   │   ├── ResiliencePluginBase   (NEW — KS8)
│   │   │   │   └── ConsensusPluginBase    (NEW — KS8)
│   │   │   └── DataManagementPluginBase   (MODIFY — KS6)
│   │   └── DataPipelinePluginBase
│   │       └── DataTransformationPluginBase
│   │           └── EncryptionPluginBase   (MOVE HERE — KS5)
│   └── PluginBase.cs                      # OLD hierarchy (DELETE — KS5)
├── Infrastructure/
│   └── Messaging/                         # Message bus (MODIFY — KS3)
└── Security/
    ├── IKeyStore.cs                       # Key storage (MODIFY — KS5)
    └── NativeKeyHandle.cs                 (NEW — KS5)
```

### Pattern 1: Async-All-The-Way (Killshot 1)
**What:** Pipeline calls are 100% async. No `.Result`, `.GetAwaiter().GetResult()`, or `.Wait()` in pipeline hot paths.
**When to use:** ALL data pipeline operations.
**Example:**
```csharp
// BEFORE (sync wrapper — THREADPOOL STARVATION):
public bool HasAccess(string resource, string subject, Permission requested)
{
    return HasAccessAsync(resource, subject, requested).GetAwaiter().GetResult();
}

// AFTER (async only — KS1):
public abstract Task<bool> HasAccessAsync(string resource, string subject, Permission requested);
// Delete sync wrapper entirely
```

### Pattern 2: Kernel DI Service Injection (Killshot 2)
**What:** Plugins receive kernel services (IMessageBus, IStorageEngine) via `InjectKernelServices` call.
**When to use:** After plugin construction in `RegisterPluginAsync`.
**Example:**
```csharp
// DataWarehouseKernel.cs — RegisterPluginAsync
public async Task<HandshakeResponse> RegisterPluginAsync(IPlugin plugin, CancellationToken ct = default)
{
    // ... handshake ...

    // FIX: ONE LINE ADDITION (KS2)
    InjectKernelServices(plugin); // <-- ADD THIS

    _registry.Register(plugin);
    // ... rest of registration ...
}
```

### Pattern 3: Type-Safe Message Handlers (Killshot 3)
**What:** Base class provides `RegisterHandler<TRequest, TResponse>()` for compile-time type safety and automatic handler discovery.
**When to use:** All IntelligenceAwarePluginBase or FeaturePluginBase message handling.
**Example:**
```csharp
// IntelligenceAwarePluginBase or FeaturePluginBase:
protected void RegisterHandler<TRequest, TResponse>(
    Func<TRequest, CancellationToken, Task<TResponse>> handler)
    where TRequest : notnull
{
    _messageBus?.Subscribe(typeof(TRequest).FullName!, async msg =>
    {
        if (msg.Payload is TRequest req)
        {
            var response = await handler(req, CancellationToken.None);
            return MessageResponse.Ok(response);
        }
        return MessageResponse.Error("Invalid message type");
    });
}

// Plugin usage:
protected override async Task OnInitializeAsync(CancellationToken ct)
{
    RegisterHandler<QueryRequest, QueryResponse>(HandleQueryAsync);
}

private async Task<QueryResponse> HandleQueryAsync(QueryRequest req, CancellationToken ct)
{
    // Type-safe handler — no casting
}
```

### Pattern 4: Native Key Memory (Killshot 5)
**What:** Cryptographic keys stored using `NativeMemory.AllocZeroed`, wrapped in `NativeKeyHandle`, never on managed heap.
**When to use:** ALL cryptographic key storage in IKeyStore implementations.
**Example:**
```csharp
// NEW: NativeKeyHandle (IDisposable wrapper)
public sealed class NativeKeyHandle : IDisposable
{
    private unsafe byte* _keyPtr;
    private int _keySize;

    public unsafe NativeKeyHandle(int keySize)
    {
        _keySize = keySize;
        _keyPtr = (byte*)NativeMemory.AllocZeroed((nuint)keySize);
    }

    public unsafe Span<byte> KeySpan => new Span<byte>(_keyPtr, _keySize);

    public unsafe void Dispose()
    {
        if (_keyPtr != null)
        {
            CryptographicOperations.ZeroMemory(new Span<byte>(_keyPtr, _keySize));
            NativeMemory.Free(_keyPtr);
            _keyPtr = null;
        }
    }
}

// IKeyStore interface CHANGE:
Task<NativeKeyHandle> GetKeyAsync(string keyId, ISecurityContext context); // was: byte[]
```

### Pattern 5: Tenant-Scoped Persistent Storage (Killshot 6+10)
**What:** `DataManagementPluginBase` provides tenant-isolated persistent storage. All inheriting plugins get tenant scoping for free.
**When to use:** All data management plugins (catalog, governance, quality, lineage, etc.).
**Example:**
```csharp
// DataManagementPluginBase (SDK):
public abstract class DataManagementPluginBase : FeaturePluginBase
{
    private readonly ConcurrentDictionary<string, ConcurrentDictionary<string, object>> _tenantStorage = new();

    protected async Task<T?> GetDataAsync<T>(string key, CancellationToken ct = default)
    {
        var tenantId = SecurityContext?.TenantId ?? "default";
        var tenantData = _tenantStorage.GetOrAdd(tenantId, _ => new());

        if (tenantData.TryGetValue(key, out var value) && value is T typed)
            return typed;

        // Delegate to storage subsystem for persistence
        return await LoadFromStorageAsync<T>(tenantId, key, ct);
    }

    protected async Task SetDataAsync<T>(string key, T value, CancellationToken ct = default)
    {
        var tenantId = SecurityContext?.TenantId ?? "default";
        var tenantData = _tenantStorage.GetOrAdd(tenantId, _ => new());
        tenantData[key] = value!;

        // Persist to storage subsystem
        await SaveToStorageAsync(tenantId, key, value, ct);
    }

    protected abstract Task<T?> LoadFromStorageAsync<T>(string tenantId, string key, CancellationToken ct);
    protected abstract Task SaveToStorageAsync<T>(string tenantId, string key, T value, CancellationToken ct);
}
```

### Pattern 6: Scalable Vector Clocks — DVV (Killshot 7)
**What:** Replace unbounded VectorClock with Dotted Version Vector (DVV) that prunes with cluster membership.
**When to use:** Replication conflict resolution at 10M+ node scale.
**Example:**
```csharp
// BEFORE: VectorClock (unbounded — grows with every node)
public record VectorClock(Dictionary<string, long> Clocks)
{
    public VectorClock Increment(string nodeId) { /* grows forever */ }
}

// AFTER: DottedVersionVector (bounded by active membership)
public sealed class DottedVersionVector
{
    private readonly ConcurrentDictionary<string, long> _clocks = new();
    private readonly IClusterMembership _membership; // prunes dead nodes

    public DottedVersionVector Increment(string nodeId)
    {
        PruneDeadNodes(); // bounded by active cluster size
        var newDvv = new DottedVersionVector(_membership);
        foreach (var kv in _clocks)
            newDvv._clocks[kv.Key] = kv.Value;
        newDvv._clocks[nodeId] = newDvv._clocks.GetValueOrDefault(nodeId) + 1;
        return newDvv;
    }

    private void PruneDeadNodes()
    {
        var activeNodes = _membership.GetAliveMembers().Select(m => m.Id).ToHashSet();
        var deadNodes = _clocks.Keys.Except(activeNodes).ToList();
        foreach (var dead in deadNodes)
            _clocks.TryRemove(dead, out _);
    }
}
```

### Pattern 7: Multi-Raft with Groups (Killshot 8)
**What:** Split data into groups of 3-5 voters. Each group runs independent Raft. O(1) heartbeats per node instead of O(N).
**When to use:** Consensus at 10K+ node scale.
**Example:**
```csharp
// NEW: ConsensusPluginBase
public abstract class ConsensusPluginBase : InfrastructurePluginBase
{
    protected abstract Task<ConsensusResult> ProposeAsync(byte[] data, CancellationToken ct);
    protected abstract Task<bool> IsLeaderAsync();
}

// NEW: UltimateConsensus (Multi-Raft)
public class UltimateConsensus : ConsensusPluginBase
{
    private readonly ConcurrentDictionary<int, RaftGroup> _groups = new();

    // Each group: 3-5 voters, independent leader election
    private RaftGroup GetGroupForKey(string key)
    {
        var groupId = Math.Abs(key.GetHashCode()) % _config.GroupCount;
        return _groups.GetOrAdd(groupId, id => new RaftGroup(id, _config));
    }

    protected override Task<ConsensusResult> ProposeAsync(byte[] data, CancellationToken ct)
    {
        var group = GetGroupForKey(ExtractKeyFromData(data));
        return group.ProposeAsync(data, ct); // only this group votes
    }
}
```

### Pattern 8: Lineage Default BFS Traversal (Killshot 9)
**What:** `LineageStrategyBase` provides default BFS traversal + persistence. Inheritors get working implementation unless overridden.
**When to use:** All 13 stub lineage strategies.
**Example:**
```csharp
// LineageStrategyBase (current — stubs return empty):
public abstract Task<LineageGraph> GetUpstreamAsync(string nodeId, int maxDepth = 10, CancellationToken ct = default);
public abstract Task<LineageGraph> GetDownstreamAsync(string nodeId, int maxDepth = 10, CancellationToken ct = default);

// LineageStrategyBase (KS9 — default BFS implementation):
public virtual async Task<LineageGraph> GetUpstreamAsync(string nodeId, int maxDepth = 10, CancellationToken ct = default)
{
    ThrowIfNotInitialized();

    var visited = new HashSet<string>();
    var nodes = new List<LineageNode>();
    var edges = new List<LineageEdge>();
    var queue = new Queue<(string id, int depth)>();
    queue.Enqueue((nodeId, 0));

    while (queue.Count > 0)
    {
        var (currentId, depth) = queue.Dequeue();
        if (depth > maxDepth || visited.Contains(currentId)) continue;
        visited.Add(currentId);

        // Load from _nodes/_edges dictionaries (base class persistence)
        if (_nodes.TryGetValue(currentId, out var node))
            nodes.Add(node);

        // Find upstream edges
        foreach (var edge in _edges.Values.Where(e => e.TargetNodeId == currentId))
        {
            queue.Enqueue((edge.SourceNodeId, depth + 1));
            edges.Add(edge);
        }
    }

    return new LineageGraph
    {
        RootNodeId = nodeId,
        Nodes = nodes.AsReadOnly(),
        Edges = edges.AsReadOnly(),
        Depth = maxDepth,
        UpstreamCount = nodes.Count - 1
    };
}
// Strategies can override to optimize or discard (return empty)
```

### Anti-Patterns to Avoid
- **Sync-over-async wrappers:** `.Result`, `.GetAwaiter().GetResult()`, `.Wait()` — cause threadpool starvation under load
- **Forgetting InjectKernelServices:** Plugins won't receive IMessageBus, IStorageEngine — silent failure
- **Untyped message handlers:** `object` casting fragile, no compile-time safety
- **Managed heap keys:** GC moves byte[], key material scattered in memory
- **Flat ConcurrentDictionary for multi-tenant:** No tenant isolation, memory-only, no persistence
- **Unbounded VectorClock:** At 10M nodes, O(N) memory per operation
- **Single-group Raft:** O(N) heartbeats per leader — impossible at 10K+ nodes
- **Stub lineage strategies:** 13 of 18 return empty arrays — production unusable

## Don't Hand-Roll

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| Async pipeline | Sync wrapper helpers | Async all the way | Threadpool starvation inevitable under load |
| Typed handlers | Custom casting framework | Reflection + generics (MediatR pattern) | Type safety, handler discovery, compile-time errors |
| Secure key memory | Managed byte[] with GC.SuppressFinalize | NativeMemory + CryptographicOperations.ZeroMemory | GC can't move native memory, guaranteed wipe |
| Vector clocks at scale | Classic VectorClock + manual pruning | DVV or ITC with membership binding | Pruning errors break causality, DVV proven safe |
| Consensus at scale | Single Raft group scaling | Multi-Raft with groups | Math: 10K nodes * 1 leader = 10K heartbeats/sec, Multi-Raft = groups * heartbeats |
| BFS lineage traversal | Per-strategy graph algorithms | Base class default implementation | DRY — 13 strategies need same BFS, centralize once |

**Key insight:** These are solved problems with well-documented failure modes. Custom solutions introduce subtle bugs (GC key copying, causality violations, heartbeat storms) that only manifest at scale.

## Common Pitfalls

### Pitfall 1: Async Deadlock in Sync Context
**What goes wrong:** Calling `.GetAwaiter().GetResult()` from ASP.NET, WinForms, or WPF causes deadlock.
**Why it happens:** Sync context captures continuation, blocked thread holds sync context, continuation can't resume.
**How to avoid:** Never block on async in UI or ASP.NET. Async all the way. Delete sync wrappers.
**Warning signs:** App hangs under load, thread dumps show blocked threads waiting on tasks.

### Pitfall 2: Missing InjectKernelServices Call
**What goes wrong:** Plugins silently fail to receive IMessageBus, IStorageEngine — operations throw NullReferenceException.
**Why it happens:** `RegisterPluginAsync` constructs plugin but forgets to inject services.
**How to avoid:** Add `InjectKernelServices(plugin);` immediately after construction in RegisterPluginAsync.
**Warning signs:** Plugin tests pass (mocked), integration tests fail with NRE on kernel services.

### Pitfall 3: Scoped Service Injected into Singleton
**What goes wrong:** Runtime exception or subtle state leaks between requests.
**Why it happens:** .NET DI validates lifetime scopes — scoped into singleton violates lifecycle rules.
**How to avoid:** Plugins are singletons — use IServiceProvider to resolve scoped services per-operation.
**Warning signs:** Development environment throws on startup, production leaks tenant data.

### Pitfall 4: Key Material on Managed Heap
**What goes wrong:** GC copies byte[] during compaction, key material scattered in memory, survives CryptographicOperations.ZeroMemory.
**Why it happens:** Managed heap allows GC to move objects. Pinning only prevents moves while pinned, not historical copies.
**How to avoid:** NativeMemory.AllocZeroed for keys. Never store keys in byte[] on managed heap.
**Warning signs:** Memory dumps contain plaintext keys, forensic analysis finds key fragments.

### Pitfall 5: VectorClock Memory Explosion
**What goes wrong:** At 10M nodes, VectorClock grows to 10M * 8 bytes = 80MB per operation. OOM at scale.
**Why it happens:** Classic VectorClock has entry per node ever seen, never prunes.
**How to avoid:** Use DVV (Dotted Version Vector) or ITC (Interval Tree Clock) that prune with cluster membership.
**Warning signs:** Memory grows linearly with cluster churn, eventual OOM, GC pressure.

### Pitfall 6: Single-Group Raft Heartbeat Storm
**What goes wrong:** At 10K nodes, leader sends 10K heartbeats every 50ms = 200K messages/sec. Network saturation.
**Why it happens:** Single Raft group requires leader to heartbeat all followers.
**How to avoid:** Multi-Raft with groups of 3-5 voters. 10K nodes / 5 = 2K groups, each group independent.
**Warning signs:** Network saturation at scale, leader CPU 100%, follower heartbeat timeouts.

### Pitfall 7: Tenant Data Leakage in Flat Storage
**What goes wrong:** Tenant A sees Tenant B's data, compliance violation.
**Why it happens:** Flat ConcurrentDictionary has no tenant scoping. Keys collide across tenants.
**How to avoid:** Scope storage by ISecurityContext.TenantId in DataManagementPluginBase.
**Warning signs:** QA finds cross-tenant data, audit logs show unauthorized access.

### Pitfall 8: Lineage Strategies Return Empty
**What goes wrong:** Production lineage queries return no results. Impact analysis broken.
**Why it happens:** 13 of 18 strategies are stubs returning `Array.Empty<LineageNode>()`.
**How to avoid:** Implement default BFS traversal in LineageStrategyBase. Strategies inherit working implementation.
**Warning signs:** Lineage UI shows no graph, GetUpstreamAsync returns zero nodes for known datasets.

## Code Examples

Verified patterns from codebase analysis:

### Example 1: Async Pipeline (KS1)
```csharp
// Source: DataWarehouse.SDK/Contracts/PluginBase.cs (current — DELETE sync wrapper)
public abstract class AccessControlPluginBase : SecurityProviderPluginBase, IAccessControl
{
    // BEFORE (KS1 violation):
    public bool HasAccess(string resource, string subject, Permission requested)
    {
        return HasAccessAsync(resource, subject, requested).GetAwaiter().GetResult(); // THREADPOOL STARVATION
    }

    // AFTER (KS1 fix):
    // Delete sync wrapper. Pipeline calls async directly.
    public abstract Task<bool> HasAccessAsync(string resource, string subject, Permission requested);
}
```

### Example 2: Kernel DI Wiring (KS2)
```csharp
// Source: DataWarehouse.Kernel/DataWarehouseKernel.cs (lines 144-199)
public async Task<HandshakeResponse> RegisterPluginAsync(IPlugin plugin, CancellationToken ct = default)
{
    ArgumentNullException.ThrowIfNull(plugin);
    _logger?.LogDebug("Registering plugin {PluginId} ({PluginName})", plugin.Id, plugin.Name);

    var request = new HandshakeRequest { /* ... */ };
    var response = await plugin.OnHandshakeAsync(request);

    if (response.Success)
    {
        // FIX: ADD THIS LINE (KS2)
        InjectKernelServices(plugin); // <-- 1-line fix

        _registry.Register(plugin);
        // ... rest of registration ...
    }

    return response;
}
```

### Example 3: Native Key Handle (KS5)
```csharp
// Source: NEW file DataWarehouse.SDK/Security/NativeKeyHandle.cs
using System;
using System.Runtime.InteropServices;
using System.Security.Cryptography;

namespace DataWarehouse.SDK.Security;

/// <summary>
/// Wraps cryptographic key material in unmanaged memory (KS5).
/// Prevents GC from copying key bytes. Guaranteed secure wipe on disposal.
/// </summary>
public sealed unsafe class NativeKeyHandle : IDisposable
{
    private byte* _keyPtr;
    private readonly int _keySize;
    private bool _disposed;

    public NativeKeyHandle(int keySize)
    {
        if (keySize <= 0) throw new ArgumentOutOfRangeException(nameof(keySize));
        _keySize = keySize;
        _keyPtr = (byte*)NativeMemory.AllocZeroed((nuint)keySize);
    }

    /// <summary>Gets a span over the key material. Valid only until Dispose.</summary>
    public Span<byte> KeySpan
    {
        get
        {
            ObjectDisposedException.ThrowIf(_disposed, this);
            return new Span<byte>(_keyPtr, _keySize);
        }
    }

    /// <summary>Gets the key size in bytes.</summary>
    public int KeySize => _keySize;

    public void Dispose()
    {
        if (_disposed) return;

        // Secure wipe before freeing
        CryptographicOperations.ZeroMemory(new Span<byte>(_keyPtr, _keySize));
        NativeMemory.Free(_keyPtr);
        _keyPtr = null;
        _disposed = true;
        GC.SuppressFinalize(this);
    }

    ~NativeKeyHandle() => Dispose();
}
```

### Example 4: Dotted Version Vector (KS7)
```csharp
// Source: NEW DataWarehouse.SDK/Replication/DottedVersionVector.cs
using System.Collections.Concurrent;

namespace DataWarehouse.SDK.Replication;

/// <summary>
/// Dotted Version Vector with automatic pruning (KS7).
/// Bounded by active cluster membership. Scales to 10M+ nodes.
/// </summary>
public sealed class DottedVersionVector
{
    private readonly ConcurrentDictionary<string, long> _clocks = new();
    private readonly IClusterMembership _membership;

    public DottedVersionVector(IClusterMembership membership)
    {
        _membership = membership ?? throw new ArgumentNullException(nameof(membership));
    }

    /// <summary>Increments the clock for a node and prunes dead nodes.</summary>
    public DottedVersionVector Increment(string nodeId)
    {
        PruneDeadNodes();
        var newDvv = new DottedVersionVector(_membership);

        // Copy current clocks
        foreach (var kv in _clocks)
            newDvv._clocks[kv.Key] = kv.Value;

        // Increment for this node
        newDvv._clocks[nodeId] = newDvv._clocks.GetValueOrDefault(nodeId) + 1;
        return newDvv;
    }

    /// <summary>Checks if this DVV happens-before other.</summary>
    public bool HappensBefore(DottedVersionVector other)
    {
        foreach (var (node, time) in _clocks)
        {
            if (!other._clocks.TryGetValue(node, out var otherTime) || time > otherTime)
                return false;
        }
        return true;
    }

    /// <summary>Merges two DVVs (join operation).</summary>
    public static DottedVersionVector Merge(DottedVersionVector a, DottedVersionVector b)
    {
        var merged = new DottedVersionVector(a._membership);

        foreach (var (node, time) in a._clocks)
            merged._clocks[node] = time;

        foreach (var (node, time) in b._clocks)
            merged._clocks[node] = Math.Max(merged._clocks.GetValueOrDefault(node), time);

        merged.PruneDeadNodes();
        return merged;
    }

    /// <summary>Prunes entries for nodes no longer in cluster (keeps size bounded).</summary>
    private void PruneDeadNodes()
    {
        var activeNodes = _membership.GetAliveMembers()
            .Select(m => m.Id)
            .ToHashSet();

        var deadNodes = _clocks.Keys.Except(activeNodes).ToList();
        foreach (var dead in deadNodes)
            _clocks.TryRemove(dead, out _);
    }

    /// <summary>Gets the current clock size (for monitoring).</summary>
    public int Size => _clocks.Count;
}
```

## State of the Art

| Old Approach | Current Approach | When Changed | Impact |
|--------------|------------------|--------------|--------|
| Sync-over-async wrappers | Async all the way | .NET Core 1.0 (2016) | Threadpool starvation eliminated |
| Managed byte[] for keys | NativeMemory.AllocZeroed | .NET 6 (2021) | Keys never on GC heap |
| Classic VectorClock | DVV (Dotted Version Vector) | Shapiro et al. 2011 | Bounded memory at 10M+ nodes |
| Single Raft group | Multi-Raft with groups | CockroachDB (2015), TiKV (2016) | Scales to 10K+ nodes |
| Untyped message handlers | Generic typed handlers (MediatR pattern) | MediatR 3.0 (2017) | Compile-time safety |

**Deprecated/outdated:**
- `.Result` and `.Wait()`: Deprecated for async code since .NET Core 1.0 — use `await` exclusively
- `GetAwaiter().GetResult()`: Acceptable only in console `Main()` — forbidden in libraries and web apps
- `ProtectedMemory` (DPAPI): Windows-only — use NativeMemory for cross-platform secure memory
- Classic VectorClock without pruning: Unbounded memory — replace with DVV or ITC
- Single-group Raft at scale: O(N) heartbeat complexity — use Multi-Raft for 10K+ nodes

## Open Questions

1. **KS7 — DVV vs ITC Choice**
   - What we know: DVV is simpler, ITC better for dynamic membership (frequent joins/leaves)
   - What's unclear: DataWarehouse cluster churn rate — do we optimize for stability or churn?
   - Recommendation: Start with DVV (simpler), monitor cluster churn, migrate to ITC if churn >10%/hour

2. **KS8 — Multi-Raft Group Size**
   - What we know: Groups of 3-5 voters recommended. Smaller = faster, larger = more fault-tolerant
   - What's unclear: DataWarehouse failure domains — how many concurrent node failures expected?
   - Recommendation: Default to 5 voters per group (tolerates 2 failures), make configurable

3. **KS5 — NativeKeyHandle Lifetime**
   - What we know: Must dispose to wipe memory. Can't use in async across await boundaries (pointer invalid)
   - What's unclear: How to pass keys across async boundaries without copying to managed heap?
   - Recommendation: Use NativeKeyHandle only in synchronous crypto operations, copy to managed byte[] for async (trade security for correctness), or redesign crypto APIs to be fully synchronous

## Sources

### Primary (HIGH confidence)
- NativeMemory.AllocZeroed: [Microsoft Learn - NativeMemory.AllocZeroed](https://learn.microsoft.com/en-us/dotnet/api/system.runtime.interopservices.nativememory.alloczeroed?view=net-8.0)
- Async/await best practices: [Why is .GetAwaiter().GetResult() bad in C#?](https://www.nikouusitalo.com/blog/why-is-getawaiter-getresult-bad-in-c/)
- ThreadPool starvation: [Understanding Thread Exhaustion with GetAwaiter().GetResult()](https://mayureshwaykole.medium.com/understanding-thread-exhaustion-with-getawaiter-getresult-in-c-862e6d0c3602)
- .NET DI service lifetimes: [Microsoft Learn - Service Lifetimes](https://learn.microsoft.com/en-us/dotnet/core/extensions/dependency-injection/service-lifetimes)
- Secure memory practices: [Handling Sensitive Data - Yubico](https://docs.yubico.com/yesdk/users-manual/sdk-programming-guide/sensitive-data.html)
- DataWarehouse codebase: `DataWarehouse.SDK/Contracts/`, `DataWarehouse.Kernel/DataWarehouseKernel.cs`, `Plugins/DataWarehouse.Plugins.UltimateDataLineage/`

### Secondary (MEDIUM confidence)
- Dotted Version Vectors: [The CRDT Dictionary](https://www.iankduncan.com/engineering/2025-11-27-crdt-dictionary/)
- CRDT Optimizations: [CRDT optimizations - Bartosz Sypytkowski](https://www.bartoszsypytkowski.com/crdt-optimizations/)
- Multi-Raft scaling: [Building a large-scale distributed storage system based on Raft](https://www.cncf.io/blog/2019/11/04/building-a-large-scale-distributed-storage-system-based-on-raft/)
- CockroachDB Multi-Raft: [Scaling Raft](https://www.cockroachlabs.com/blog/scaling-raft/)
- Interval Tree Clocks: [Interval Tree Clocks - HackMD](https://hackmd.io/@manifoldx/interval-tree-clocks)

### Tertiary (LOW confidence - architectural context)
- Generic handler registration patterns: [MediatR GitHub Issues #521](https://github.com/jbogard/MediatR/issues/521) (community patterns, not official docs)
- ITC scalability claims: Multiple sources mention dynamic systems but none provide 10M node benchmarks — recommendation is based on algorithmic complexity analysis, not empirical data

## Metadata

**Confidence breakdown:**
- KS1 (Async pipeline): HIGH - Well-documented anti-pattern, official Microsoft guidance, codebase sync wrappers identified
- KS2 (Kernel DI wiring): HIGH - 1-line fix, codebase shows missing call, straightforward
- KS3 (Typed handlers): MEDIUM - MediatR pattern well-known, but reflection-based registration has edge cases
- KS5 (Native key memory): HIGH - NativeMemory official API, CryptographicOperations verified, secure memory practices documented
- KS6+10 (Tenant storage): HIGH - Standard multi-tenant pattern, ISecurityContext.TenantId exists in codebase
- KS7 (DVV/ITC): MEDIUM - DVV algorithm proven, but 10M node claims extrapolated from complexity analysis, not benchmarked
- KS8 (Multi-Raft): MEDIUM - CockroachDB/TiKV production proven at 10K nodes, but 10M claim is extrapolation
- KS9 (Lineage defaults): HIGH - BFS is standard graph algorithm, codebase shows 13 stubs, straightforward implementation

**Research date:** 2026-02-17
**Valid until:** 2026-04-17 (60 days — stable domains: async/await, NativeMemory, CRDT theory; fast-moving: Multi-Raft implementations)
