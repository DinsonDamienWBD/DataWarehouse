---
phase: 50
plan: 50-02
title: "Fix P2 Findings: Test Gaps"
depends_on: [49-01, 49-02, 49-03, 49-04, 49-05, 50-01]
---

# Plan 50-02: Fix P2 Findings — Test Gaps

## Role
You are a **Test Coverage Engineer**. Fill test gaps identified in Phase 48 to improve confidence and prevent regressions.

## Goal
Add missing tests identified in Phase 48:
- Edge case coverage gaps
- Error path coverage gaps
- Integration test gaps
- Boundary condition tests
- Concurrency scenario tests
- Configuration variation tests

## Inputs
Read findings from:
- `.planning/phases/48-hostile-test-audit/TEST-AUDIT.md` (P2 test gaps section)
- Code coverage reports (if available)

## Approach

### 1. Inventory P2 Test Gaps
Use `Grep` to extract all P2 test gap findings:
```bash
grep -r "P2.*test\|test.*P2\|missing.*test\|coverage.*gap" .planning/phases/48-*/*.md
```

Create consolidated list in `50-02-P2-TEST-INVENTORY.md`:
- Gap ID
- Description
- Location (what's not tested)
- Test type needed (unit/integration/scenario)
- Priority within P2

### 2. Test Categories

#### Category A: Edge Case Coverage
Add tests for:
- Empty collections
- Null inputs
- Maximum/minimum values
- Boundary values (off-by-one)
- Empty strings vs null strings
- Zero-length arrays

Example:
```csharp
[Fact]
public void ProcessData_EmptyInput_ReturnsEmptyResult()
{
    var result = _sut.ProcessData(Array.Empty<byte>());
    Assert.Empty(result);
}
```

#### Category B: Error Path Coverage
Add tests for:
- Invalid input rejection
- Exception handling paths
- Resource exhaustion scenarios
- Timeouts
- Cancellation
- Dependency failures

Example:
```csharp
[Fact]
public void ProcessData_InvalidInput_ThrowsArgumentException()
{
    Assert.Throws<ArgumentException>(() => _sut.ProcessData(null));
}
```

#### Category C: Integration Test Gaps
Add tests for:
- Multi-plugin workflows
- Message bus routing between plugins
- End-to-end pipeline execution
- Strategy selection and execution
- Configuration loading and application

Example:
```csharp
[Fact]
public async Task WriteReadPipeline_EndToEnd_DataRoundTrips()
{
    // Arrange: Write data
    await _kernel.WriteAsync(testData);

    // Act: Read data back
    var result = await _kernel.ReadAsync(testKey);

    // Assert: Data matches
    Assert.Equal(testData, result);
}
```

#### Category D: Boundary Condition Tests
Add tests for:
- Buffer size boundaries
- Collection size limits
- String length limits
- Numeric range boundaries
- Time-based boundaries (timeouts, expiration)

Example:
```csharp
[Theory]
[InlineData(0)]
[InlineData(1)]
[InlineData(1024)]
[InlineData(1048576)] // 1 MB
public void Compress_VariousSizes_Succeeds(int size)
{
    var data = new byte[size];
    var result = _compressor.Compress(data);
    Assert.NotNull(result);
}
```

#### Category E: Concurrency Scenario Tests
Add tests for:
- Concurrent reads
- Concurrent writes
- Read-write races
- Thread-safety of shared state
- Lock contention scenarios

Example:
```csharp
[Fact]
public async Task ConcurrentWrites_MultipleThreads_AllSucceed()
{
    var tasks = Enumerable.Range(0, 10)
        .Select(i => _cache.WriteAsync($"key{i}", $"value{i}"))
        .ToArray();

    await Task.WhenAll(tasks);

    // Verify all writes succeeded
    for (int i = 0; i < 10; i++)
    {
        var value = await _cache.ReadAsync($"key{i}");
        Assert.Equal($"value{i}", value);
    }
}
```

#### Category F: Configuration Variation Tests
Add tests for:
- Different configuration values
- Missing optional configuration
- Invalid configuration rejection
- Configuration precedence (defaults < file < env < CLI)

Example:
```csharp
[Fact]
public void Initialize_MissingRequiredConfig_Throws()
{
    var config = new Dictionary<string, string>(); // Empty config
    Assert.Throws<InvalidOperationException>(() =>
        _plugin.Initialize(config));
}
```

### 3. Test Execution
For EACH test gap:
1. Identify what needs to be tested
2. Write test case(s)
3. Verify test initially fails (if testing a fix) or passes (if testing existing code)
4. Run all tests to ensure no regression
5. Document the test in `50-02-TESTS-ADDED.md`

### 4. Verification
After all tests added:
1. `dotnet test` — must pass with all new tests
2. Verify test count increased appropriately
3. Review code coverage (if tooling available)
4. Ensure no flaky tests (run multiple times)

## Output
Create `50-02-P2-TEST-INVENTORY.md` — List of all P2 test gaps
Create `50-02-TESTS-ADDED.md` — Detailed log of tests added:
```markdown
# P2 Test Additions

## Summary
- Total gaps identified: N
- Tests added: M
- Coverage improvement: X% → Y%

## Tests Added

### Edge Cases: A tests
- `TestClass.TestMethod` — tests [scenario]
- ...

### Error Paths: B tests
- `TestClass.TestMethod` — tests [error scenario]
- ...

### Integration: C tests
- `TestClass.TestMethod` — tests [end-to-end scenario]
- ...

### Boundary Conditions: D tests
- `TestClass.TestMethod` — tests [boundary]
- ...

### Concurrency: E tests
- `TestClass.TestMethod` — tests [concurrent scenario]
- ...

### Configuration: F tests
- `TestClass.TestMethod` — tests [config variation]
- ...

## Coverage Metrics
- Before: X% line coverage, Y% branch coverage
- After: A% line coverage, B% branch coverage
- Improvement: +N% line, +M% branch
```

## Success Criteria
- All P2 test gaps addressed
- All new tests pass
- No flaky tests introduced
- Test count increased appropriately
- Code coverage improved (if measured)
- `50-02-TESTS-ADDED.md` documents all work

## Constraints
- Tests must be deterministic (no flaky tests)
- Tests must be fast (< 1 second per test ideal, < 10 seconds max)
- Tests must be isolated (no shared state between tests)
- Integration tests should use in-memory implementations where possible
- All tests must clean up resources
