---
phase: 63-universal-fabric
plan: 11
type: execute
wave: 4
depends_on: ["63-06", "63-07"]
files_modified:
  - Clients/python/dw_client/__init__.py
  - Clients/python/dw_client/client.py
  - Clients/python/dw_client/s3_compat.py
  - Clients/python/setup.py
  - Clients/python/README.md
autonomous: true

must_haves:
  truths:
    - "Python client connects to DataWarehouse S3-compatible endpoint"
    - "Python client supports get, put, delete, list operations via S3 protocol"
    - "Python client installable via pip install"
  artifacts:
    - path: "Clients/python/dw_client/client.py"
      provides: "Main DataWarehouse Python client"
      contains: "class DataWarehouseClient"
    - path: "Clients/python/dw_client/s3_compat.py"
      provides: "S3-compatible operations using boto3"
      contains: "class S3CompatClient"
    - path: "Clients/python/setup.py"
      provides: "Package installation"
      contains: "setup("
  key_links:
    - from: "Clients/python/dw_client/s3_compat.py"
      to: "Plugins/DataWarehouse.Plugins.UniversalFabric/S3Server/S3HttpServer.cs"
      via: "S3 HTTP protocol"
      pattern: "boto3"
---

<objective>
Create the Python cross-language client SDK for DataWarehouse.

Purpose: Python is the most popular data engineering language. This client SDK lets Python applications use DataWarehouse as a storage backend via the S3-compatible API, plus a native dw:// addressing client.

Output: Pip-installable Python package with S3-compatible and native dw:// clients.
</objective>

<execution_context>
@C:/Users/ddamien/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/ddamien/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/63-universal-fabric/63-06-SUMMARY.md
@.planning/phases/63-universal-fabric/63-07-SUMMARY.md
@DataWarehouse.SDK/Storage/Fabric/S3Types.cs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Python client package structure and S3-compatible client</name>
  <files>Clients/python/dw_client/__init__.py, Clients/python/dw_client/s3_compat.py, Clients/python/setup.py</files>
  <action>
1. Create directory structure: Clients/python/dw_client/

2. setup.py:
```python
from setuptools import setup, find_packages
setup(
    name="dw-client",
    version="5.0.0",
    description="DataWarehouse Universal Storage Client",
    packages=find_packages(),
    install_requires=["boto3>=1.26.0", "requests>=2.28.0"],
    python_requires=">=3.9",
    classifiers=["Programming Language :: Python :: 3", "License :: OSI Approved :: MIT License"],
)
```

3. __init__.py:
```python
from .client import DataWarehouseClient
from .s3_compat import S3CompatClient
__version__ = "5.0.0"
__all__ = ["DataWarehouseClient", "S3CompatClient"]
```

4. s3_compat.py -- S3-compatible client using boto3:
```python
import boto3
from botocore.config import Config
from typing import Optional, Dict, List, BinaryIO, Iterator

class S3CompatClient:
    """Client for DataWarehouse S3-compatible API using boto3."""

    def __init__(self, endpoint_url: str, access_key: str, secret_key: str,
                 region: str = "us-east-1", use_ssl: bool = False):
        self._client = boto3.client(
            "s3",
            endpoint_url=endpoint_url,
            aws_access_key_id=access_key,
            aws_secret_access_key=secret_key,
            region_name=region,
            use_ssl=use_ssl,
            config=Config(signature_version="s3v4", s3={"addressing_style": "path"}),
        )

    # Bucket operations
    def list_buckets(self) -> List[Dict]: ...
    def create_bucket(self, bucket: str) -> None: ...
    def delete_bucket(self, bucket: str) -> None: ...
    def bucket_exists(self, bucket: str) -> bool: ...

    # Object operations
    def put_object(self, bucket: str, key: str, body: BinaryIO,
                   content_type: str = None, metadata: Dict[str, str] = None) -> Dict: ...
    def get_object(self, bucket: str, key: str) -> BinaryIO: ...
    def delete_object(self, bucket: str, key: str) -> None: ...
    def head_object(self, bucket: str, key: str) -> Dict: ...
    def list_objects(self, bucket: str, prefix: str = "",
                     max_keys: int = 1000) -> Iterator[Dict]: ...
    def object_exists(self, bucket: str, key: str) -> bool: ...

    # Multipart upload
    def upload_file(self, bucket: str, key: str, file_path: str,
                    multipart_threshold: int = 100 * 1024 * 1024) -> None: ...
    def download_file(self, bucket: str, key: str, file_path: str) -> None: ...

    # Presigned URLs
    def presign_get(self, bucket: str, key: str, expires_in: int = 3600) -> str: ...
    def presign_put(self, bucket: str, key: str, expires_in: int = 3600) -> str: ...

    # Copy
    def copy_object(self, source_bucket: str, source_key: str,
                    dest_bucket: str, dest_key: str) -> Dict: ...
```

Each method should be fully implemented using the boto3 S3 client (not stubs). Include proper error handling wrapping botocore.exceptions.ClientError.
  </action>
  <verify>python -c "import ast; ast.parse(open('Clients/python/dw_client/s3_compat.py').read()); print('OK')"</verify>
  <done>Python S3-compatible client is syntactically valid and wraps all S3 operations via boto3</done>
</task>

<task type="auto">
  <name>Task 2: Create native DataWarehouse Python client with dw:// addressing</name>
  <files>Clients/python/dw_client/client.py</files>
  <action>
Create DataWarehouseClient that provides a higher-level API using dw:// addressing:

```python
import requests
from typing import Optional, Dict, List, BinaryIO, Union
from .s3_compat import S3CompatClient

class DataWarehouseClient:
    """High-level DataWarehouse client with dw:// addressing support."""

    def __init__(self, endpoint: str, access_key: str, secret_key: str,
                 region: str = "us-east-1"):
        self._endpoint = endpoint.rstrip("/")
        self._s3 = S3CompatClient(endpoint, access_key, secret_key, region)

    # dw:// addressing operations
    def store(self, dw_uri: str, data: Union[bytes, BinaryIO, str],
              metadata: Dict[str, str] = None) -> Dict:
        """Store data at a dw:// address. dw://bucket/key format."""
        bucket, key = self._parse_dw_uri(dw_uri)
        if isinstance(data, str):
            data = data.encode("utf-8")
        if isinstance(data, bytes):
            from io import BytesIO
            data = BytesIO(data)
        return self._s3.put_object(bucket, key, data, metadata=metadata)

    def retrieve(self, dw_uri: str) -> bytes:
        """Retrieve data from a dw:// address."""
        bucket, key = self._parse_dw_uri(dw_uri)
        stream = self._s3.get_object(bucket, key)
        return stream.read()

    def delete(self, dw_uri: str) -> None:
        """Delete object at a dw:// address."""
        bucket, key = self._parse_dw_uri(dw_uri)
        self._s3.delete_object(bucket, key)

    def exists(self, dw_uri: str) -> bool:
        """Check if object exists at a dw:// address."""
        bucket, key = self._parse_dw_uri(dw_uri)
        return self._s3.object_exists(bucket, key)

    def list(self, dw_uri: str, max_keys: int = 1000) -> List[Dict]:
        """List objects under a dw:// prefix."""
        bucket, key = self._parse_dw_uri(dw_uri)
        return list(self._s3.list_objects(bucket, prefix=key, max_keys=max_keys))

    def copy(self, source_uri: str, dest_uri: str) -> Dict:
        """Copy object between dw:// addresses."""
        src_bucket, src_key = self._parse_dw_uri(source_uri)
        dst_bucket, dst_key = self._parse_dw_uri(dest_uri)
        return self._s3.copy_object(src_bucket, src_key, dst_bucket, dst_key)

    def upload_file(self, dw_uri: str, file_path: str) -> None:
        """Upload a local file to a dw:// address with automatic multipart."""
        bucket, key = self._parse_dw_uri(dw_uri)
        self._s3.upload_file(bucket, key, file_path)

    def download_file(self, dw_uri: str, file_path: str) -> None:
        """Download from a dw:// address to a local file."""
        bucket, key = self._parse_dw_uri(dw_uri)
        self._s3.download_file(bucket, key, file_path)

    # Bucket management
    def create_bucket(self, name: str) -> None: self._s3.create_bucket(name)
    def delete_bucket(self, name: str) -> None: self._s3.delete_bucket(name)
    def list_buckets(self) -> List[Dict]: return self._s3.list_buckets()

    # Presigned URLs
    def presign(self, dw_uri: str, method: str = "GET", expires_in: int = 3600) -> str:
        bucket, key = self._parse_dw_uri(dw_uri)
        if method.upper() == "PUT":
            return self._s3.presign_put(bucket, key, expires_in)
        return self._s3.presign_get(bucket, key, expires_in)

    @staticmethod
    def _parse_dw_uri(uri: str) -> tuple:
        """Parse dw://bucket/key into (bucket, key)."""
        if uri.startswith("dw://"):
            uri = uri[5:]
        elif uri.startswith("s3://"):
            uri = uri[5:]
        parts = uri.split("/", 1)
        bucket = parts[0]
        key = parts[1] if len(parts) > 1 else ""
        if not bucket:
            raise ValueError(f"Invalid dw:// URI: missing bucket name")
        return bucket, key
```

Include full docstrings on all methods with usage examples.
  </action>
  <verify>python -c "import ast; ast.parse(open('Clients/python/dw_client/client.py').read()); print('OK')"</verify>
  <done>DataWarehouseClient provides dw:// addressing over S3 protocol; all methods implemented (not stubs)</done>
</task>

</tasks>

<verification>
- Python source files are syntactically valid
- All methods are implemented (not pass/stub)
- Package installable via `pip install -e Clients/python/`
</verification>

<success_criteria>
- Python client connects to DataWarehouse S3 endpoint via boto3
- dw:// URIs parsed correctly to bucket/key
- File upload/download with automatic multipart
- Presigned URL generation works
</success_criteria>

<output>
After completion, create `.planning/phases/63-universal-fabric/63-11-SUMMARY.md`
</output>
