---
phase: 29-advanced-distributed-coordination
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - DataWarehouse.SDK/Infrastructure/Distributed/Membership/SwimClusterMembership.cs
  - DataWarehouse.SDK/Infrastructure/Distributed/Membership/SwimProtocolState.cs
  - DataWarehouse.SDK/Infrastructure/Distributed/Replication/GossipReplicator.cs
autonomous: true

must_haves:
  truths:
    - "SWIM probe loop selects random peers and detects failures via direct ping + indirect ping-req"
    - "Suspected nodes transition to Dead after configurable suspicion timeout"
    - "Incarnation numbers allow nodes to refute false suspicion"
    - "Membership changes (join/leave/suspect/dead) propagate epidemically via gossip piggyback"
    - "Gossip replicator spreads arbitrary data via bounded epidemic propagation"
  artifacts:
    - path: "DataWarehouse.SDK/Infrastructure/Distributed/Membership/SwimClusterMembership.cs"
      provides: "IClusterMembership implementation with SWIM failure detection"
      min_lines: 300
    - path: "DataWarehouse.SDK/Infrastructure/Distributed/Membership/SwimProtocolState.cs"
      provides: "SWIM per-member state machine with incarnation numbers"
      min_lines: 60
    - path: "DataWarehouse.SDK/Infrastructure/Distributed/Replication/GossipReplicator.cs"
      provides: "IGossipProtocol implementation for P2P epidemic data propagation"
      min_lines: 150
  key_links:
    - from: "SwimClusterMembership"
      to: "IP2PNetwork"
      via: "constructor injection for inter-node communication"
      pattern: "IP2PNetwork.*_network"
    - from: "SwimClusterMembership"
      to: "IGossipProtocol"
      via: "uses gossip to disseminate membership changes"
      pattern: "IGossipProtocol|SpreadAsync"
    - from: "GossipReplicator"
      to: "IP2PNetwork"
      via: "uses P2P network for message delivery"
      pattern: "IP2PNetwork.*_network"
    - from: "SwimClusterMembership"
      to: "SwimProtocolState"
      via: "tracks per-member SWIM state"
      pattern: "SwimMemberState|SwimProtocolState"
---

<objective>
Implement SWIM gossip cluster membership (DIST-12) and P2P gossip-based data replication (DIST-15) as SDK-level classes.

Purpose: Provide decentralized cluster membership with automatic failure detection (SWIM protocol) and epidemic data propagation (gossip replication). These are foundational -- Raft (29-02) and CRDT replication (29-03) depend on membership discovery and gossip transport.

Output:
- `SwimClusterMembership` implementing `IClusterMembership` with SWIM probe/suspect/dead lifecycle
- `SwimProtocolState` tracking per-member incarnation numbers and status transitions
- `GossipReplicator` implementing `IGossipProtocol` for bounded epidemic data propagation
</objective>

<execution_context>
@C:/Users/ddamien/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/ddamien/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/29-advanced-distributed-coordination/29-RESEARCH.md

@DataWarehouse.SDK/Contracts/Distributed/IClusterMembership.cs
@DataWarehouse.SDK/Contracts/Distributed/IP2PNetwork.cs
@DataWarehouse.SDK/Infrastructure/InMemory/InMemoryClusterMembership.cs
@DataWarehouse.SDK/Infrastructure/InMemory/InMemoryP2PNetwork.cs
</context>

<tasks>

<task type="auto">
  <name>Task 1: SWIM Protocol State and Cluster Membership</name>
  <files>
    DataWarehouse.SDK/Infrastructure/Distributed/Membership/SwimProtocolState.cs
    DataWarehouse.SDK/Infrastructure/Distributed/Membership/SwimClusterMembership.cs
  </files>
  <action>
Create the `Distributed/Membership/` directory under `DataWarehouse.SDK/Infrastructure/`.

**File 1: SwimProtocolState.cs**

Create in namespace `DataWarehouse.SDK.Infrastructure.Distributed`:

1. `SwimConfiguration` record with properties:
   - `ProtocolPeriodMs` (int, default 1000) -- probe cycle interval
   - `PingTimeoutMs` (int, default 500) -- direct ping timeout
   - `IndirectPingCount` (int, default 3) -- number of indirect probers
   - `SuspicionTimeoutMs` (int, default 5000) -- time before Suspected -> Dead
   - `MaxGossipPiggybackSize` (int, default 10) -- max membership changes per message

2. `SwimMemberState` internal sealed class:
   - `ClusterNode Node` (get; set)
   - `ClusterNodeStatus Status` (get; set)
   - `int IncarnationNumber` (get; set)
   - `DateTimeOffset LastPingAt` (get; set)
   - `DateTimeOffset SuspectedAt` (get; set)

3. `SwimMessageType` internal enum: Ping, PingReq, Ack, Alive, Suspect, Dead, Join, Leave

4. `SwimMessage` internal sealed class with: Type, SourceNodeId, TargetNodeId, IncarnationNumber, MembershipUpdates (list of membership change DTOs), serializable via System.Text.Json.

**File 2: SwimClusterMembership.cs**

Create `SwimClusterMembership` sealed class implementing `IClusterMembership`:
- Namespace: `DataWarehouse.SDK.Infrastructure.Distributed`
- Attribute: `[SdkCompatibility("2.0.0", Notes = "Phase 29: SWIM gossip membership")]`

Constructor takes:
- `string nodeId, string address, int port` -- self identity
- `IP2PNetwork network` -- for inter-node communication
- `IGossipProtocol gossip` -- for membership change dissemination
- `SwimConfiguration? config = null` -- optional, defaults to new SwimConfiguration()

Internal state:
- `ConcurrentDictionary<string, SwimMemberState> _members` -- all known members
- `ClusterNode _self` -- local node
- `CancellationTokenSource _probeCts` -- for stopping probe loop
- `SemaphoreSlim _stateLock = new(1, 1)` -- for state transitions

Implement all `IClusterMembership` methods:
- `GetMembers()`: Return all members with Status != Dead
- `GetLeader()`: Return member with Role == Leader, or null (Raft sets this later via internal setter)
- `GetSelf()`: Return `_self`
- `JoinAsync()`: Add self to members, serialize Join message, broadcast via `_network.BroadcastAsync()`, start probe loop
- `LeaveAsync()`: Mark self as Leaving, broadcast Leave message, stop probe loop
- `IsHealthyAsync()`: Check member exists and Status == Active

Internal `SetLeader(string nodeId)` method for Raft integration (plan 29-02 will call this).

Probe loop (`StartProbeLoopAsync` / `RunProbeLoopAsync`):
- Use `PeriodicTimer(TimeSpan.FromMilliseconds(config.ProtocolPeriodMs))`
- Each tick: select random member, attempt direct ping via `_network.RequestFromPeerAsync`
- If ping times out (use `Task.WhenAny` with `Task.Delay(config.PingTimeoutMs)`): send PingReq to `config.IndirectPingCount` random members
- If indirect ping also fails: call `MarkSuspected(targetNodeId)`
- Also on each tick: check all Suspected members -- if `SuspectedAt + SuspicionTimeoutMs` elapsed, call `MarkDead(nodeId)`
- Piggyback: attach up to `MaxGossipPiggybackSize` recent membership changes to each ping/ack message

State transitions with events:
- `MarkSuspected(nodeId)`: Set status to Suspected, set SuspectedAt, fire OnMembershipChanged(NodeSuspected)
- `MarkDead(nodeId)`: Set status to Dead, fire OnMembershipChanged(NodeDead)
- `HandleAlive(nodeId, incarnation)`: If incarnation > current, reset to Active, fire event
- When self is suspected: increment own IncarnationNumber, broadcast Alive message (refutation)

Message handling:
- Subscribe to `_network.OnPeerEvent` and `_gossip.OnGossipReceived` for incoming SWIM messages
- Deserialize incoming messages (System.Text.Json) and dispatch to handlers
- Handle Ping -> respond with Ack, Handle PingReq -> forward ping to target, Handle Join -> add member, Handle Leave -> mark leaving
- Handle Suspect -> if incarnation >= current, mark suspected (unless self, then refute), Handle Alive -> update if newer incarnation

Thread safety: All state mutations through `_stateLock` or atomic ConcurrentDictionary operations. Use `RandomNumberGenerator.GetInt32()` for random peer selection (CRYPTO-02 compliance).

Serialize/deserialize SWIM messages as JSON byte[] for IP2PNetwork transport.

All async paths pass CancellationToken. Implement IDisposable to cancel probe loop CTS and dispose _stateLock.
  </action>
  <verify>
Run `dotnet build DataWarehouse.SDK/DataWarehouse.SDK.csproj` -- zero new errors. Verify files exist at expected paths. Grep for `IClusterMembership` in SwimClusterMembership.cs confirms interface implementation. Grep for `PeriodicTimer` confirms probe loop pattern. Grep for `RandomNumberGenerator` confirms CSPRNG usage.
  </verify>
  <done>
SwimClusterMembership fully implements IClusterMembership with SWIM probe/suspect/dead lifecycle. SwimProtocolState defines per-member state with incarnation numbers. Probe loop runs periodically with configurable intervals. State transitions fire OnMembershipChanged events. Self-refutation via incarnation number increment when suspected. All state access is thread-safe.
  </done>
</task>

<task type="auto">
  <name>Task 2: Gossip Replicator for P2P Data Propagation</name>
  <files>
    DataWarehouse.SDK/Infrastructure/Distributed/Replication/GossipReplicator.cs
  </files>
  <action>
Create the `Distributed/Replication/` directory under `DataWarehouse.SDK/Infrastructure/`.

**File: GossipReplicator.cs**

Create `GossipReplicator` sealed class implementing `IGossipProtocol`:
- Namespace: `DataWarehouse.SDK.Infrastructure.Distributed`
- Attribute: `[SdkCompatibility("2.0.0", Notes = "Phase 29: Gossip-based P2P replication")]`

Constructor takes:
- `IP2PNetwork network` -- for message delivery
- `IClusterMembership membership` -- for peer discovery
- `GossipReplicatorConfiguration? config = null`

`GossipReplicatorConfiguration` record:
- `MaxPendingMessages` (int, default 1000) -- bounded queue capacity
- `FanoutCount` (int, default 3) -- number of peers to forward each message to
- `MaxGenerations` (int, default 5) -- max hops before message expires
- `GossipIntervalMs` (int, default 500) -- background gossip sweep interval

Internal state:
- `Channel<GossipMessage> _pendingChannel` -- bounded with `BoundedChannelFullMode.DropOldest` (MUST be bounded per SDK rules)
- `ConcurrentDictionary<string, DateTimeOffset> _seenMessages` -- deduplication (MessageId -> first seen)
- `SemaphoreSlim _seenCleanupLock = new(1, 1)` -- for periodic seen-set pruning
- Bounded `_seenMessages` to 10,000 entries max -- evict oldest when exceeded

Implement `IGossipProtocol`:

`SpreadAsync(GossipMessage message, CancellationToken ct)`:
1. Check `message.Generation < config.MaxGenerations` -- if exceeded, drop silently
2. Add to `_seenMessages` for dedup
3. Select `min(config.FanoutCount, availablePeers)` random peers from `_membership.GetMembers()` (exclude self and origin)
4. For each selected peer: create new GossipMessage with `Generation + 1`, serialize to byte[], send via `_network.SendToPeerAsync(peer.NodeId, ...)`
5. Fire `OnGossipReceived` locally so the local node also processes the message

`GetPendingAsync(CancellationToken ct)`:
1. Read all available messages from `_pendingChannel.Reader` (non-blocking TryRead loop)
2. Return as `IReadOnlyList<GossipMessage>`

`OnGossipReceived` event: Fired when a gossip message arrives (either from SpreadAsync locally or from network).

Message reception:
- Subscribe to `_network.OnPeerEvent` for incoming data
- When data arrives: deserialize as GossipMessage, check `_seenMessages` for dedup (skip if already seen)
- If new: add to `_seenMessages`, write to `_pendingChannel.Writer`, fire `OnGossipReceived`, and re-spread (with incremented Generation) to `FanoutCount` random peers

Background cleanup task:
- Use `PeriodicTimer` at 60-second intervals
- Prune `_seenMessages` entries older than 5 minutes
- Prune to max 10,000 entries if exceeded (remove oldest)
- Pass CancellationToken throughout

Thread safety: ConcurrentDictionary for seen set, Channel<T> for pending queue (inherently thread-safe), RandomNumberGenerator for peer selection.

Implement IDisposable: cancel background tasks, complete _pendingChannel.Writer, dispose semaphore.

Use `using` aliases for type disambiguation if needed (follow InMemoryReplicationSync pattern):
```csharp
using SyncResult = DataWarehouse.SDK.Contracts.Distributed.SyncResult;
```
  </action>
  <verify>
Run `dotnet build DataWarehouse.SDK/DataWarehouse.SDK.csproj` -- zero new errors. Verify GossipReplicator.cs exists. Grep for `IGossipProtocol` confirms interface implementation. Grep for `Channel<GossipMessage>` confirms bounded channel. Grep for `BoundedChannelFullMode.DropOldest` confirms bounded behavior. Grep for `RandomNumberGenerator` confirms CSPRNG.
  </verify>
  <done>
GossipReplicator fully implements IGossipProtocol with bounded epidemic propagation. Messages spread to configurable fanout count of random peers. Generation tracking prevents infinite propagation. Deduplication via seen-message set prevents reprocessing. Bounded Channel<T> queue prevents memory growth. Background cleanup prunes stale dedup entries.
  </done>
</task>

</tasks>

<verification>
1. `dotnet build DataWarehouse.SDK/DataWarehouse.SDK.csproj` compiles with zero new errors
2. Three new files exist: SwimClusterMembership.cs, SwimProtocolState.cs, GossipReplicator.cs
3. SwimClusterMembership implements IClusterMembership (all 6 methods + event)
4. GossipReplicator implements IGossipProtocol (SpreadAsync, GetPendingAsync, OnGossipReceived)
5. All collections are bounded (ConcurrentDictionary with max size, Channel with BoundedChannelFullMode)
6. All async methods accept and propagate CancellationToken
7. RandomNumberGenerator used for all random selection (not System.Random)
8. System.Text.Json used for serialization (not Newtonsoft)
</verification>

<success_criteria>
- SWIM membership detects failures via configurable probe cycle (direct ping + indirect ping-req + suspicion timeout)
- Incarnation numbers allow nodes to refute false suspicion
- Gossip replicator provides bounded epidemic data propagation with deduplication
- All implementations are production-ready SDK-level classes (Rule 13)
- Zero new NuGet dependencies
- Build passes with zero errors
</success_criteria>

<output>
After completion, create `.planning/phases/29-advanced-distributed-coordination/29-01-SUMMARY.md`
</output>
