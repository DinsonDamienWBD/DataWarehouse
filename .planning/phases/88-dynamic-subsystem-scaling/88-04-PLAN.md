---
phase: 88-dynamic-subsystem-scaling
plan: 04
type: execute
wave: 2
depends_on: ["88-01"]
files_modified:
  - Plugins/DataWarehouse.Plugins.UltimateBlockchain/Scaling/SegmentedBlockStore.cs
  - Plugins/DataWarehouse.Plugins.UltimateBlockchain/Scaling/BlockchainScalingManager.cs
autonomous: true

must_haves:
  truths:
    - "List<Block> replaced with segmented page store using 64MB segments"
    - "VDEs with >2 billion blocks work correctly (no long-to-int cast)"
    - "Journal is sharded by block range for parallel write throughput"
    - "Per-tier locks replace single global lock for concurrent access"
    - "Manifest and validation caches are bounded with LRU eviction"
  artifacts:
    - path: "Plugins/DataWarehouse.Plugins.UltimateBlockchain/Scaling/SegmentedBlockStore.cs"
      provides: "Segmented mmap'd page store replacing List<Block>, 64MB segments, long addressing"
      exports: ["SegmentedBlockStore"]
    - path: "Plugins/DataWarehouse.Plugins.UltimateBlockchain/Scaling/BlockchainScalingManager.cs"
      provides: "IScalableSubsystem for blockchain with sharded journal, per-tier locks, bounded caches"
      exports: ["BlockchainScalingManager"]
  key_links:
    - from: "Plugins/DataWarehouse.Plugins.UltimateBlockchain/Scaling/SegmentedBlockStore.cs"
      to: "DataWarehouse.SDK/Contracts/Scaling/BoundedCache.cs"
      via: "Uses BoundedCache for block page cache with segment-level eviction"
      pattern: "BoundedCache"
    - from: "Plugins/DataWarehouse.Plugins.UltimateBlockchain/Scaling/BlockchainScalingManager.cs"
      to: "DataWarehouse.SDK/Contracts/Scaling/IScalableSubsystem.cs"
      via: "Implements IScalableSubsystem for blockchain subsystem"
      pattern: "IScalableSubsystem"
---

<objective>
Fix the blockchain scaling bug: replace unbounded List<Block> with a segmented store, fix the long-to-int cast for >2B blocks, shard the journal, and add per-tier locking.

Purpose: DSCL-04 -- blockchain currently crashes or corrupts data beyond ~2B blocks due to int cast, and the in-memory List<Block> exhausts memory. This makes blockchain production-ready at scale.

Output: Two new files providing segmented block store and blockchain scaling manager.
</objective>

<execution_context>
@C:/Users/ddamien/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/ddamien/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/88-dynamic-subsystem-scaling/88-01-SUMMARY.md
@Plugins/DataWarehouse.Plugins.UltimateBlockchain/
@DataWarehouse.SDK/Contracts/Scaling/BoundedCache.cs
@DataWarehouse.SDK/Contracts/Scaling/IScalableSubsystem.cs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create SegmentedBlockStore replacing List&lt;Block&gt;</name>
  <files>
    Plugins/DataWarehouse.Plugins.UltimateBlockchain/Scaling/SegmentedBlockStore.cs
  </files>
  <action>
Create `SegmentedBlockStore` that replaces unbounded `List<Block>` with a memory-mapped segmented page store:

1. **Segment structure**: Each segment is 64MB. Blocks are serialized contiguously within segments. Segment index maps block number range -> segment file/memory. Use `long` for all block indices (fix the int cast bug).

2. **Memory-mapped I/O**: Use `MemoryMappedFile` for hot segments (most recent N segments, configurable). Cold segments are file-backed only, loaded on demand via `IPersistentBackingStore`.

3. **Block addressing**: `long GetBlockIndex(long blockNumber)` maps block numbers to segment + offset. Support block numbers up to `long.MaxValue` (fix the `long -> int` cast that causes overflow at >2B blocks). Audit ALL casts from long to int in the blockchain plugin and replace with long-safe operations.

4. **Sharded journal**: Journal entries are partitioned by block range (configurable shard size, default 10,000 blocks per shard). Each shard has its own append-only file. Writes to different block ranges can proceed in parallel.

5. **Per-tier locking**: Replace the single `SemaphoreSlim` or `lock` with a `ConcurrentDictionary<string, SemaphoreSlim>` keyed by tier name. Operations on different tiers (hot/warm/cold) proceed concurrently. Within a tier, operations are serialized.

6. **Block page cache**: Use `BoundedCache<long, Block>` with LRU eviction for recently accessed blocks. Size from `ScalingLimits.MaxCacheEntries` (default 100,000 blocks).

Public API:
- `Task AppendBlockAsync(Block block, CancellationToken ct)` -- append to current segment, create new segment if full
- `Task<Block?> GetBlockAsync(long blockNumber, CancellationToken ct)` -- cache-first, then segment lookup
- `Task<IReadOnlyList<Block>> GetBlockRangeAsync(long start, long count, CancellationToken ct)` -- batch read
- `long BlockCount { get; }` -- total blocks across all segments (long, not int)
- `Task CompactAsync(CancellationToken ct)` -- merge small segments, defragment

`[SdkCompatibility("6.0.0")]` on all public types. Full XML docs.
  </action>
  <verify>
`dotnet build Plugins/DataWarehouse.Plugins.UltimateBlockchain/DataWarehouse.Plugins.UltimateBlockchain.csproj` compiles with 0 errors. Grep for `(int)` casts in the blockchain plugin to verify none remain on block indices.
  </verify>
  <done>SegmentedBlockStore uses 64MB memory-mapped segments. All block indices are long. Journal is sharded by block range. Per-tier locks enable concurrent access. Block page cache uses BoundedCache with LRU.</done>
</task>

<task type="auto">
  <name>Task 2: Create BlockchainScalingManager implementing IScalableSubsystem</name>
  <files>
    Plugins/DataWarehouse.Plugins.UltimateBlockchain/Scaling/BlockchainScalingManager.cs
  </files>
  <action>
Create `BlockchainScalingManager` implementing `IScalableSubsystem`:

1. **Wire SegmentedBlockStore**: Replace all references to `List<Block>` in UltimateBlockchainPlugin with calls through `SegmentedBlockStore`. Modify the plugin's `InitializeAsync` to create the scaling manager and store.

2. **Bounded caches**: Replace any `ConcurrentDictionary` used for manifest caching or validation caching with `BoundedCache<string, T>` instances. Manifest cache: LRU, default 10,000 entries. Validation cache: TTL (5 min), default 50,000 entries.

3. **IScalableSubsystem implementation**:
   - `GetScalingMetrics()`: block count, segment count, cache hit rates, journal shard count, per-tier lock contention
   - `ReconfigureLimitsAsync()`: change max cache entries, max concurrent writes, segment sizes at runtime
   - `CurrentLimits`: reflects current configuration
   - `CurrentBackpressureState`: monitors block append queue depth

4. **Configurable MaxConcurrentWrites**: Defaults to `Environment.ProcessorCount`. Configurable via `ScalingLimits.MaxConcurrentOperations`. Uses `SemaphoreSlim` to limit concurrent block appends.

`[SdkCompatibility("6.0.0")]` on all public types. Full XML docs.
  </action>
  <verify>
`dotnet build Plugins/DataWarehouse.Plugins.UltimateBlockchain/DataWarehouse.Plugins.UltimateBlockchain.csproj` compiles with 0 errors. Grep for `List<Block>` in the plugin directory -- should only appear in comments or documentation, not as field declarations.
  </verify>
  <done>BlockchainScalingManager wires SegmentedBlockStore into plugin. All unbounded collections replaced with BoundedCache. IScalableSubsystem provides metrics and runtime reconfiguration. MaxConcurrentWrites enforced via semaphore.</done>
</task>

</tasks>

<verification>
- Full solution builds with 0 errors
- No `List<Block>` field declarations in blockchain plugin (only in comments)
- No `(int)` casts on block indices
- `BoundedCache` used for manifest and validation caches
- Per-tier locks visible in code (ConcurrentDictionary of SemaphoreSlim or similar)
</verification>

<success_criteria>
Blockchain uses segmented 64MB mmap'd store with long addressing. No int overflow at >2B blocks. Journal sharded by block range. Per-tier locks enable concurrency. All caches bounded. Solution builds clean.
</success_criteria>

<output>
After completion, create `.planning/phases/88-dynamic-subsystem-scaling/88-04-SUMMARY.md`
</output>
