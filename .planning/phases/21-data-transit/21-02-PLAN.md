---
phase: 21-data-transit
plan: 02
type: execute
wave: 2
depends_on: ["21-01"]
files_modified:
  - Plugins/DataWarehouse.Plugins.UltimateDataTransit/Strategies/Chunked/ChunkedResumableStrategy.cs
  - Plugins/DataWarehouse.Plugins.UltimateDataTransit/Strategies/Chunked/DeltaDifferentialStrategy.cs
autonomous: true

must_haves:
  truths:
    - "ChunkedResumableStrategy splits large files into configurable chunks (default 4MB) with SHA-256 per chunk"
    - "Chunk manifest tracks each chunk's offset, size, hash, and completion status"
    - "Failed transfers resume from last completed chunk without re-transferring completed data"
    - "DeltaDifferentialStrategy computes rolling hash (Adler-32) on source and destination to identify changed blocks"
    - "Only changed blocks are transferred, reducing bandwidth for incremental updates"
    - "Both strategies integrate with the base class transfer ID and progress reporting"
  artifacts:
    - path: "Plugins/DataWarehouse.Plugins.UltimateDataTransit/Strategies/Chunked/ChunkedResumableStrategy.cs"
      provides: "Chunked upload/download with chunk manifest, SHA-256 integrity, resume capability"
      min_lines: 200
    - path: "Plugins/DataWarehouse.Plugins.UltimateDataTransit/Strategies/Chunked/DeltaDifferentialStrategy.cs"
      provides: "Rolling-hash delta sync transferring only changed blocks"
      min_lines: 180
  key_links:
    - from: "ChunkedResumableStrategy.ResumeTransferAsync"
      to: "chunk manifest"
      via: "reads manifest to find last completed chunk, resumes from there"
      pattern: "manifest.*chunk.*completed|resume.*offset"
    - from: "DeltaDifferentialStrategy.TransferAsync"
      to: "rolling hash comparison"
      via: "computes Adler-32 checksums on blocks, identifies differences, sends only changed blocks"
      pattern: "Adler|rolling.*hash|changed.*block"
---

<objective>
Implement chunked/resumable and delta/differential transfer strategies for handling large files and incremental updates.

Purpose: Enable reliable large-file transfers that survive interruptions and efficient incremental sync that minimizes bandwidth
Output: 2 advanced strategies (ChunkedResumable, DeltaDifferential) compiled and registered in the plugin
</objective>

<execution_context>
@C:/Users/ddamien/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/ddamien/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/21-data-transit/21-RESEARCH.md
@.planning/phases/21-data-transit/21-01-SUMMARY.md

# SDK contracts from Plan 01
@DataWarehouse.SDK/Contracts/Transit/IDataTransitStrategy.cs
@DataWarehouse.SDK/Contracts/Transit/DataTransitTypes.cs
@DataWarehouse.SDK/Contracts/Transit/DataTransitStrategyBase.cs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement ChunkedResumableStrategy with manifest tracking and integrity verification</name>
  <files>
    Plugins/DataWarehouse.Plugins.UltimateDataTransit/Strategies/Chunked/ChunkedResumableStrategy.cs
  </files>
  <action>
Create `internal sealed class ChunkedResumableStrategy : DataTransitStrategyBase` in namespace `DataWarehouse.Plugins.UltimateDataTransit.Strategies.Chunked`.

**Strategy identity:**
- StrategyId: "transit-chunked-resumable"
- Name: "Chunked Resumable Transfer"
- Capabilities: SupportsResumable=true, SupportsStreaming=true, SupportsCompression=true, SupportsEncryption=true, MaxTransferSizeBytes=long.MaxValue, SupportedProtocols=["http", "https", "http2", "http3"]

**Chunk manifest:** Define internal sealed record `ChunkManifest`:
- `string TransferId`
- `long TotalSize`
- `int ChunkSizeBytes` (default 4 * 1024 * 1024 = 4MB)
- `List<ChunkInfo> Chunks` where `ChunkInfo` is: `int Index, long Offset, int Size, string? Sha256Hash, bool Completed`

**TransferAsync implementation:**
1. Generate transfer ID via base class `GenerateTransferId()`
2. Compute total size from `request.SizeBytes` or `request.DataStream.Length`
3. Create `ChunkManifest` with chunks computed from total size / chunk size
4. For each chunk:
   a. Read chunk bytes from source stream at offset
   b. Compute SHA-256 hash of chunk bytes using `System.Security.Cryptography.SHA256.HashData()`
   c. Store hash in manifest
   d. Transfer chunk to destination using HttpClient POST to `{destination.Uri}/chunks/{transferId}/{chunkIndex}` with Content-Range header
   e. Mark chunk Completed=true in manifest
   f. Report progress via IProgress<TransitProgress> with percent = completedChunks / totalChunks * 100
5. After all chunks complete, POST manifest to `{destination.Uri}/manifest/{transferId}` for server-side assembly
6. Return TransitResult with success, total bytes, duration, SHA-256 of full content

**ResumeTransferAsync implementation:**
1. Retrieve stored manifest for `transferId` from `ConcurrentDictionary<string, ChunkManifest> _manifests`
2. Find first chunk where Completed=false
3. Resume from that chunk index, following same logic as TransferAsync step 4+
4. Skip completed chunks entirely (do not re-transfer or re-hash them)

**CancelTransferAsync:** Use CancellationTokenSource from base class active transfer tracking.

**Thread safety:** Use `ConcurrentDictionary<string, ChunkManifest>` for manifest storage. Use Interlocked for byte counters.

**Error handling:** If a chunk transfer fails, do NOT mark it completed. Store manifest state so ResumeTransferAsync can pick up. Retry individual chunks up to 3 times with exponential backoff (1s, 2s, 4s) before failing the whole transfer.

XML docs on all public/internal members. No Task.Run wrapping. All async throughout.
  </action>
  <verify>
Build: `dotnet build Plugins/DataWarehouse.Plugins.UltimateDataTransit/DataWarehouse.Plugins.UltimateDataTransit.csproj`
Expect: 0 errors
Grep: `rg "TODO|NotImplementedException|simulate|placeholder" Plugins/DataWarehouse.Plugins.UltimateDataTransit/Strategies/Chunked/ChunkedResumableStrategy.cs`
Expect: 0 matches
  </verify>
  <done>
ChunkedResumableStrategy compiles and implements: chunk splitting with configurable size, SHA-256 per-chunk integrity, manifest-based resume from last completed chunk, exponential backoff retry per chunk, progress reporting.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement DeltaDifferentialStrategy with rolling-hash block comparison</name>
  <files>
    Plugins/DataWarehouse.Plugins.UltimateDataTransit/Strategies/Chunked/DeltaDifferentialStrategy.cs
  </files>
  <action>
Create `internal sealed class DeltaDifferentialStrategy : DataTransitStrategyBase` in namespace `DataWarehouse.Plugins.UltimateDataTransit.Strategies.Chunked`.

**Strategy identity:**
- StrategyId: "transit-delta-differential"
- Name: "Delta Differential Transfer"
- Capabilities: SupportsDelta=true, SupportsResumable=false, SupportsStreaming=true, MaxTransferSizeBytes=long.MaxValue, SupportedProtocols=["http", "https", "http2", "rsync"]

**Rolling hash implementation** (rsync-style algorithm):
Define `internal sealed class RollingHashComputer`:
- Block size: configurable, default 4096 bytes
- `uint ComputeAdler32(ReadOnlySpan<byte> data)` - Adler-32 weak hash:
  ```
  s1 = 1 + sum(data[i]) mod 65521
  s2 = sum(s1 after each byte) mod 65521
  return (s2 << 16) | s1
  ```
- `byte[] ComputeStrongHash(ReadOnlySpan<byte> data)` - SHA-256 for collision resolution using `SHA256.HashData()`
- `uint RollHash(uint currentHash, byte removedByte, byte addedByte, int blockSize)` - O(1) rolling update:
  ```
  s1 = ((currentHash & 0xFFFF) - removedByte + addedByte) mod 65521
  s2 = ((currentHash >> 16) - blockSize * removedByte + s1 - 1) mod 65521
  return (s2 << 16) | s1
  ```

**Block signature:** `internal sealed record BlockSignature(int Index, long Offset, int Size, uint WeakHash, byte[] StrongHash)`

**TransferAsync implementation:**
1. Generate transfer ID
2. **Signature phase:** Request destination block signatures via HTTP GET `{destination.Uri}/signatures/{path}?blockSize={blockSize}`
   - If destination doesn't have the file (404), fall back to full transfer using HttpClient
   - Parse response as list of `BlockSignature`
3. **Matching phase:** Build dictionary of weak hash -> list of BlockSignature from destination signatures. Scan source data stream:
   - Compute rolling Adler-32 over sliding window of `blockSize`
   - If weak hash matches a destination block, compute strong SHA-256 hash and compare
   - If strong hash matches -> block is unchanged, record as "match at source offset X -> dest block index Y"
   - If no match -> record as "literal data" (bytes to transfer)
4. **Transfer phase:** Send delta instruction set to destination:
   - POST to `{destination.Uri}/delta/{transferId}` with binary payload containing:
     - Match instructions: (type=MATCH, destBlockIndex, sourceOffset)
     - Literal instructions: (type=LITERAL, offset, length, data)
5. Report progress: track bytes analyzed vs total, bytes to transfer vs total (show savings)
6. Return TransitResult with BytesTransferred = actual bytes sent (not total file size), Metadata includes "deltaSavingsPercent"

**IsAvailableAsync:** Check if destination supports delta protocol by HEAD request to `{endpoint.Uri}/signatures` expecting 200 or 501.

**Thread safety:** RollingHashComputer is stateless and thread-safe. Transfer state tracked via base class.

XML docs on all members. Use `System.IO.Hashing` for any additional hash needs. No `System.Security.Cryptography.MD5` (use SHA-256 for strong hash per research recommendation).
  </action>
  <verify>
Build: `dotnet build Plugins/DataWarehouse.Plugins.UltimateDataTransit/DataWarehouse.Plugins.UltimateDataTransit.csproj`
Expect: 0 errors
Grep: `rg "TODO|NotImplementedException|simulate|placeholder" Plugins/DataWarehouse.Plugins.UltimateDataTransit/Strategies/Chunked/DeltaDifferentialStrategy.cs`
Expect: 0 matches
  </verify>
  <done>
DeltaDifferentialStrategy compiles with: Adler-32 rolling hash, SHA-256 strong hash for collision resolution, rsync-style block matching, delta instruction transfer (match + literal), bandwidth savings tracking. RollingHashComputer is stateless and O(1) per byte for rolling updates.
  </done>
</task>

</tasks>

<verification>
- [ ] Plugin builds: `dotnet build Plugins/DataWarehouse.Plugins.UltimateDataTransit/DataWarehouse.Plugins.UltimateDataTransit.csproj` passes with 0 errors
- [ ] ChunkedResumableStrategy implements ResumeTransferAsync with manifest-based resume
- [ ] DeltaDifferentialStrategy implements rolling-hash delta sync with Adler-32 + SHA-256
- [ ] No forbidden patterns (TODO, NotImplementedException, simulate, placeholder, stub)
- [ ] Both strategies extend DataTransitStrategyBase
- [ ] All types have XML documentation
</verification>

<success_criteria>
Phase 21 Plan 02 succeeds when:
1. ChunkedResumableStrategy splits files into 4MB chunks with SHA-256 integrity per chunk
2. Resume capability works by reading manifest and skipping completed chunks
3. DeltaDifferentialStrategy computes Adler-32 rolling hash with SHA-256 strong hash verification
4. Delta transfer sends only changed blocks, not the entire file
5. Both strategies compile with zero Rule 13 violations
</success_criteria>

<output>
After completion, create `.planning/phases/21-data-transit/21-02-SUMMARY.md`
</output>
