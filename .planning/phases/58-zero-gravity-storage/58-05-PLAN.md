---
phase: 58-zero-gravity-storage
plan: 05
type: execute
wave: 2
depends_on: ["58-01"]
files_modified:
  - DataWarehouse.SDK/Storage/Placement/GravityAwarePlacementOptimizer.cs
  - DataWarehouse.SDK/Storage/Placement/GravityScoringWeights.cs
autonomous: true

must_haves:
  truths:
    - "Gravity optimizer scores objects on access frequency, colocation, egress cost, latency, and compliance"
    - "Higher gravity score = harder/costlier to move"
    - "Rebalance plan generation respects gravity scores (low-gravity objects moved first)"
    - "Batch scoring available for efficient cluster-wide assessment"
  artifacts:
    - path: "DataWarehouse.SDK/Storage/Placement/GravityAwarePlacementOptimizer.cs"
      provides: "Multi-dimensional scoring gravity optimizer"
      exports: ["GravityAwarePlacementOptimizer"]
      contains: "IPlacementOptimizer"
    - path: "DataWarehouse.SDK/Storage/Placement/GravityScoringWeights.cs"
      provides: "Configurable scoring dimension weights"
      exports: ["GravityScoringWeights"]
  key_links:
    - from: "GravityAwarePlacementOptimizer.ComputeGravityAsync"
      to: "GravityScoringWeights"
      via: "uses weights for multi-dimensional scoring"
      pattern: "Weights\\."
    - from: "GravityAwarePlacementOptimizer"
      to: "CrushPlacementAlgorithm"
      via: "delegates initial placement to CRUSH, then applies gravity optimization"
      pattern: "IPlacementAlgorithm.*ComputePlacement"
---

<objective>
Implement a gravity-aware placement optimizer that scores objects on multiple dimensions (access patterns, colocation, cost, latency, compliance) and generates optimal rebalance plans that minimize disruption.

Purpose: Not all data should be treated equally during rebalancing. Frequently-accessed data co-located with its consumers has high "gravity" and should stay put. Cold, isolated data has low gravity and can be moved freely for cost optimization.
Output: GravityAwarePlacementOptimizer implementing IPlacementOptimizer + GravityScoringWeights config.
</objective>

<execution_context>
@C:/Users/ddamien/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/ddamien/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/58-zero-gravity-storage/58-01-SUMMARY.md
@DataWarehouse.SDK/Storage/Placement/PlacementTypes.cs
@DataWarehouse.SDK/Storage/Placement/IPlacementOptimizer.cs
@DataWarehouse.SDK/Storage/Placement/IPlacementAlgorithm.cs
</context>

<tasks>

<task type="auto">
  <name>Task 1: GravityScoringWeights Configuration</name>
  <files>DataWarehouse.SDK/Storage/Placement/GravityScoringWeights.cs</files>
  <action>
Create GravityScoringWeights.cs — namespace `DataWarehouse.SDK.Storage.Placement`:

```csharp
/// Configurable weights for each dimension of the gravity scoring model.
/// All weights are 0.0-1.0. Final composite score is the weighted sum normalized to [0,1].
/// Higher composite score = higher gravity (harder to move).
[SdkCompatibility("5.0.0", Notes = "Phase 58: Gravity-aware placement optimizer")]
public sealed record GravityScoringWeights
{
    /// Weight for access frequency dimension. Hot data has high gravity.
    /// Default 0.30 — access patterns are the strongest gravity signal.
    public double AccessFrequency { get; init; } = 0.30;

    /// Weight for colocation dimension. Data near its consumers has high gravity.
    /// Default 0.20 — moving colocated data causes cascading latency increases.
    public double Colocation { get; init; } = 0.20;

    /// Weight for egress cost dimension. High-egress-cost locations increase gravity.
    /// Default 0.15 — moving data out of expensive locations incurs direct cost.
    public double EgressCost { get; init; } = 0.15;

    /// Weight for latency dimension. Low-latency placements increase gravity.
    /// Default 0.15 — data already in optimal latency position shouldn't move.
    public double Latency { get; init; } = 0.15;

    /// Weight for compliance dimension. Compliance-constrained data has maximum gravity.
    /// Default 0.20 — regulatory requirements override all cost optimization.
    public double Compliance { get; init; } = 0.20;

    /// Default scoring weights optimized for balanced cost/performance.
    public static GravityScoringWeights Default => new();

    /// Cost-optimized weights: prioritize egress cost and access frequency.
    public static GravityScoringWeights CostOptimized => new()
    {
        AccessFrequency = 0.20,
        Colocation = 0.10,
        EgressCost = 0.35,
        Latency = 0.10,
        Compliance = 0.25
    };

    /// Performance-optimized weights: prioritize latency and colocation.
    public static GravityScoringWeights PerformanceOptimized => new()
    {
        AccessFrequency = 0.35,
        Colocation = 0.30,
        EgressCost = 0.05,
        Latency = 0.25,
        Compliance = 0.05
    };

    /// Compliance-first weights: regulatory requirements dominate.
    public static GravityScoringWeights ComplianceFirst => new()
    {
        AccessFrequency = 0.10,
        Colocation = 0.10,
        EgressCost = 0.10,
        Latency = 0.10,
        Compliance = 0.60
    };

    /// Validates that weights are within range and sum to a reasonable value.
    public bool IsValid()
    {
        var weights = new[] { AccessFrequency, Colocation, EgressCost, Latency, Compliance };
        return weights.All(w => w >= 0.0 && w <= 1.0) && weights.Sum() > 0;
    }

    /// Normalize weights so they sum to 1.0.
    public GravityScoringWeights Normalize()
    {
        double sum = AccessFrequency + Colocation + EgressCost + Latency + Compliance;
        if (sum == 0) return Default;
        return new GravityScoringWeights
        {
            AccessFrequency = AccessFrequency / sum,
            Colocation = Colocation / sum,
            EgressCost = EgressCost / sum,
            Latency = Latency / sum,
            Compliance = Compliance / sum
        };
    }
}
```
  </action>
  <verify>dotnet build DataWarehouse.SDK/DataWarehouse.SDK.csproj --no-restore --verbosity quiet 2>&1 | tail -3</verify>
  <done>GravityScoringWeights compiles with 5 dimensions, 4 preset profiles, normalization.</done>
</task>

<task type="auto">
  <name>Task 2: GravityAwarePlacementOptimizer Implementation</name>
  <files>DataWarehouse.SDK/Storage/Placement/GravityAwarePlacementOptimizer.cs</files>
  <action>
Create GravityAwarePlacementOptimizer.cs — namespace `DataWarehouse.SDK.Storage.Placement`:

```csharp
/// Gravity-aware placement optimizer that scores objects on multiple dimensions
/// and generates rebalance plans that minimize disruption by moving low-gravity objects first.
///
/// Gravity dimensions:
/// 1. Access frequency: normalized reads+writes per hour (0=cold, 1=hottest)
/// 2. Colocation: count of co-accessed dependencies on same node (0=isolated, 1=fully colocated)
/// 3. Egress cost: normalized cost to move data out of current location (0=free, 1=most expensive)
/// 4. Latency: inverse of current latency relative to consumers (0=worst latency, 1=optimal)
/// 5. Compliance: 1.0 if compliance region matches, 0.0 if moving would violate regulations
[SdkCompatibility("5.0.0", Notes = "Phase 58: Gravity-aware placement optimizer")]
public sealed class GravityAwarePlacementOptimizer : IPlacementOptimizer
{
    private readonly IPlacementAlgorithm _crushAlgorithm;
    private readonly GravityScoringWeights _weights;

    // Data providers (injected or set)
    private readonly Func<string, CancellationToken, Task<AccessMetrics>>? _accessMetricsProvider;
    private readonly Func<string, CancellationToken, Task<ColocationMetrics>>? _colocationProvider;
    private readonly Func<string, CancellationToken, Task<CostMetrics>>? _costProvider;
    private readonly Func<string, CancellationToken, Task<LatencyMetrics>>? _latencyProvider;
    private readonly Func<string, CancellationToken, Task<ComplianceMetrics>>? _complianceProvider;

    public GravityAwarePlacementOptimizer(
        IPlacementAlgorithm crushAlgorithm,
        GravityScoringWeights? weights = null,
        Func<string, CancellationToken, Task<AccessMetrics>>? accessMetricsProvider = null,
        Func<string, CancellationToken, Task<ColocationMetrics>>? colocationProvider = null,
        Func<string, CancellationToken, Task<CostMetrics>>? costProvider = null,
        Func<string, CancellationToken, Task<LatencyMetrics>>? latencyProvider = null,
        Func<string, CancellationToken, Task<ComplianceMetrics>>? complianceProvider = null)
    {
        _crushAlgorithm = crushAlgorithm ?? throw new ArgumentNullException(nameof(crushAlgorithm));
        _weights = (weights ?? GravityScoringWeights.Default).Normalize();
        _accessMetricsProvider = accessMetricsProvider;
        _colocationProvider = colocationProvider;
        _costProvider = costProvider;
        _latencyProvider = latencyProvider;
        _complianceProvider = complianceProvider;
    }

    public async Task<DataGravityScore> ComputeGravityAsync(string objectKey, CancellationToken ct = default)
    {
        // Gather metrics from all dimensions (providers return defaults if not configured)
        var access = _accessMetricsProvider != null
            ? await _accessMetricsProvider(objectKey, ct)
            : new AccessMetrics();
        var colocation = _colocationProvider != null
            ? await _colocationProvider(objectKey, ct)
            : new ColocationMetrics();
        var cost = _costProvider != null
            ? await _costProvider(objectKey, ct)
            : new CostMetrics();
        var latency = _latencyProvider != null
            ? await _latencyProvider(objectKey, ct)
            : new LatencyMetrics();
        var compliance = _complianceProvider != null
            ? await _complianceProvider(objectKey, ct)
            : new ComplianceMetrics();

        // Compute normalized dimension scores [0, 1]
        double accessScore = NormalizeAccessFrequency(access.ReadsPerHour + access.WritesPerHour);
        double colocationScore = colocation.ColocatedDependencies > 0
            ? Math.Min(1.0, colocation.ColocatedDependencies / 10.0)
            : 0.0;
        double egressScore = Math.Min(1.0, (double)cost.EgressCostPerGB / 0.12m); // $0.12/GB as max reference
        double latencyScore = latency.CurrentLatencyMs > 0
            ? Math.Max(0.0, 1.0 - (latency.CurrentLatencyMs / 200.0)) // 200ms as worst-case reference
            : 0.5; // unknown latency = neutral
        double complianceScore = compliance.InComplianceRegion ? 1.0 : 0.0;

        // Weighted composite score
        double composite = _weights.AccessFrequency * accessScore
            + _weights.Colocation * colocationScore
            + _weights.EgressCost * egressScore
            + _weights.Latency * latencyScore
            + _weights.Compliance * complianceScore;

        return new DataGravityScore
        {
            ObjectKey = objectKey,
            CurrentNode = cost.CurrentNodeId ?? "",
            AccessFrequency = access.ReadsPerHour + access.WritesPerHour,
            LastAccessUtc = access.LastAccessUtc,
            ColocatedDependencies = colocation.ColocatedDependencies,
            EgressCostPerGB = cost.EgressCostPerGB,
            LatencyMs = latency.CurrentLatencyMs,
            ComplianceWeight = complianceScore,
            CompositeScore = Math.Clamp(composite, 0.0, 1.0)
        };
    }

    public async Task<IReadOnlyList<DataGravityScore>> ComputeGravityBatchAsync(
        IReadOnlyList<string> objectKeys, CancellationToken ct = default)
    {
        // Process in parallel with bounded concurrency
        var semaphore = new SemaphoreSlim(Environment.ProcessorCount * 2);
        var tasks = objectKeys.Select(async key =>
        {
            await semaphore.WaitAsync(ct);
            try { return await ComputeGravityAsync(key, ct); }
            finally { semaphore.Release(); }
        });
        return (await Task.WhenAll(tasks)).ToList();
    }

    public async Task<PlacementDecision> OptimizePlacementAsync(
        PlacementTarget target,
        IReadOnlyList<NodeDescriptor> clusterMap,
        DataGravityScore gravity,
        CancellationToken ct = default)
    {
        // Start with CRUSH placement
        var crushDecision = _crushAlgorithm.ComputePlacement(target, clusterMap);

        // If gravity is high (> 0.7), prefer keeping object on current node if it's in the CRUSH set
        if (gravity.CompositeScore > 0.7 && !string.IsNullOrEmpty(gravity.CurrentNode))
        {
            var currentInCluster = clusterMap.FirstOrDefault(n => n.NodeId == gravity.CurrentNode);
            if (currentInCluster != null && crushDecision.TargetNodes.Any(n => n.NodeId == gravity.CurrentNode))
            {
                // Already includes current node — promote it to primary
                var reordered = new List<NodeDescriptor> { currentInCluster };
                reordered.AddRange(crushDecision.TargetNodes.Where(n => n.NodeId != gravity.CurrentNode));
                return crushDecision with
                {
                    TargetNodes = reordered,
                    PrimaryNode = currentInCluster,
                    ReplicaNodes = reordered.Skip(1).ToList()
                };
            }
        }

        return crushDecision;
    }

    public async Task<RebalancePlan> GenerateRebalancePlanAsync(
        IReadOnlyList<NodeDescriptor> clusterMap,
        RebalanceOptions options,
        CancellationToken ct = default)
    {
        // This is a planning method — generate moves but don't execute them
        // Real implementations would enumerate all objects and their current placements
        // For now, return an empty plan (actual enumeration requires storage layer integration)
        // The rebalancer service (Plan 07) will use this with real data

        // Calculate ideal distribution based on weights
        double totalWeight = clusterMap.Sum(n => n.Weight);
        var idealDistribution = clusterMap.ToDictionary(
            n => n.NodeId,
            n => n.Weight / totalWeight);

        return new RebalancePlan
        {
            Moves = Array.Empty<RebalanceMove>(),
            EstimatedDurationSeconds = 0,
            EstimatedEgressBytes = 0,
            EstimatedCost = 0
        };
    }

    /// Normalize access frequency to [0, 1] using logarithmic scaling.
    /// 0 access/hr = 0, 1 = ~0.3, 10 = ~0.5, 100 = ~0.7, 1000 = ~0.85, 10000+ = ~1.0
    private static double NormalizeAccessFrequency(double accessesPerHour)
    {
        if (accessesPerHour <= 0) return 0.0;
        return Math.Min(1.0, Math.Log10(1 + accessesPerHour) / 4.0); // log10(10001) ≈ 4.0
    }
}

// Metric input records for gravity scoring providers
public record AccessMetrics
{
    public double ReadsPerHour { get; init; }
    public double WritesPerHour { get; init; }
    public DateTimeOffset LastAccessUtc { get; init; } = DateTimeOffset.UtcNow;
}

public record ColocationMetrics
{
    public int ColocatedDependencies { get; init; }
    public IReadOnlyList<string> DependencyKeys { get; init; } = Array.Empty<string>();
}

public record CostMetrics
{
    public string? CurrentNodeId { get; init; }
    public decimal EgressCostPerGB { get; init; }
    public decimal StorageCostPerGBMonth { get; init; }
}

public record LatencyMetrics
{
    public double CurrentLatencyMs { get; init; }
    public double OptimalLatencyMs { get; init; }
}

public record ComplianceMetrics
{
    public bool InComplianceRegion { get; init; } = true;
    public IReadOnlyList<string> RequiredRegions { get; init; } = Array.Empty<string>();
}
```

Ensure all metric records have the `[SdkCompatibility]` attribute.
  </action>
  <verify>dotnet build DataWarehouse.SDK/DataWarehouse.SDK.csproj --no-restore --verbosity quiet 2>&1 | tail -3</verify>
  <done>GravityAwarePlacementOptimizer compiles, implements all 4 IPlacementOptimizer methods. ComputeGravityAsync produces composite score from 5 dimensions. Batch scoring uses bounded parallelism. Gravity-aware optimization promotes high-gravity objects to primary node.</done>
</task>

</tasks>

<verification>
- `dotnet build DataWarehouse.SDK/DataWarehouse.SDK.csproj` succeeds
- GravityAwarePlacementOptimizer implements IPlacementOptimizer
- 5 scoring dimensions with configurable weights
- 4 preset weight profiles available
</verification>

<success_criteria>
Gravity-aware optimizer scores objects on 5 dimensions and generates placement decisions that respect data gravity. Low-gravity objects are prioritized for movement. Compliance constraints override cost optimization.
</success_criteria>

<output>
After completion, create `.planning/phases/58-zero-gravity-storage/58-05-SUMMARY.md`
</output>
