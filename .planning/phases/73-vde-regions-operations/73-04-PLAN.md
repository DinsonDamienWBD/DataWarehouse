---
phase: 73-vde-regions-operations
plan: 04
type: execute
wave: 3
depends_on: ["73-01"]
files_modified:
  - DataWarehouse.SDK/VirtualDiskEngine/Regions/CompressionDictionaryRegion.cs
  - DataWarehouse.SDK/VirtualDiskEngine/Regions/MetricsLogRegion.cs
  - DataWarehouse.SDK/VirtualDiskEngine/Regions/AnonymizationTableRegion.cs
autonomous: true

must_haves:
  truths:
    - "Compression Dictionary Region manages up to 256 dictionaries addressable by 2-byte DictId"
    - "Dictionary lookup by DictId is O(1) via array indexing"
    - "Metrics Log records time-series samples and auto-compacts when capacity threshold is reached"
    - "Anonymization Table maps PII identifiers to anonymized tokens for GDPR right-to-be-forgotten"
    - "Anonymization Table supports bulk erasure of all mappings for a subject (GDPR compliance)"
    - "All three regions round-trip through Serialize/Deserialize with UniversalBlockTrailer verification"
  artifacts:
    - path: "DataWarehouse.SDK/VirtualDiskEngine/Regions/CompressionDictionaryRegion.cs"
      provides: "Compression Dictionary region with DICT block type"
      contains: "CompressionDictionaryRegion"
    - path: "DataWarehouse.SDK/VirtualDiskEngine/Regions/MetricsLogRegion.cs"
      provides: "Metrics Log region with MTRK block type"
      contains: "MetricsLogRegion"
    - path: "DataWarehouse.SDK/VirtualDiskEngine/Regions/AnonymizationTableRegion.cs"
      provides: "Anonymization Table region with ANON block type"
      contains: "AnonymizationTableRegion"
  key_links:
    - from: "CompressionDictionaryRegion"
      to: "BlockTypeTags.DICT"
      via: "UniversalBlockTrailer.Write"
      pattern: "BlockTypeTags\\.DICT"
    - from: "MetricsLogRegion"
      to: "BlockTypeTags.MTRK"
      via: "UniversalBlockTrailer.Write"
      pattern: "BlockTypeTags\\.MTRK"
    - from: "AnonymizationTableRegion"
      to: "BlockTypeTags.ANON"
      via: "UniversalBlockTrailer.Write"
      pattern: "BlockTypeTags\\.ANON"
---

<objective>
Implement three operational regions: Compression Dictionary (256 dictionaries, O(1) lookup), Metrics Log (time-series with auto-compaction), and Anonymization Table (GDPR PII-to-token mapping).

Purpose: Compression Dictionary enables per-data-type trained dictionaries (Zstd-style). Metrics Log records operational time-series. Anonymization Table supports GDPR right-to-be-forgotten by mapping PII to anonymized tokens with bulk erasure.
Output: Three new region files in DataWarehouse.SDK/VirtualDiskEngine/Regions/
</objective>

<execution_context>
@C:/Users/ddamien/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/ddamien/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

Block types: BlockTypeTags.DICT (0x44494354), BlockTypeTags.MTRK (0x4D54524B), BlockTypeTags.ANON (0x414E4F4E)
NOTE: MTRK is also used by IntegrityTreeRegion. For MetricsLogRegion, use BlockTypeTags.MTRK since the tag is named "Metrics tracker". The executor should verify this does not conflict -- if it does, the metrics region can share the tag (different region type IDs in the RegionDirectory distinguish them) or use a comment noting the shared tag.

@DataWarehouse.SDK/VirtualDiskEngine/Regions/StreamingAppendRegion.cs (ring buffer pattern for metrics)
@DataWarehouse.SDK/VirtualDiskEngine/Regions/ComplianceVaultRegion.cs (multi-block overflow)
@DataWarehouse.SDK/VirtualDiskEngine/Format/BlockTypeTags.cs
@DataWarehouse.SDK/VirtualDiskEngine/Format/UniversalBlockTrailer.cs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Compression Dictionary Region</name>
  <files>DataWarehouse.SDK/VirtualDiskEngine/Regions/CompressionDictionaryRegion.cs</files>
  <action>
Create `CompressionDictionaryRegion.cs` with:

1. `CompressionDictEntry` (readonly record struct, `[SdkCompatibility("6.0.0")]`):
   - `ushort DictId` -- 2-byte dictionary identifier (0-255 for user dictionaries, 256+ reserved)
   - `ushort AlgorithmId` -- compression algorithm (0=Zstd, 1=Brotli, 2=LZ4, 3=Deflate, 4=Custom)
   - `long BlockOffset` -- starting block where dictionary data is stored in the VDE
   - `int BlockCount` -- blocks occupied by the dictionary data
   - `int DictionarySizeBytes` -- exact byte size of the dictionary
   - `long TrainedUtcTicks` -- when the dictionary was trained
   - `long SampleCount` -- number of samples used to train this dictionary
   - `byte[] ContentHash` -- 32-byte SHA-256 of the dictionary data (for integrity)
   - `const int SerializedSize = 72` (2+2+8+4+4+8+8+4+32 = 72) -- wait, recalculate: 2+2+8+4+4+8+8+32 = 68. Add SampleCount:8 = 76. Let me be precise: DictId(2)+AlgorithmId(2)+BlockOffset(8)+BlockCount(4)+DictionarySizeBytes(4)+TrainedUtcTicks(8)+SampleCount(8)+ContentHash(32) = 68.
   - Actually: 2+2+8+4+4+8+8+32 = 68
   - `const int SerializedSize = 68`
   - `internal void WriteTo(Span<byte>, int offset)` / `internal static CompressionDictEntry ReadFrom(ReadOnlySpan<byte>, int offset)`

2. `CompressionDictionaryRegion` (sealed class, `[SdkCompatibility("6.0.0", Notes = "Phase 73: VDE regions -- Compression Dictionary (VREG-16)")]`):
   - `const int MaxDictionaries = 256` -- maximum dictionaries (DictId 0-255)
   - Internal: `CompressionDictEntry?[]` array of size 256 for O(1) lookup by DictId index. NOT a dictionary -- a flat array where index = DictId.
   - `uint Generation { get; set; }`
   - `int DictionaryCount` -- count of non-null entries
   - `void RegisterDictionary(CompressionDictEntry entry)` -- validates DictId < 256, hash is 32 bytes, rejects if slot occupied
   - `CompressionDictEntry? GetDictionary(ushort dictId)` -- O(1) array index lookup
   - `bool RemoveDictionary(ushort dictId)` -- sets slot to null
   - `bool ReplaceDictionary(CompressionDictEntry entry)` -- overwrites existing (for retraining)
   - `IReadOnlyList<CompressionDictEntry> GetDictionariesByAlgorithm(ushort algorithmId)` -- filter
   - `IReadOnlyList<CompressionDictEntry> GetAllDictionaries()` -- all non-null entries

   Serialization:
   - `int RequiredBlocks(int blockSize)` -- header + entries (only non-null entries serialized, with DictId prefix for sparse encoding)
   - Header: `[DictionaryCount:4 LE][Reserved:12][entries...]`
   - `void Serialize(Span<byte>, int blockSize)` / `static CompressionDictionaryRegion Deserialize(ReadOnlySpan<byte>, int blockSize, int blockCount)`
   - Use BlockTypeTags.DICT. Multi-block overflow for large dictionary sets.
  </action>
  <verify>
`dotnet build DataWarehouse.SDK/DataWarehouse.SDK.csproj --no-restore` compiles clean. Verify MaxDictionaries is 256 and GetDictionary returns via array index.
  </verify>
  <done>
CompressionDictionaryRegion.cs exists with 256-slot array for O(1) DictId lookup. Builds clean.
  </done>
</task>

<task type="auto">
  <name>Task 2: Metrics Log Region + Anonymization Table Region</name>
  <files>
    DataWarehouse.SDK/VirtualDiskEngine/Regions/MetricsLogRegion.cs
    DataWarehouse.SDK/VirtualDiskEngine/Regions/AnonymizationTableRegion.cs
  </files>
  <action>
**MetricsLogRegion.cs:**

1. `MetricsSample` (readonly record struct, `[SdkCompatibility("6.0.0")]`):
   - `ushort MetricId` -- identifies the metric (user-defined)
   - `long TimestampUtcTicks` -- when the sample was recorded
   - `double Value` -- the metric value
   - `byte AggregationType` -- 0=Raw, 1=Sum, 2=Average, 3=Min, 4=Max, 5=Count, 6=P99
   - `const int SerializedSize = 19` (2+8+8+1)
   - `internal void WriteTo(Span<byte>, int offset)` / `internal static MetricsSample ReadFrom(ReadOnlySpan<byte>, int offset)`

2. `MetricsLogRegion` (sealed class, `[SdkCompatibility("6.0.0", Notes = "Phase 73: VDE regions -- Metrics Log (VREG-17)")]`):
   - Internal: `List<MetricsSample>` for time-series storage
   - `uint Generation { get; set; }`
   - `long SampleCount` property
   - `long MaxCapacitySamples { get; }` -- configurable max samples before auto-compaction
   - `double CompactionThreshold { get; }` -- 0.0-1.0, percentage of capacity that triggers compaction (default 0.8)
   - Constructor: `MetricsLogRegion(long maxCapacitySamples, double compactionThreshold = 0.8)`
   - `void RecordSample(MetricsSample sample)` -- appends sample. If SampleCount >= MaxCapacitySamples * CompactionThreshold, calls AutoCompact before appending.
   - `void AutoCompact()` -- compacts by: (1) grouping consecutive samples with same MetricId into 1-minute windows, (2) replacing raw samples in each window with aggregated samples (one per metric per minute: average value, AggregationType=Average). This reduces sample count significantly.
   - `IReadOnlyList<MetricsSample> GetSamples(ushort metricId, long fromTicks, long toTicks)` -- range query
   - `IReadOnlyList<MetricsSample> GetLatestSamples(ushort metricId, int count)` -- most recent N
   - `IReadOnlyList<MetricsSample> GetAllSamples()`

   Serialization:
   - Header: `[SampleCount:8 LE][MaxCapacitySamples:8 LE][CompactionThreshold:8 LE (as double)][Reserved:8][samples...]`
   - `int RequiredBlocks(int blockSize)` / `void Serialize(Span<byte>, int blockSize)` / `static MetricsLogRegion Deserialize(ReadOnlySpan<byte>, int blockSize, int blockCount)`
   - Use BlockTypeTags.MTRK. Multi-block overflow.

**AnonymizationTableRegion.cs:**

1. `AnonymizationMapping` (readonly record struct, `[SdkCompatibility("6.0.0")]`):
   - `Guid MappingId` -- unique mapping identifier
   - `Guid SubjectId` -- the data subject (person) this PII belongs to
   - `ushort PiiType` -- 0=Name, 1=Email, 2=Phone, 3=SSN, 4=Address, 5=DOB, 6=IP, 7=Custom
   - `byte[] PiiHash` -- 32-byte SHA-256 hash of the original PII (we never store raw PII)
   - `byte[] AnonymizedToken` -- 32-byte anonymized replacement token
   - `long CreatedUtcTicks` -- when the mapping was created
   - `ushort Flags` -- bit 0: active, bit 1: erased (right-to-be-forgotten applied)
   - `const int SerializedSize = 102` (16+16+2+32+32+8+2 = 108) -- recalculate: 16+16+2+32+32+8+2 = 108
   - `const int SerializedSize = 108`
   - `internal void WriteTo(Span<byte>, int offset)` / `internal static AnonymizationMapping ReadFrom(ReadOnlySpan<byte>, int offset)`

2. `AnonymizationTableRegion` (sealed class, `[SdkCompatibility("6.0.0", Notes = "Phase 73: VDE regions -- Anonymization Table (VREG-18)")]`):
   - Internal: `List<AnonymizationMapping>` + `Dictionary<Guid, int>` index by MappingId + `Dictionary<Guid, List<int>>` index by SubjectId (for bulk erasure)
   - `uint Generation { get; set; }`
   - `int MappingCount` property
   - `void AddMapping(AnonymizationMapping mapping)` -- validates hashes are 32 bytes
   - `AnonymizationMapping? GetMapping(Guid mappingId)` -- O(1) lookup
   - `IReadOnlyList<AnonymizationMapping> GetMappingsBySubject(Guid subjectId)` -- all mappings for a data subject
   - `int EraseSubject(Guid subjectId)` -- GDPR right-to-be-forgotten: sets erased flag on ALL mappings for this subject, zeros out PiiHash and AnonymizedToken bytes. Returns count of erased mappings. Add XML doc: "Implements GDPR Article 17 right to erasure. After calling this method, the original PII cannot be recovered from this region."
   - `bool IsSubjectErased(Guid subjectId)` -- checks if all mappings for subject have erased flag
   - `IReadOnlyList<AnonymizationMapping> GetAllMappings()` -- snapshot (includes erased)
   - `IReadOnlyList<AnonymizationMapping> GetActiveMappings()` -- excludes erased

   Serialization:
   - Header: `[MappingCount:4 LE][Reserved:12][entries...]`
   - Use BlockTypeTags.ANON. Multi-block overflow.
   - On Deserialize, rebuild both dictionaries (MappingId index and SubjectId index).
  </action>
  <verify>
`dotnet build DataWarehouse.SDK/DataWarehouse.SDK.csproj --no-restore` compiles clean. Verify MetricsLogRegion has AutoCompact method. Verify AnonymizationTableRegion has EraseSubject method with GDPR doc comment.
  </verify>
  <done>
MetricsLogRegion.cs exists with time-series recording and auto-compaction. AnonymizationTableRegion.cs exists with PII-to-token mapping and GDPR bulk erasure. Both build clean.
  </done>
</task>

</tasks>

<verification>
1. `dotnet build DataWarehouse.SDK/DataWarehouse.SDK.csproj` -- zero errors
2. CompressionDictionaryRegion.MaxDictionaries == 256, uses flat array for O(1)
3. MetricsLogRegion.AutoCompact aggregates 1-minute windows
4. AnonymizationTableRegion.EraseSubject zeros out PII data
5. All three use correct BlockTypeTags (DICT, MTRK, ANON)
</verification>

<success_criteria>
- Compression Dictionary manages 256 dictionaries with O(1) lookup by DictId
- Metrics Log records time-series and auto-compacts at threshold
- Anonymization Table supports GDPR right-to-be-forgotten bulk erasure
- All three serialize/deserialize with trailer verification
- Build passes with zero errors
</success_criteria>

<output>
After completion, create `.planning/phases/73-vde-regions-operations/73-04-SUMMARY.md`
</output>
