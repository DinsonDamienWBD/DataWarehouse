using System;using System.Collections.Generic;using System.Net.Http;using System.Net.Http.Headers;using System.Runtime.CompilerServices;using System.Text;using System.Text.Json;using System.Threading;using System.Threading.Tasks;using DataWarehouse.SDK.Connectors;using Microsoft.Extensions.Logging;

namespace DataWarehouse.Plugins.UltimateConnector.Strategies.AI;

/// <summary>Helicone AI proxy. HTTPS to api.helicone.ai. LLM observability, request logging, rate limiting, caching.</summary>
public sealed class HeliconeConnectionStrategy : AiConnectionStrategyBase
{
    public override string StrategyId => "ai-helicone";public override string DisplayName => "Helicone";public override ConnectionStrategyCapabilities Capabilities => new(SupportsPooling: false, SupportsStreaming: true, SupportsAuthentication: true);public override string SemanticDescription => "Helicone AI observability proxy. LLM request logging, cost tracking, rate limiting, caching, and usage analytics.";public override string[] Tags => ["helicone", "llm-observability", "proxy", "logging", "cost-tracking", "caching"];
    public HeliconeConnectionStrategy(ILogger? logger = null) : base(logger) { }
    protected override async Task<IConnectionHandle> ConnectCoreAsync(ConnectionConfig config, CancellationToken ct){var baseUrl = config.ConnectionString ?? "https://oai.helicone.ai/v1";var httpClient = new HttpClient { BaseAddress = new Uri(baseUrl), Timeout = config.Timeout };if (config.Properties.TryGetValue("HeliconeApiKey", out var heliconeKey)){httpClient.DefaultRequestHeaders.Add("Helicone-Auth", $"Bearer {heliconeKey}");}if (config.Properties.TryGetValue("ApiKey", out var apiKey)){httpClient.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue("Bearer", apiKey.ToString()!);}if (config.Properties.TryGetValue("HeliconeCache", out var cache) && cache?.ToString() == "true"){httpClient.DefaultRequestHeaders.Add("Helicone-Cache-Enabled", "true");}return new DefaultConnectionHandle(httpClient, new Dictionary<string, object> { ["Provider"] = "Helicone", ["BaseUrl"] = baseUrl });}
    protected override async Task<bool> TestCoreAsync(IConnectionHandle handle, CancellationToken ct){try{var httpClient = handle.GetConnection<HttpClient>();using var response = await httpClient.GetAsync("/", ct);return response.IsSuccessStatusCode;}catch{return false;}}
    protected override Task DisconnectCoreAsync(IConnectionHandle handle, CancellationToken ct){handle.GetConnection<HttpClient>().Dispose();if (handle is DefaultConnectionHandle defaultHandle) defaultHandle.MarkDisconnected();return Task.CompletedTask;}
    protected override async Task<ConnectionHealth> GetHealthCoreAsync(IConnectionHandle handle, CancellationToken ct){var sw = System.Diagnostics.Stopwatch.StartNew();try{var httpClient = handle.GetConnection<HttpClient>();using var response = await httpClient.GetAsync("/", ct);sw.Stop();return new ConnectionHealth(response.IsSuccessStatusCode, response.IsSuccessStatusCode ? "Helicone connected" : "Helicone error: HTTP " + (int)response.StatusCode, sw.Elapsed, DateTimeOffset.UtcNow);}catch(Exception ex){sw.Stop();return new ConnectionHealth(false, $"Helicone error: {ex.Message}", sw.Elapsed, DateTimeOffset.UtcNow);}}
    public override async Task<string> SendRequestAsync(IConnectionHandle handle, string prompt, Dictionary<string, object>? options = null, CancellationToken ct = default){var httpClient = handle.GetConnection<HttpClient>();var model = options?.GetValueOrDefault("model", "gpt-4o") ?? "gpt-4o";var payload = new { model, messages = new[] { new { role = "user", content = prompt } }, temperature = options?.GetValueOrDefault("temperature", 0.7) };var json = JsonSerializer.Serialize(payload);using var content = new StringContent(json, Encoding.UTF8, "application/json");if (options?.TryGetValue("Helicone-User-Id", out var userId) == true){content.Headers.Add("Helicone-User-Id", userId?.ToString());}if (options?.TryGetValue("Helicone-Property-Session", out var session) == true){content.Headers.Add("Helicone-Property-Session", session?.ToString());}using var response = await httpClient.PostAsync("/chat/completions", content, ct);response.EnsureSuccessStatusCode();var result = await response.Content.ReadAsStringAsync(ct);using var doc = JsonDocument.Parse(result);return doc.RootElement.GetProperty("choices")[0].GetProperty("message").GetProperty("content").GetString() ?? "";}
    public override async IAsyncEnumerable<string> StreamResponseAsync(IConnectionHandle handle, string prompt, Dictionary<string, object>? options = null, [EnumeratorCancellation] CancellationToken ct = default){var httpClient = handle.GetConnection<HttpClient>();var model = options?.GetValueOrDefault("model", "gpt-4o") ?? "gpt-4o";var payload = new { model, messages = new[] { new { role = "user", content = prompt } }, stream = true };var json = JsonSerializer.Serialize(payload);using var content = new StringContent(json, Encoding.UTF8, "application/json");var request = new HttpRequestMessage(HttpMethod.Post, "/chat/completions"){Content = content};using var response = await httpClient.SendAsync(request, HttpCompletionOption.ResponseHeadersRead, ct);using var stream = await response.Content.ReadAsStreamAsync(ct);using var reader = new System.IO.StreamReader(stream);string? line;while (!ct.IsCancellationRequested && (line = await reader.ReadLineAsync(ct)) != null){if (string.IsNullOrEmpty(line) || !line.StartsWith("data: ")) continue;var data = line.Substring(6);if (data == "[DONE]") break;string? chunk = null;try{using var evt = JsonDocument.Parse(data);var delta = evt.RootElement.GetProperty("choices")[0].GetProperty("delta");if (delta.TryGetProperty("content", out var contentProp)){chunk = contentProp.GetString();}}catch{/* skip malformed */}if (chunk != null) yield return chunk;}}
}
