using System;using System.Collections.Generic;using System.Net.Http;using System.Net.Http.Headers;using System.Runtime.CompilerServices;using System.Text;using System.Text.Json;using System.Threading;using System.Threading.Tasks;using DataWarehouse.SDK.Connectors;using Microsoft.Extensions.Logging;

namespace DataWarehouse.Plugins.UltimateConnector.Strategies.AI;

/// <summary>Together AI. HTTPS to api.together.xyz/v1. Open-source model hosting with OpenAI-compatible API.</summary>
public sealed class TogetherAiConnectionStrategy : AiConnectionStrategyBase
{
    public override string StrategyId => "ai-together";public override string DisplayName => "Together AI";public override ConnectionStrategyCapabilities Capabilities => new(SupportsPooling: false, SupportsStreaming: true, SupportsAuthentication: true);public override string SemanticDescription => "Together AI open-source model hosting. Run Llama, Mistral, and other open models via OpenAI-compatible API.";public override string[] Tags => ["together", "llm", "open-source", "inference", "hosting"];
    public TogetherAiConnectionStrategy(ILogger? logger = null) : base(logger) { }
    protected override async Task<IConnectionHandle> ConnectCoreAsync(ConnectionConfig config, CancellationToken ct){var httpClient = new HttpClient { BaseAddress = new Uri("https://api.together.xyz/v1"), Timeout = config.Timeout };if (config.Properties.TryGetValue("ApiKey", out var apiKey)){httpClient.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue("Bearer", apiKey.ToString()!);}return new DefaultConnectionHandle(httpClient, new Dictionary<string, object> { ["Provider"] = "TogetherAI" });}
    protected override async Task<bool> TestCoreAsync(IConnectionHandle handle, CancellationToken ct){try{var httpClient = handle.GetConnection<HttpClient>();using var response = await httpClient.GetAsync("/", ct);return response.IsSuccessStatusCode;}catch{return false;}}
    protected override Task DisconnectCoreAsync(IConnectionHandle handle, CancellationToken ct){handle.GetConnection<HttpClient>().Dispose();if (handle is DefaultConnectionHandle defaultHandle) defaultHandle.MarkDisconnected();return Task.CompletedTask;}
    protected override async Task<ConnectionHealth> GetHealthCoreAsync(IConnectionHandle handle, CancellationToken ct){var sw = System.Diagnostics.Stopwatch.StartNew();try{var httpClient = handle.GetConnection<HttpClient>();using var response = await httpClient.GetAsync("/", ct);sw.Stop();return new ConnectionHealth(response.IsSuccessStatusCode, response.IsSuccessStatusCode ? "TogetherAi connected" : "TogetherAi error: HTTP " + (int)response.StatusCode, sw.Elapsed, DateTimeOffset.UtcNow);}catch(Exception ex){sw.Stop();return new ConnectionHealth(false, $"TogetherAi error: {ex.Message}", sw.Elapsed, DateTimeOffset.UtcNow);}}
    public override async Task<string> SendRequestAsync(IConnectionHandle handle, string prompt, Dictionary<string, object>? options = null, CancellationToken ct = default){var httpClient = handle.GetConnection<HttpClient>();var model = options?.GetValueOrDefault("model", "meta-llama/Llama-3-70b-chat-hf") ?? "meta-llama/Llama-3-70b-chat-hf";var payload = new { model, messages = new[] { new { role = "user", content = prompt } }, temperature = options?.GetValueOrDefault("temperature", 0.7) };var json = JsonSerializer.Serialize(payload);using var content = new StringContent(json, Encoding.UTF8, "application/json");using var response = await httpClient.PostAsync("/chat/completions", content, ct);response.EnsureSuccessStatusCode();var result = await response.Content.ReadAsStringAsync(ct);using var doc = JsonDocument.Parse(result);return doc.RootElement.GetProperty("choices")[0].GetProperty("message").GetProperty("content").GetString() ?? "";}
    public override async IAsyncEnumerable<string> StreamResponseAsync(IConnectionHandle handle, string prompt, Dictionary<string, object>? options = null, [EnumeratorCancellation] CancellationToken ct = default){var httpClient = handle.GetConnection<HttpClient>();var model = options?.GetValueOrDefault("model", "meta-llama/Llama-3-70b-chat-hf") ?? "meta-llama/Llama-3-70b-chat-hf";var payload = new { model, messages = new[] { new { role = "user", content = prompt } }, stream = true };var json = JsonSerializer.Serialize(payload);using var content = new StringContent(json, Encoding.UTF8, "application/json");var request = new HttpRequestMessage(HttpMethod.Post, "/chat/completions"){Content = content};using var response = await httpClient.SendAsync(request, HttpCompletionOption.ResponseHeadersRead, ct);using var stream = await response.Content.ReadAsStreamAsync(ct);using var reader = new System.IO.StreamReader(stream);string? line;while (!ct.IsCancellationRequested && (line = await reader.ReadLineAsync(ct)) != null){if (string.IsNullOrEmpty(line) || !line.StartsWith("data: ")) continue;var data = line.Substring(6);if (data == "[DONE]") break;string? chunk = null;try{using var evt = JsonDocument.Parse(data);var delta = evt.RootElement.GetProperty("choices")[0].GetProperty("delta");if (delta.TryGetProperty("content", out var contentProp)){chunk = contentProp.GetString();}}catch{/* skip malformed */}if (chunk != null) yield return chunk;}}
}
